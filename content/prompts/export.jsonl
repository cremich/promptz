{"__typename":{"S":"prompt"},"content":{"S":"Analyze the output of Eclipse MAT (heap dump leak suspects report) in the current folder, provide a summary and suggestions how to optimize the application."},"copyCount":{"N":"3"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"instruction":{"S":"Analyze the output of Eclipse MAT (heap dump leak suspects report) in the current folder, provide a summary and suggestions how to optimize the application."},"howto":{"S":""},"slug":{"S":"java-heap-dump-analysis-e546a9d6"},"createdAt":{"S":"2025-03-07T11:03:39.541Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Java Heap Dump analysis"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-03-07T21:43:10.368Z"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Analyzed and summarized an Eclipe MAT report with clear, actionable insights."},"id":{"S":"e546a9d6-5f66-420d-9950-37d8794da1d6"},"sourceURL":{"S":"https://www.linkedin.com/posts/smoell_java-javadevelopment-aws-activity-7303725402647109634-SWJJ"},"tags":{"L":[{"S":"CLI"},{"S":"Chat"},{"S":"Optimize"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"/dev Create a new Flask route in a dedicated web page at the following path: \"/votes\". This page should be password protected. The page will show a table (in a grid format) with the four restaurants and the vote for each restaurant. The page will also allow a user to vote for the restaurant of their choosing. This page should be modern, rich and following all the latest standards of web user interface developments. "},"copyCount":{"N":"7"},"owner_username":{"S":"mreferre"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"/dev Create a new Flask route in a dedicated web page at the following path: \"/votes\". This page should be password protected. The page will show a table (in a grid format) with the four restaurants and the vote for each restaurant. The page will also allow a user to vote for the restaurant of their choosing. This page should be modern, rich and following all the latest standards of web user interface developments. "},"howto":{"S":"The prerequisite would be to create the infrastructure to run the application locally. There is a script [here](https://github.com/aws-containers/votingapp/blob/master/preparation/prepare.sh) that allows to do that. You can then run the Python application in your IDE (which requires proper IAM permissions to have the app connect to DynamoDB etc.). It's a bit of work to setup initially but for me the ROI is worth because I use this app frequently to experiment with Q. I often use this for demoing Amazon Q Developer capabilities but hopefully can inspire for other type of real usage. "},"slug":{"S":"build-a-ui-for-a-votingapp-44aee1cf"},"createdAt":{"S":"2024-11-27T10:47:18.197Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Build a UI for a votingapp"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-01-31T10:48:13.776Z"},"category":{"S":"Dev Agent"},"sdlc_phase":{"S":"Enhance"},"owner":{"S":"c39478e2-40e1-70f2-1bec-0e9943f7efd8"},"description":{"S":"This prompt allows for creating a complete Flask-based user interface from scratch on top of this application that only exposes APIs (https://github.com/aws-containers/votingapp). I often use this for demoing Amazon Q Developer capabilities but hopefully can inspire for other type of real usage."},"id":{"S":"44aee1cf-3a45-4127-96b2-b146cf95ffaa"},"tags":{"L":[{"S":"Enhance"},{"S":"IDE"},{"S":"Dev Agent"}]}}
{"content":{"S":"As an experienced .Net software engineer, AWS solution architect, and technical writer, your task is to review and update the ActewAGL_Energy_API_Integration_Solution.md which outlining the steps to implement a new API submission route for the ActewAGL Energy Processor.\r\nTo achieve this, follow these steps:\r\n- Project Context: Review the files within the .amazonq/project-intelligence project to understand the existing context.\r\n- AWS Login: Use aws sso login --profile my-sso-profile to access AWS for infrastructure checks or local service execution.\r\n- Existing Route Review: Examine the /Users/louisnguyen/Desktop/Workspace/myconnect-connect-processor/Connect.Processor/Connectors/Endpoint/ActewAglEnergy directory for existing files related to this route.\r\n- API swagger document: Based on the API documentation located at /Users/louisnguyen/Desktop/Workspace/myconnect-connect-processor/Connect.Processor/Connectors/Endpoint/ActewAglEnergy/ESA_openApi_Specification-1.json, create the necessary models, database schema, and mapping classes.\r\n- Reference Implementation: Utilize the /Users/louisnguyen/Desktop/Workspace/myconnect-connect-processor/Connect.Processor/Connectors/Endpoint/SimplyEnergy implementation as a template for payload construction, mapping, authentication, authorization, order submission, and response handling for the new API Submission route of ActewAGL.\r\n- Existing Route Preservation: Maintain the existing SendSDFIRequestEmailAsync() route. Integrate the new API submission route by updating the existing processor, services, and related files within the ActewAGLEnergy provider.\r\n\r\nThe API submission route must meet the following requirements:\r\n- Payload Validation: Ensure the order payload sent to the ActewAGL API adheres to the API documentation's specifications and validation rules.\r\nAuthentication/Authorization: Implement the same authentication and authorization mechanism as the SimplyEnergy route, leveraging AddHttpMessageHandler() from the StartupExtensions.cs class.\r\n- Data Mapping: Map all payload fields directly from the records within the ExternalSubmissionContainer table in the mc-connect PostgresDB. Avoid creating unnecessary Constants classes.\r\n- The ActewAGl processor and service should be able to handle both SendSDFIRequestEmailAsync() and new APISubmission routes, similar with /Users/louisnguyen/Desktop/Workspace/myconnect-connect-processor/Connect.Processor/Connectors/Endpoint/AglEnergy/AglEnergyProcessor.cs.\r\n\r\n\r\nThe solution document should:\r\n- Provide a comprehensive and simple solution to create a new API Submission route for ActewAGL energy provider. \r\n- Provide clear and concise step by step instructions for implementing the new API submission route.\r\n- Include a dedicated section on integration tests for this new ActewAgl-APISubmission route follow the existing tests patterns from other energy providers routes. \r\n- Be well-structured and easy to understand for prompt implementation.\r\n- Don't make any changes at this planning step."},"copyCount":{"N":"0"},"howto":{"S":""},"slug":{"S":"actewaglapisubmission-d642f781"},"createdAt":{"S":"2025-08-28T00:53:57.529Z"},"scope":{"S":"PRIVATE"},"name":{"S":"ActewAGLApiSubmission"},"downloadCount":{"N":"0"},"updatedAt":{"S":"2025-08-28T00:56:32.743Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Create ActewAGLApiSubmission route"},"id":{"S":"d642f781-24ed-45f2-8944-58c7a8943279"},"sourceURL":{"S":""},"tags":{"L":[]}}
{"content":{"S":"I'm a {job title} with {Number} years relevant experience and just recorded myself giving a talk on {talk title}. Please check if there are any video files of any format in this directory (case insensitive) or ask me to provide the link to a public YouTube video URL. I want you to ask me which file or youtube url to choose by presenting me with a well formatted CLI numbered menu and then you will do the following:\r\n\r\nAssume you're a professional speaking coach and you're focused on reviewing my talks and assessing my presentation strengths and growth areas. Please do not give flattering responses, my goal is to improve my talk delivery.\r\n\r\nYou'll need to extract the speaking and non-verbal activity using open source software in order to access my sentiment, quality of delivery, overall mood, facial expressions, hand gestures, body language, and related factors that a public speaking speech coach would analyze.\r\n\r\nI'm looking for honest, constructive feedback so that I can get better at this.\r\n\r\nMake sure all the tools you use are local to my computer -- I don't want to incur any cloud computing charges for this project.\r\n\r\nPlease create these separate analysis files:\r\n1. A comprehensive analysis document with general observations and recommendations\r\n2. A timestamp-focused document highlighting specific moments to target in practice sessions\r\n3. Structure outline of the talk from the perspective of an audience member listening - include questions and note taking annotations so the speaker knows where there are areas to make clearer. Also attempt to discern what the call to action for the audience. \r\n4. A scorecard of the talk with a rubric based on what my job title and experience is at the beginning of this prompt. I want points for each section along with a grade overall.\r\n\r\nInclude specific timestamps I should focus on, with detailed notes about what issues occur at those timestamps and how to fix them.\r\n\r\nPlease use clear naming conventions and subfolder for each talk when needed based on the source filename within it so that I can come back and use this folder for multiple talk recordings over time. Also create an markdown file in the main folder so you know what do to next time I ask this in this directory. Remember if you need to review frame-by-frame thumbnails or have additional dependencies to complete this project, please sort them in clearly marked subfolders so that the the analysis files are what is seen per project -- I don't want to be overwhelmed by too many files at first glance of the output. \r\n\r\nAfter everything is complete, you can ask me if I want to process any more talks to start this over again."},"copyCount":{"N":"6"},"starCount":{"N":"0"},"instruction":{"S":"I'm a {job title} with {Number} years relevant experience and just recorded myself giving a talk on {talk title}. Please check if there are any video files of any format in this directory (case insensitive) or ask me to provide the link to a public YouTube video URL. I want you to ask me which file or youtube url to choose by presenting me with a well formatted CLI numbered menu and then you will do the following:\r\n\r\nAssume you're a professional speaking coach and you're focused on reviewing my talks and assessing my presentation strengths and growth areas. Please do not give flattering responses, my goal is to improve my talk delivery.\r\n\r\nYou'll need to extract the speaking and non-verbal activity using open source software in order to access my sentiment, quality of delivery, overall mood, facial expressions, hand gestures, body language, and related factors that a public speaking speech coach would analyze.\r\n\r\nI'm looking for honest, constructive feedback so that I can get better at this.\r\n\r\nMake sure all the tools you use are local to my computer -- I don't want to incur any cloud computing charges for this project.\r\n\r\nPlease create these separate analysis files:\r\n1. A comprehensive analysis document with general observations and recommendations\r\n2. A timestamp-focused document highlighting specific moments to target in practice sessions\r\n3. Structure outline of the talk from the perspective of an audience member listening - include questions and note taking annotations so the speaker knows where there are areas to make clearer. Also attempt to discern what the call to action for the audience. \r\n4. A scorecard of the talk with a rubric based on what my job title and experience is at the beginning of this prompt. I want points for each section along with a grade overall.\r\n\r\nInclude specific timestamps I should focus on, with detailed notes about what issues occur at those timestamps and how to fix them.\r\n\r\nPlease use clear naming conventions and subfolder for each talk when needed based on the source filename within it so that I can come back and use this folder for multiple talk recordings over time. Also create an markdown file in the main folder so you know what do to next time I ask this in this directory. Remember if you need to review frame-by-frame thumbnails or have additional dependencies to complete this project, please sort them in clearly marked subfolders so that the the analysis files are what is seen per project -- I don't want to be overwhelmed by too many files at first glance of the output. \r\n\r\nAfter everything is complete, you can ask me if I want to process any more talks to start this over again."},"howto":{"S":"**Prerequisites:**\r\n1. A video recording of your presentation (local file or YouTube URL)\r\n2. Basic information about your professional background (job title and years of experience)\r\n3. The title of your talk\r\n\r\n**Usage Instructions:**\r\n1. Provide your job title, years of experience, and talk title in the designated placeholders\r\n2. Have your presentation video ready (either as a local file or a public YouTube URL)\r\n3. Run the prompt in Amazon Q, which will scan for video files or ask you to provide a YouTube link\r\n4. Select the video you want analyzed from the presented menu\r\n5. Amazon Q will generate multiple analysis files organized in a structured folder system\r\n6. Review the feedback documents to identify areas for improvement\r\n7. Use the timestamp-specific feedback to focus your practice sessions\r\n8. The prompt creates a persistent markdown file so you can easily analyze additional presentations in the future\r\n\r\nThis prompt is ideal for professionals looking to improve their public speaking skills through detailed, objective feedback without requiring external coaching services."},"slug":{"S":"professional-speaking-coach-feedback-generator-bd566113"},"createdAt":{"S":"2025-06-06T20:32:06.540Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Professional Speaking Coach Feedback Generator"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"2"},"updatedAt":{"S":"2025-06-06T20:32:06.540Z"},"owner":{"S":"1304c862-60a1-7070-5e2a-bb36ace4add1"},"description":{"S":"Transforms Amazon Q into a speaking coach that analyzes presentation videos, providing detailed feedback on delivery, body language, and content structure.\r\n\r\nCreates multiple analysis files including comprehensive feedback, timestamp-specific notes, talk structure outline, and a personalized scorecard based on your experience level. Organizes outputs for easy reference and future analyses."},"id":{"S":"bd566113-5f1c-42ec-a96f-e61839d2c5d0"},"sourceURL":{"NULL":true},"tags":{"L":[{"S":"CLI"},{"S":"Chat"},{"S":"Optimize"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"@workspace can you generate a mermaid flow diagram of my application (data flow from up to bottom, use colors, keep formatting simple)"},"copyCount":{"N":"29"},"owner_username":{"S":"olemaitre"},"starCount":{"N":"1"},"interface":{"S":"IDE"},"instruction":{"S":"@workspace can you generate a mermaid flow diagram of my application (data flow from up to bottom, use colors, keep formatting simple)"},"howto":{"S":"You need a folder containing your application code (python, typescript, ...) and/or infrastructure code\r\nCopy/Paste the generated code into a markdown (.md) file, preview your markdown file (e.g. using mermaid extension in VS Code)"},"slug":{"S":"generate-mermaid-application-flow-diagram-from-code-31f51737"},"createdAt":{"S":"2024-11-04T20:02:26.177Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Generate Mermaid application flow diagram from code"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-04-23T12:39:03.218Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Design"},"owner":{"S":"03746802-d021-70a3-b8b8-e364eaff2b71"},"description":{"S":"Generates a mermaid application flow diagram as code to visualize/document the design of your application"},"id":{"S":"31f51737-d832-4e8b-a21d-3f3e3d973637"},"sourceURL":{"S":"https://github.com/welcloud-io/wio-from-diagram-to-code-with-amazon-q-developer/blob/main/_playground/README.md#11---generate-applicationflow-diagram"},"tags":{"L":[{"S":"Design"},{"S":"IDE"},{"S":"Chat"}]}}
{"content":{"S":"Analiza el archivo ServiceDocsTemplate.md, despues analiza el archivo @stackUtilityDocs.md ahi se lista el servicio ApiMensajeError-Fn su codigo fuente esta en servicios/code/utilities/ApiMensajesError-Fn/ , con esta informacion y el archivo template actualiza el archivo de documentacion del servicio en la ruta estabecida en el documento del stack"},"copyCount":{"N":"0"},"howto":{"S":""},"slug":{"S":"documentar-servicio-d1a7c41d"},"createdAt":{"S":"2025-08-21T00:06:11.111Z"},"scope":{"S":"PRIVATE"},"name":{"S":"Documentar servicio"},"downloadCount":{"N":"0"},"updatedAt":{"S":"2025-08-21T00:06:11.111Z"},"owner":{"S":"43f4a882-d0d1-70bf-b154-24dc52a0abd4"},"description":{"S":"Permite documentar el servicio API mencionado basedo en un template , stack de cloudformation y codigo fuente del servicio."},"id":{"S":"d1a7c41d-4abc-4515-904d-62bfba44a63c"},"tags":{"L":[]},"sourceURL":{"S":""}}
{"content":{"S":"You are acting as an experienced .Net software engineer, an AWS solution architecture and technical writer:\r\n\r\nYour task is to:\r\n- Give a comprehensive solution document to create a new Email Integration route for Ergon Energy on this service. \r\n\r\nTo doing that you must: \r\n- Read all files inside .amazonq/project-intelligence project to get the project context.\r\n- Login to aws using command: aws sso login --profile my-sso-profile if need to check the current infrastructure or run the service on local.\r\n- Check the /Users/louisnguyen/Desktop/Workspace/myconnect-connect-processor/Connect.Processor/Connectors/Endpoint/ErgonEnergy folder to get the current files that created for this route.\r\n- - Use JJProcessor as a sample for the build submission part, create a ConnectionRequest with properties.\r\n- Use AGLEnergyCAFSerice as sample for the service, should closed the requestContainer once the email been sent, and submitted a OutComeContainer to DB. \r\n- Create the Map class to map the Request properties with the CSV-Excel Row.s (exp: EASAleCafReqiestMap (ClassMap), all fields should have correct data types with the CAF file, except phone number should be text. CAF file to use for this route is Ergon Example CAF.csv\r\n- Check  file ExcelService method Generate you will see that you can pass a password to generate the file. Then if you check the OriginEnergyCAFService method GenerateSalesSubmissionsStream you can see it in use\r\n\r\nThe integration routes must satisfied below requirements: \r\n- This route is Individual CAF (not batched)\r\n- Email submission with password protected XLSX (Ergon will send template)\r\n- Concession - hard code “no” and add scripting about contacting Ergon\r\n- Require middle name if the ID type is Medicare and the middle name is present on the card. Add to scripting only for now (validation later)\r\n- Require card number for driver license, add field and scripting\r\n- Have a filed for Medicare card's  colour\r\n- No passport allowed as ID type, add validation in SF later\r\n- Submit email to mail trap for testing on staging.\r\n\r\n\r\nThe goals are\r\n- Give a solution document in .md format with detail instruction and step by step to update and create this email integration route.\r\n- Have a section to cover unit tests and integration tests for this route.\r\n- The report should be well-structured with clear sections and easy for prompt implement. \r\n- Don't make any code changes without acknowledge me."},"copyCount":{"N":"7"},"starCount":{"N":"0"},"instruction":{"S":"You are acting as an experienced .Net software engineer, an AWS solution architecture and technical writer:\r\n\r\nYour task is to:\r\n- Give a comprehensive solution document to create a new Email Integration route for Ergon Energy on this service. \r\n\r\nTo doing that you must: \r\n- Read all files inside .amazonq/project-intelligence project to get the project context.\r\n- Login to aws using command: aws sso login --profile my-sso-profile if need to check the current infrastructure or run the service on local.\r\n- Check the /Users/louisnguyen/Desktop/Workspace/myconnect-connect-processor/Connect.Processor/Connectors/Endpoint/ErgonEnergy folder to get the current files that created for this route.\r\n- - Use JJProcessor as a sample for the build submission part, create a ConnectionRequest with properties.\r\n- Use AGLEnergyCAFSerice as sample for the service, should closed the requestContainer once the email been sent, and submitted a OutComeContainer to DB. \r\n- Create the Map class to map the Request properties with the CSV-Excel Row.s (exp: EASAleCafReqiestMap (ClassMap), all fields should have correct data types with the CAF file, except phone number should be text. CAF file to use for this route is Ergon Example CAF.csv\r\n- Check  file ExcelService method Generate you will see that you can pass a password to generate the file. Then if you check the OriginEnergyCAFService method GenerateSalesSubmissionsStream you can see it in use\r\n\r\nThe integration routes must satisfied below requirements: \r\n- This route is Individual CAF (not batched)\r\n- Email submission with password protected XLSX (Ergon will send template)\r\n- Concession - hard code “no” and add scripting about contacting Ergon\r\n- Require middle name if the ID type is Medicare and the middle name is present on the card. Add to scripting only for now (validation later)\r\n- Require card number for driver license, add field and scripting\r\n- Have a filed for Medicare card's  colour\r\n- No passport allowed as ID type, add validation in SF later\r\n- Submit email to mail trap for testing on staging.\r\n\r\n\r\nThe goals are\r\n- Give a solution document in .md format with detail instruction and step by step to update and create this email integration route.\r\n- Have a section to cover unit tests and integration tests for this route.\r\n- The report should be well-structured with clear sections and easy for prompt implement. \r\n- Don't make any code changes without acknowledge me."},"howto":{"NULL":true},"slug":{"S":"ergon-submission-92c2d045"},"createdAt":{"S":"2025-08-01T05:15:06.594Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Ergon Submission"},"updatedAt":{"S":"2025-08-01T05:15:06.594Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Create a new Email integration route for Ergon"},"id":{"S":"92c2d045-4e45-4bf6-aa7d-812a74b1d7b0"},"sourceURL":{"NULL":true},"tags":{"L":[]}}
{"__typename":{"S":"prompt"},"content":{"S":"/dev Add unit tests for CDK L3 construct in this repository. \n\nWhen creating unit tests using fine-grained assertions, follow these principles:\n- Verify security configurations and business requirements.\n- Test boundary conditions and error cases in construct properties.\n- Verify that required resources are created and properly linked.\n- Verify that required resources contain the right IAM permissions.\n- Focus unit tests on specific behaviors that must not change.\n- if applicable, mock CDK assets like docker images or lambda function to prevent generating zip files during test execution. This speeds up test execution.\n- each test should only test a single specific aspect of the construct.\n- Ensure that the unit test cover constructs and not stacks.\n\nThe unit test should conform to the following guidelines:\n- use jest as the test framework\n- add comments to explain what every test is covering\n- use a meaningful name of the test\n- do not add extra `describe` blocks.\n- use the `test()` method to run an individual test\n- do not import `describe`, `test`, `jest` or `expect`.\n- use the `aws-cdk-lib.assertions` library from CDK v2 for assertions\n- use single named imports\n- use arrow functions for all test functions.\n- the test file must be named like the source ending with `.test.ts`. Example: if the source file is named `api-construct.ts`, the test file must be named `api-construct.test.ts`"},"copyCount":{"N":"5"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"/dev Add unit tests for CDK L3 construct in this repository. \n\nWhen creating unit tests using fine-grained assertions, follow these principles:\n- Verify security configurations and business requirements.\n- Test boundary conditions and error cases in construct properties.\n- Verify that required resources are created and properly linked.\n- Verify that required resources contain the right IAM permissions.\n- Focus unit tests on specific behaviors that must not change.\n- if applicable, mock CDK assets like docker images or lambda function to prevent generating zip files during test execution. This speeds up test execution.\n- each test should only test a single specific aspect of the construct.\n- Ensure that the unit test cover constructs and not stacks.\n\nThe unit test should conform to the following guidelines:\n- use jest as the test framework\n- add comments to explain what every test is covering\n- use a meaningful name of the test\n- do not add extra `describe` blocks.\n- use the `test()` method to run an individual test\n- do not import `describe`, `test`, `jest` or `expect`.\n- use the `aws-cdk-lib.assertions` library from CDK v2 for assertions\n- use single named imports\n- use arrow functions for all test functions.\n- the test file must be named like the source ending with `.test.ts`. Example: if the source file is named `api-construct.ts`, the test file must be named `api-construct.test.ts`"},"howto":{"S":""},"slug":{"S":"cdk-unit-tests-for-typescript-and-jest-1ad0b831"},"createdAt":{"S":"2025-01-17T12:41:12.208Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"CDK unit tests for Typescript and jest"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-01-17T13:06:48.394Z"},"category":{"S":"Dev Agent"},"sdlc_phase":{"S":"Test"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Testing constructs with fine-grained assertions focussing on covering relevant business logic, integration aspects and guardrails."},"id":{"S":"1ad0b831-7349-4a10-a048-4c373b5b9ea9"},"tags":{"L":[{"S":"Test"},{"S":"IDE"},{"S":"Dev Agent"}]}}
{"content":{"S":"Apply a code review by comparing all the changes in this branch with main/master. Do not make any changes; report your review results at the end. Respect the following rules for your review:\r\n- Check for staged files in submodules repositories too\r\n- Code is commented in hard-to-understand areas\r\n- Corresponding changes to the documentation have been made\r\n- Run the linter to prove the changes generate no new lint errors\r\n- Run unit tests to prove the change does not introduce breaking changes\r\n- Check if any dependent changes have been merged"},"copyCount":{"N":"0"},"starCount":{"N":"0"},"instruction":{"S":"Apply a code review by comparing all the changes in this branch with main/master. Do not make any changes; report your review results at the end. Respect the following rules for your review:\r\n- Check for staged files in submodules repositories too\r\n- Code is commented in hard-to-understand areas\r\n- Corresponding changes to the documentation have been made\r\n- Run the linter to prove the changes generate no new lint errors\r\n- Run unit tests to prove the change does not introduce breaking changes\r\n- Check if any dependent changes have been merged"},"howto":{"NULL":true},"slug":{"S":"code-review-ecb2dc66"},"createdAt":{"S":"2025-07-04T06:37:01.638Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Code review"},"updatedAt":{"S":"2025-07-04T06:37:01.638Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Code review"},"id":{"S":"ecb2dc66-0228-4731-8e08-9c618425992b"},"sourceURL":{"NULL":true},"tags":{"L":[]}}
{"__typename":{"S":"prompt"},"content":{"S":"@workspace Analyze the code in the workspace and create a mermaid sequence diagram that illustrates the <ENTER YOUR FLOW> with these specifications:\r\n\r\nLayout and Structure:\r\nArrange participants (actors/systems) horizontally from left to right based on their order of interaction\r\nPosition the initiating actor/system on the far left\r\nGroup related systems next to each other\r\nMaintain consistent spacing between lifelines\r\n\r\nParticipant Styling:\r\nUse distinct colors for different types of participants:\r\nUser/External Actors: Light Orange (#FFE4B5)\r\nAPI/Controllers: Light Blue (#ADD8E6)\r\nServices: Light Green (#90EE90)\r\nDatabases: Light Yellow (#FFFFE0)\r\nExternal Services: Light Purple (#E6E6FA)\r\nUse clear, descriptive names for participants\r\nAdd stereotypes to indicate participant types (<<API>>, <<Service>>, etc.)\r\n\r\nMessage Representation:\r\nUse appropriate arrow types:\r\nSolid arrows (→) for synchronous calls\r\nDotted arrows (-->) for asynchronous calls\r\nOpen arrows (->) for responses\r\nBold arrows (=>) for critical path operations\r\nKeep messages short but descriptive\r\nInclude important parameters in message labels\r\nShow return values where significant\r\n\r\nFlow Organization:\r\nBreak long sequences into logical segments using dividers\r\nUse activation boxes to show processing time\r\nInclude alt/opt/loop fragments for conditional flows\r\nShow parallel processing using par fragments\r\nHighlight error paths using alt fragments\r\n\r\nDocumentation and Clarity:\r\nAdd notes for complex logic or important conditions\r\nInclude timing information where relevant\r\nShow retry/timeout mechanisms\r\nDocument error handling paths\r\nAdd sequence numbers for key steps\r\n\r\nOptimization:\r\nFocus on main success scenario first\r\nShow alternative paths separately if too complex\r\nLimit diagram to one main business transaction\r\nCollapse repetitive sequences into loop fragments\r\nHide unnecessary technical details\r\n\r\nAdditional Details:\r\nInclude HTTP methods for API calls\r\nShow important status codes/responses\r\nIndicate async/await patterns clearly\r\nMark critical validation points\r\nShow transaction boundaries\r\nPlease generate a sequence diagram that captures the main flow while maintaining readability and providing sufficient detail for understanding the interaction pattern"},"copyCount":{"N":"6"},"owner_username":{"S":"Vinay Nadig"},"starCount":{"N":"0"},"instruction":{"S":"@workspace Analyze the code in the workspace and create a mermaid sequence diagram that illustrates the <ENTER YOUR FLOW> with these specifications:\r\n\r\nLayout and Structure:\r\nArrange participants (actors/systems) horizontally from left to right based on their order of interaction\r\nPosition the initiating actor/system on the far left\r\nGroup related systems next to each other\r\nMaintain consistent spacing between lifelines\r\n\r\nParticipant Styling:\r\nUse distinct colors for different types of participants:\r\nUser/External Actors: Light Orange (#FFE4B5)\r\nAPI/Controllers: Light Blue (#ADD8E6)\r\nServices: Light Green (#90EE90)\r\nDatabases: Light Yellow (#FFFFE0)\r\nExternal Services: Light Purple (#E6E6FA)\r\nUse clear, descriptive names for participants\r\nAdd stereotypes to indicate participant types (<<API>>, <<Service>>, etc.)\r\n\r\nMessage Representation:\r\nUse appropriate arrow types:\r\nSolid arrows (→) for synchronous calls\r\nDotted arrows (-->) for asynchronous calls\r\nOpen arrows (->) for responses\r\nBold arrows (=>) for critical path operations\r\nKeep messages short but descriptive\r\nInclude important parameters in message labels\r\nShow return values where significant\r\n\r\nFlow Organization:\r\nBreak long sequences into logical segments using dividers\r\nUse activation boxes to show processing time\r\nInclude alt/opt/loop fragments for conditional flows\r\nShow parallel processing using par fragments\r\nHighlight error paths using alt fragments\r\n\r\nDocumentation and Clarity:\r\nAdd notes for complex logic or important conditions\r\nInclude timing information where relevant\r\nShow retry/timeout mechanisms\r\nDocument error handling paths\r\nAdd sequence numbers for key steps\r\n\r\nOptimization:\r\nFocus on main success scenario first\r\nShow alternative paths separately if too complex\r\nLimit diagram to one main business transaction\r\nCollapse repetitive sequences into loop fragments\r\nHide unnecessary technical details\r\n\r\nAdditional Details:\r\nInclude HTTP methods for API calls\r\nShow important status codes/responses\r\nIndicate async/await patterns clearly\r\nMark critical validation points\r\nShow transaction boundaries\r\nPlease generate a sequence diagram that captures the main flow while maintaining readability and providing sufficient detail for understanding the interaction pattern"},"howto":{"S":"Copy the prompt and replace <ENTER YOUR FLOW> with the desired system flow that you would like to capture in the sequence diagram"},"slug":{"S":"draw-like-a-pro-sequence-diagrams-for-a-system-flow-33ece251"},"createdAt":{"S":"2025-03-06T17:42:11.632Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Draw like a Pro : Sequence Diagrams for a system flow"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-03-06T17:42:11.632Z"},"owner":{"S":"google_101017001478424673799"},"description":{"S":"Better prompts for drawing sequence diagram"},"id":{"S":"33ece251-8400-45cc-902a-2373956665be"},"tags":{"L":[]}}
{"content":{"S":"You are acting as an experienced .Net software engineer, an AWS solution architecture and technical writer:\r\n\r\nYour task is to:\r\n- Checking the feature change plan on /Users/louisnguyen/Desktop/Workspace/myconnect-addresses/DataFind_Service_Implementation_Scope.md, give estimate time to completed (hours) and provide list of questions that need to clarified to implement this change correctly. \r\n\r\nTo doing that you must: \r\n- Read all files inside .amazonq/project-intelligence project to get the project context.\r\n- Reade the change plan on /Users/louisnguyen/Desktop/Workspace/myconnect-addresses/DataFind_Service_Implementation_Scope.md\r\n- Verify how we could test this change.\r\n\r\nThe goals are\r\n- Give a estimate document in .md format \r\n- The document should be well-structured with clear sections.\r\n- Don't make any code changes without acknowledge me."},"copyCount":{"N":"1"},"howto":{"S":""},"slug":{"S":"estimate-new-tickets-7adc164d"},"createdAt":{"S":"2025-09-30T02:43:21.902Z"},"scope":{"S":"PRIVATE"},"name":{"S":"Estimate new tickets"},"downloadCount":{"N":"0"},"updatedAt":{"S":"2025-09-30T02:43:21.902Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Estimate new tickets"},"id":{"S":"7adc164d-84c5-44da-99a9-2fb01959fca9"},"sourceURL":{"S":""},"tags":{"L":[]}}
{"__typename":{"S":"prompt"},"content":{"S":"@workspace Analyze the code in the workspace and create a mermaid sequence diagram that illustrates the <ENTER YOUR FLOW> with these specifications:\r\n\r\nLayout and Structure:\r\nArrange participants (actors/systems) horizontally from left to right based on their order of interaction\r\nPosition the initiating actor/system on the far left\r\nGroup related systems next to each other\r\nMaintain consistent spacing between lifelines\r\n\r\nParticipant Styling:\r\nUse distinct colors for different types of participants:\r\nUser/External Actors: Light Orange (#FFE4B5)\r\nAPI/Controllers: Light Blue (#ADD8E6)\r\nServices: Light Green (#90EE90)\r\nDatabases: Light Yellow (#FFFFE0)\r\nExternal Services: Light Purple (#E6E6FA)\r\nUse clear, descriptive names for participants\r\nAdd stereotypes to indicate participant types (<<API>>, <<Service>>, etc.)\r\n\r\nMessage Representation:\r\nUse appropriate arrow types:\r\nSolid arrows (→) for synchronous calls\r\nDotted arrows (-->) for asynchronous calls\r\nOpen arrows (->) for responses\r\nBold arrows (=>) for critical path operations\r\nKeep messages short but descriptive\r\nInclude important parameters in message labels\r\nShow return values where significant\r\n\r\nFlow Organization:\r\nBreak long sequences into logical segments using dividers\r\nUse activation boxes to show processing time\r\nInclude alt/opt/loop fragments for conditional flows\r\nShow parallel processing using par fragments\r\nHighlight error paths using alt fragments\r\n\r\nDocumentation and Clarity:\r\nAdd notes for complex logic or important conditions\r\nInclude timing information where relevant\r\nShow retry/timeout mechanisms\r\nDocument error handling paths\r\nAdd sequence numbers for key steps\r\n\r\nOptimization:\r\nFocus on main success scenario first\r\nShow alternative paths separately if too complex\r\nLimit diagram to one main business transaction\r\nCollapse repetitive sequences into loop fragments\r\nHide unnecessary technical details\r\n\r\nAdditional Details:\r\nInclude HTTP methods for API calls\r\nShow important status codes/responses\r\nIndicate async/await patterns clearly\r\nMark critical validation points\r\nShow transaction boundaries\r\nPlease generate a sequence diagram that captures the main flow while maintaining readability and providing sufficient detail for understanding the interaction pattern"},"copyCount":{"N":"0"},"owner_username":{"S":"Vinay Nadig"},"starCount":{"N":"0"},"instruction":{"S":"@workspace Analyze the code in the workspace and create a mermaid sequence diagram that illustrates the <ENTER YOUR FLOW> with these specifications:\r\n\r\nLayout and Structure:\r\nArrange participants (actors/systems) horizontally from left to right based on their order of interaction\r\nPosition the initiating actor/system on the far left\r\nGroup related systems next to each other\r\nMaintain consistent spacing between lifelines\r\n\r\nParticipant Styling:\r\nUse distinct colors for different types of participants:\r\nUser/External Actors: Light Orange (#FFE4B5)\r\nAPI/Controllers: Light Blue (#ADD8E6)\r\nServices: Light Green (#90EE90)\r\nDatabases: Light Yellow (#FFFFE0)\r\nExternal Services: Light Purple (#E6E6FA)\r\nUse clear, descriptive names for participants\r\nAdd stereotypes to indicate participant types (<<API>>, <<Service>>, etc.)\r\n\r\nMessage Representation:\r\nUse appropriate arrow types:\r\nSolid arrows (→) for synchronous calls\r\nDotted arrows (-->) for asynchronous calls\r\nOpen arrows (->) for responses\r\nBold arrows (=>) for critical path operations\r\nKeep messages short but descriptive\r\nInclude important parameters in message labels\r\nShow return values where significant\r\n\r\nFlow Organization:\r\nBreak long sequences into logical segments using dividers\r\nUse activation boxes to show processing time\r\nInclude alt/opt/loop fragments for conditional flows\r\nShow parallel processing using par fragments\r\nHighlight error paths using alt fragments\r\n\r\nDocumentation and Clarity:\r\nAdd notes for complex logic or important conditions\r\nInclude timing information where relevant\r\nShow retry/timeout mechanisms\r\nDocument error handling paths\r\nAdd sequence numbers for key steps\r\n\r\nOptimization:\r\nFocus on main success scenario first\r\nShow alternative paths separately if too complex\r\nLimit diagram to one main business transaction\r\nCollapse repetitive sequences into loop fragments\r\nHide unnecessary technical details\r\n\r\nAdditional Details:\r\nInclude HTTP methods for API calls\r\nShow important status codes/responses\r\nIndicate async/await patterns clearly\r\nMark critical validation points\r\nShow transaction boundaries\r\nPlease generate a sequence diagram that captures the main flow while maintaining readability and providing sufficient detail for understanding the interaction pattern"},"howto":{"S":"Copy the prompt and replace <ENTER YOUR FLOW> with the desired system flow that you would like to capture in the sequence diagram"},"slug":{"S":"draw-like-a-pro-sequence-diagrams-for-a-system-flow-554c2628"},"createdAt":{"S":"2025-03-06T15:52:30.443Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Draw like a Pro : Sequence Diagrams for a system flow"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-03-06T15:52:30.443Z"},"owner":{"S":"google_101017001478424673799"},"description":{"S":"Mermaid scripts for sequence diagrams analyzing your workspace"},"id":{"S":"554c2628-3c3b-49de-8bd2-ecda24cbf485"},"tags":{"L":[{"S":"IDE"},{"S":"CLI"},{"S":"Chat"},{"S":"Plan"},{"S":"Design"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"We decided to {decision-title}. Here are the main reasons that impacted our reasoning:\r\n- {reason-1}\r\n- {reason-2}\r\n- {reason-3}\r\n\r\nCreate an architecture decision record draft for this decision."},"copyCount":{"N":"0"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"We decided to {decision-title}. Here are the main reasons that impacted our reasoning:\r\n- {reason-1}\r\n- {reason-2}\r\n- {reason-3}\r\n\r\nCreate an architecture decision record draft for this decision."},"howto":{"S":""},"slug":{"S":"draft-adrs-e3afd39a"},"createdAt":{"S":"2024-10-25T14:56:14.385Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Draft ADRs"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-08-11T12:39:21.551Z"},"category":{"S":"Dev Agent"},"sdlc_phase":{"S":"Design"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Creates a draft for a new Architecture Decision Record in your git repository"},"id":{"S":"e3afd39a-06f9-42db-b4db-9dd437960747"},"sourceURL":{"S":""},"tags":{"L":[{"S":"Design"},{"S":"IDE"},{"S":"Dev Agent"}]}}
{"content":{"S":"You are acting as an experienced ReactJS software engineer.\r\n\r\nYour task is to:\r\n- Check the status of the migration plan on /Users/louisnguyen/Desktop/Workspace/myconnect-ssu/internet-load-route-refactor.md and help me to complete it. \r\n\r\nTo doing that you must: \r\n- Read all files inside .amazonq/project-intelligence project to get the project context.\r\n- Read the /Users/louisnguyen/Desktop/Workspace/myconnect-ssu/internet-load-route-refactor.md file to get the migration plan. \r\n- Read the API document on /Users/louisnguyen/Desktop/Workspace/myconnect-ssu/openapi.yaml to understand the 2 routes /v1/plans and  /v1/orders that the task that this service integrates with and data structure require for each route. \r\n- Check the changes on the current local feature branch compare to main branch and migration plan to get the status of the migration. \r\n\r\nThe goals are\r\n- Give summary report on the migration status, with note on things need to be improved and compeleted.\r\n- Don't make any code changes without acknowledge me."},"copyCount":{"N":"0"},"howto":{"S":""},"slug":{"S":"ssu-react-app-f6683004"},"createdAt":{"S":"2025-09-25T04:56:51.893Z"},"scope":{"S":"PRIVATE"},"name":{"S":"SSU - React App"},"downloadCount":{"N":"0"},"updatedAt":{"S":"2025-09-25T04:56:51.893Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Changes on React App to add Origin BB submission"},"id":{"S":"f6683004-088f-4ddd-9093-0234e713e543"},"tags":{"L":[]},"sourceURL":{"S":""}}
{"content":{"S":"[ROLE & GOAL]\r\nYou are a Staff Engineer and a respected mentor performing a code review. Your objective is not just to find flaws, but to elevate the code and the developer who wrote it. Your feedback should be insightful, respectful, and always focused on achieving the highest engineering standards.\r\n\r\n[CRITICAL RULES]\r\n1.  **Constructive, Not Critical**: Frame all feedback collaboratively. Use phrases like \"Have you considered...\" or \"An alternative approach might be...\" instead of \"This is wrong.\"\r\n2.  **Explain the 'Why'**: Never just state a problem. Always explain the underlying principle or potential impact. (e.g., \"This could lead to a race condition because...\").\r\n3.  **Prioritize Impact**: Differentiate clearly between critical issues (bugs, security risks), important suggestions (architectural improvements, performance), and minor nitpicks (style preferences).\r\n4.  **Suggest, Don't Command**: When possible, offer alternative code snippets to illustrate your points, but present them as suggestions for the author to consider.\r\n\r\n[STEP-BY-STEP PROCESS]\r\n1.  **High-Level Assessment**: Start with a positive comment and a summary of the code's purpose and overall approach.\r\n2.  **Detailed Analysis**: Go through the code, identifying key areas for improvement. Group your comments by theme (e.g., Logic, Security, Readability).\r\n3.  **Synthesize Findings**: Conclude with a high-level summary of the most important changes recommended.\r\n4.  **Pose Open Questions**: Encourage a dialogue by asking questions that prompt the developer to think more deeply about their design choices.\r\n\r\n[OUTPUT FORMAT]\r\nStructure your review like a professional Pull Request comment on GitHub:\r\n\r\nHi there, thanks for putting this together! This is a solid approach to [the feature]. I've left a few thoughts and suggestions below to help us make it even more robust.\r\n\r\n**Overall:** [Your high-level assessment here.]\r\n\r\n---\r\n\r\n**Suggestions & Comments:**\r\n\r\n- **[Critical]** `File: [filename.ext], Line: [number]`\r\n  - **Observation:** [Describe the issue].\r\n  - **Impact:** [Explain the potential negative consequences].\r\n  - **Suggestion:** [Provide a clear recommendation or code snippet].\r\n\r\n- **[Suggestion]** `File: [filename.ext], Line: [number]`\r\n  - **Observation:** [Describe the potential improvement].\r\n  - **Reasoning:** [Explain the benefit of the change].\r\n\r\n---\r\n\r\n**Questions:**\r\n- [Ask 1-2 thoughtful questions about the design].\r\n\r\nLet me know what you think! Happy to discuss further."},"copyCount":{"N":"0"},"howto":{"S":"Paste the code snippet you want to be reviewed. For best results, provide the context of what the code is trying to achieve.\r\n\r\nThis agent is perfect for getting a second opinion on your code before committing, or for learning best practices through concrete examples."},"slug":{"S":"the-constructive-code-review-partner-e6f9a737"},"createdAt":{"S":"2025-09-21T05:56:51.645Z"},"scope":{"S":"PRIVATE"},"name":{"S":"The Constructive Code Review Partner"},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-10-02T20:39:14.185Z"},"owner":{"S":"a3148862-b0b1-70de-1490-f2e3251d40cd"},"description":{"S":"Simulates a thoughtful and experienced senior developer performing a code review. The agent provides feedback that is technically deep, insightful, and constructive, focusing on improving the code's quality and the developer's understanding."},"id":{"S":"e6f9a737-a10a-4c15-917c-049176cc1b80"},"sourceURL":{"S":"https://github.com/NovusAevum/promptforge-enterprise"},"tags":{"L":[{"S":"Review Agent"},{"S":"Enhance"},{"S":"Refactoring"},{"S":"Optimize"},{"S":"Security"},{"S":"Test"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"/dev Transform the application using the twelve-factor app approach. \r\nGenerate step-by-step instructions in the README.md file after refactoring is complete.\r\n\r\nUse docker as the target deployment approach."},"copyCount":{"N":"8"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"/dev Transform the application using the twelve-factor app approach. \r\nGenerate step-by-step instructions in the README.md file after refactoring is complete.\r\n\r\nUse docker as the target deployment approach."},"howto":{"S":""},"slug":{"S":"12-factor-refactoring-dac01c8d"},"createdAt":{"S":"2024-10-26T16:05:38.701Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"12-factor refactoring"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"3"},"updatedAt":{"S":"2025-03-06T15:47:24.457Z"},"category":{"S":"Dev Agent"},"sdlc_phase":{"S":"Refactoring"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Refactors a given application using 12-factor as a methodology for building software-as-a-service apps."},"id":{"S":"dac01c8d-56ea-4159-80e8-ad950cc9ed9c"},"tags":{"L":[{"S":"Refactoring"},{"S":"IDE"},{"S":"Dev Agent"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"You are an experienced technical writer and expert software engineer.\r\n\r\nYour task is to create a comprehensive structured documentation system that allows Amazon Q Developer to maintain context across sessions. It transforms Amazon Q Developer from a stateless assistant into a persistent development partner that can effectively remember project details over time.\r\n\r\n## Details\r\n\r\n### Core Files\r\n\r\nThe documentation system consists of the following hierarchy of files, all in Markdown format:\r\n\r\n```mermaid\r\nflowchart TD\r\n    P[project.md]\r\n    P --> A[architecture.md]\r\n    P --> T[techstack.md]\r\n    P --> PS[progress.md]\r\n```\r\n\r\n#### project.md\r\n\r\n- Explains why this project exists\r\n- Describes the problem being solved\r\n- Outlines how the project should work\r\n- Contains a high-level overview of is developed\r\n- Describes core requirements and goals\r\n\r\n#### architecture.md\r\n\r\n- Documents the system architecture by describing the structure of the system and the architecture characteristics the system must support.\r\n- Records key design principles\r\n- Lists design patterns being used\r\n- Explains relationships of components\r\n\r\n#### techstack.md\r\n\r\n- Describes technologies and frameworks being used\r\n- Documents the development setup and tool configurations\r\n- Notes known constraints\r\n\r\n#### progress.md\r\n\r\n- Tracks what works and what's left to build\r\n- Records current status of features\r\n- Lists known issues and limitations to be improved in the future\r\n\r\n### Steps\r\n\r\nThese are the mandatory steps to complete the tasks:\r\n\r\n1. Create a new folder `project-intelligence` inside the `.amazonq` folder\r\n2. Analyze the application to get a comprehensive understanding of the project\r\n3. Analyze the git history to understand the current state of development\r\n4. Create the project.md file\r\n5. Create the architecture.md file\r\n6. Create the techstack.md file\r\n7. Create the progress.md file\r\n\r\n### Output Format\r\n\r\n- All files must be formatted in markdown\r\n- Use mermaid syntax for aspects such as architecture visualizations, user flows or component relationships\r\n\r\n## Sense Check\r\n\r\nOnce you are finished, review all files to confirm that the documentation is meaningful, comprehensive and fulfills the described objective. If this is not the case, keep iterating on the steps and review again until you think that the task is complete."},"copyCount":{"N":"388"},"owner_username":{"S":"cremich"},"starCount":{"N":"1"},"instruction":{"S":"You are an experienced technical writer and expert software engineer.\r\n\r\nYour task is to create a comprehensive structured documentation system that allows Amazon Q Developer to maintain context across sessions. It transforms Amazon Q Developer from a stateless assistant into a persistent development partner that can effectively remember project details over time.\r\n\r\n## Details\r\n\r\n### Core Files\r\n\r\nThe documentation system consists of the following hierarchy of files, all in Markdown format:\r\n\r\n```mermaid\r\nflowchart TD\r\n    P[project.md]\r\n    P --> A[architecture.md]\r\n    P --> T[techstack.md]\r\n    P --> PS[progress.md]\r\n```\r\n\r\n#### project.md\r\n\r\n- Explains why this project exists\r\n- Describes the problem being solved\r\n- Outlines how the project should work\r\n- Contains a high-level overview of is developed\r\n- Describes core requirements and goals\r\n\r\n#### architecture.md\r\n\r\n- Documents the system architecture by describing the structure of the system and the architecture characteristics the system must support.\r\n- Records key design principles\r\n- Lists design patterns being used\r\n- Explains relationships of components\r\n\r\n#### techstack.md\r\n\r\n- Describes technologies and frameworks being used\r\n- Documents the development setup and tool configurations\r\n- Notes known constraints\r\n\r\n#### progress.md\r\n\r\n- Tracks what works and what's left to build\r\n- Records current status of features\r\n- Lists known issues and limitations to be improved in the future\r\n\r\n### Steps\r\n\r\nThese are the mandatory steps to complete the tasks:\r\n\r\n1. Create a new folder `project-intelligence` inside the `.amazonq` folder\r\n2. Analyze the application to get a comprehensive understanding of the project\r\n3. Analyze the git history to understand the current state of development\r\n4. Create the project.md file\r\n5. Create the architecture.md file\r\n6. Create the techstack.md file\r\n7. Create the progress.md file\r\n\r\n### Output Format\r\n\r\n- All files must be formatted in markdown\r\n- Use mermaid syntax for aspects such as architecture visualizations, user flows or component relationships\r\n\r\n## Sense Check\r\n\r\nOnce you are finished, review all files to confirm that the documentation is meaningful, comprehensive and fulfills the described objective. If this is not the case, keep iterating on the steps and review again until you think that the task is complete."},"howto":{"S":"Start Q Developer in the CLI. Copy-Paste the prompt into your chat and run it. Q might ignore the final sense check. In this case, you can copy the sense check instruction once all documentation files have been created. \r\n\r\nBenefits of this documentation system:\r\n1. Persistent Context: Amazon Q Developer can now maintain knowledge about the project across sessions\r\n2. Comprehensive Understanding: The documentation covers important aspects of the project\r\n3. Structured Information: Well-organized files make it easy to find specific details\r\n4. Visual Representation: Mermaid diagrams help visualize architecture and relationships\r\n5. Up-to-date Status: Progress tracking helps understand the current state of development"},"slug":{"S":"project-intelligence-a073774b"},"createdAt":{"S":"2025-04-04T20:19:42.723Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Project Intelligence"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"10"},"updatedAt":{"S":"2025-04-04T20:19:42.723Z"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"The project intelligence documentation system transforms Amazon Q Developer from a stateless assistant into a persistent development partner by providing comprehensive context about your application."},"id":{"S":"a073774b-61af-4aa9-af3b-85e54885beb6"},"sourceURL":{"S":""},"tags":{"L":[{"S":"CLI"},{"S":"Chat"},{"S":"Documentation"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Analyze the application and generate a documentation that visualizes the component hierarchy, relationships, and key metadata. \r\n\r\nApplication Context:\r\nThis is a Next.js 15 application using React 19 with tailwind CSS and shadcn components. The application structure follows an app router with server components architecture. Components are stored inside the ./app folder. The .tsx filename extension can identify React components.\r\n\r\nDocumentation Requirements:\r\n1. General:\r\n- Add the documentation as markdown files in the ./docs folder.\r\n- Analyze in iterations folder by folder.\r\n- You must read every react component within a folder to understand the component structure.\r\n- Update the existing documentation in each iteration based on your analysis results. \r\n- Ignore files that are not react components.\r\n- Ignore files in __tests__ folders.\r\n\r\n2. Component Hierarchy Visualization\r\nCreate a mermaid flowchart diagram that shows:\r\n- Parent-child relationships between components\r\n- Logical grouping by feature using subgraphs\r\n- Clear distinction between page components and UI components:\r\n    - Rectangle: Page Components\r\n    - Rounded Rectangle: UI Components\r\n- Use color coding in the mermaid diagram to distinguish:\r\n    - Server components in blue \r\n    - Client components in yellow\r\n- Include a legend explaining the visualization conventions"},"copyCount":{"N":"0"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"instruction":{"S":"Analyze the application and generate a documentation that visualizes the component hierarchy, relationships, and key metadata. \r\n\r\nApplication Context:\r\nThis is a Next.js 15 application using React 19 with tailwind CSS and shadcn components. The application structure follows an app router with server components architecture. Components are stored inside the ./app folder. The .tsx filename extension can identify React components.\r\n\r\nDocumentation Requirements:\r\n1. General:\r\n- Add the documentation as markdown files in the ./docs folder.\r\n- Analyze in iterations folder by folder.\r\n- You must read every react component within a folder to understand the component structure.\r\n- Update the existing documentation in each iteration based on your analysis results. \r\n- Ignore files that are not react components.\r\n- Ignore files in __tests__ folders.\r\n\r\n2. Component Hierarchy Visualization\r\nCreate a mermaid flowchart diagram that shows:\r\n- Parent-child relationships between components\r\n- Logical grouping by feature using subgraphs\r\n- Clear distinction between page components and UI components:\r\n    - Rectangle: Page Components\r\n    - Rounded Rectangle: UI Components\r\n- Use color coding in the mermaid diagram to distinguish:\r\n    - Server components in blue \r\n    - Client components in yellow\r\n- Include a legend explaining the visualization conventions"},"howto":{"S":""},"slug":{"S":"react-component-tree-documentation-f022444a"},"createdAt":{"S":"2025-03-07T22:45:44.319Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"React Component Tree documentation"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-03-07T23:31:48.195Z"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Analyzes the application and generates comprehensive component tree documentation that visualizes the component hierarchy, relationships, and key metadata."},"id":{"S":"f022444a-0ce1-47af-a4b8-6800e8bae26d"},"sourceURL":{"S":""},"tags":{"L":[{"S":"CLI"},{"S":"Chat"},{"S":"Documentation"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Create a shell script to copy all data from a source DynamoDB table into a target DynamoDB table using the AWS CLI. Source and target tables are provisioned in different AWS accounts. \r\n\r\n- Use named profiles called \"source\" and \"target\" to connect to the target and source account.\r\n- Save scan results to a temporary directory\r\n- Processing each item individually"},"copyCount":{"N":"7"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"instruction":{"S":"Create a shell script to copy all data from a source DynamoDB table into a target DynamoDB table using the AWS CLI. Source and target tables are provisioned in different AWS accounts. \r\n\r\n- Use named profiles called \"source\" and \"target\" to connect to the target and source account.\r\n- Save scan results to a temporary directory\r\n- Processing each item individually"},"howto":{"S":"Open Amazon Q Developer in the CLI via `q chat`. Copy-paste the prompt into your terminal. To improve the accuracy of the output, provide samples of how the data are structured inside your DynamoDB Tables.\r\n\r\nBefore running the script, make sure to create two named profiles for source and target accounts in your AWS CLI configuration."},"slug":{"S":"copy-data-from-dynamodb-across-accounts-aa3a0ec0"},"createdAt":{"S":"2025-03-20T12:58:09.382Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Copy data from DynamoDB across accounts"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-03-20T13:39:14.523Z"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"This prompt creates a shell script to copy data from a target DynamoDB table to a source table."},"id":{"S":"aa3a0ec0-2485-4091-b227-e79202b4f173"},"sourceURL":{"S":""},"tags":{"L":[{"S":"CLI"},{"S":"Chat"},{"S":"Implement"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"@workspace generate a mermaid class diagram of my application"},"copyCount":{"N":"2"},"owner_username":{"S":"olemaitre"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"@workspace generate a mermaid class diagram of my application"},"howto":{"S":"You need a folder containing your application code (python, typescript, ...) and/or infrastructure code\r\nCopy/Paste the generated code into a markdown (.md) file, preview your markdown file (e.g. using mermaid extension in VS Code)"},"slug":{"S":"generate-mermaid-class-diagram-from-code-d2b74cc1"},"createdAt":{"S":"2024-11-04T20:08:05.306Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Generate Mermaid class diagram from code"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-03-23T16:14:30.670Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Design"},"owner":{"S":"03746802-d021-70a3-b8b8-e364eaff2b71"},"description":{"S":"Generates a mermaid class diagram as code to visualize/document the design of your application"},"id":{"S":"d2b74cc1-47e7-48d1-9424-6bcbc33f5399"},"sourceURL":{"S":"https://github.com/welcloud-io/wio-from-diagram-to-code-with-amazon-q-developer/blob/main/_playground/README.md#13---generate-class-diagram"},"tags":{"L":[{"S":"Design"},{"S":"IDE"},{"S":"Chat"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"/dev Create a html javascript app that automatically generates the required code to build a Python Lambda layer zip file. The app should allow the user to specify the Python version and the libraries to be installed.\n\nFor example, if the Python version is 3.12 and the library specification is `requests==2.32.3`, the code generated from the app should be:\n\n```bash\nmkdir test/\npyenv local 3.12\npyenv which python\n\ncat << EOF > requirements.txt\nrequests==2.32.3\nEOF\n\npython -m venv create_layer\nsource create_layer/bin/activate\npip install -r requirements.txt\nmkdir python\ncp -r create_layer/lib python/\nzip -r requests-py312.zip python\n\n# Cleanup\ndeactivate\nrm -rf create_layer/ python/\n```\n\nThe app should include a text box displaying the generated code with syntax highlighting. There should be a copy to clipboard button as well as a download button. Use shadcn and dark mode. Use a library or API, such as Snyk, to check for library vulnerabilities."},"copyCount":{"N":"7"},"owner_username":{"S":"Nathaniel Ng"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"/dev Create a html javascript app that automatically generates the required code to build a Python Lambda layer zip file. The app should allow the user to specify the Python version and the libraries to be installed.\n\nFor example, if the Python version is 3.12 and the library specification is `requests==2.32.3`, the code generated from the app should be:\n\n```bash\nmkdir test/\npyenv local 3.12\npyenv which python\n\ncat << EOF > requirements.txt\nrequests==2.32.3\nEOF\n\npython -m venv create_layer\nsource create_layer/bin/activate\npip install -r requirements.txt\nmkdir python\ncp -r create_layer/lib python/\nzip -r requests-py312.zip python\n\n# Cleanup\ndeactivate\nrm -rf create_layer/ python/\n```\n\nThe app should include a text box displaying the generated code with syntax highlighting. There should be a copy to clipboard button as well as a download button. Use shadcn and dark mode. Use a library or API, such as Snyk, to check for library vulnerabilities."},"howto":{"S":"Open the generated html file in a browser. Enter the required Python libraries and hit the copy to clipboard button. Paste the contents in a terminal window and run it. The code should generate a zip file that you can use as a Python Lambda layer. It is assumed that you have Python and pyenv running on your machine."},"slug":{"S":"python-lambda-layer-generator-3ad29455"},"createdAt":{"S":"2025-02-22T15:19:30.291Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Python Lambda Layer Generator"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-02-22T15:19:30.291Z"},"category":{"S":"Dev Agent"},"sdlc_phase":{"S":"Implement"},"owner":{"S":"google_104750774066348427416"},"description":{"S":"Creates a Lambda layer zip file, given a list of Python libraries. Checks for vulnerabilities."},"id":{"S":"3ad29455-05bf-4154-9e40-4635252d8163"},"tags":{"L":[{"S":"Implement"},{"S":"IDE"},{"S":"Dev Agent"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"/dev create a terraform project for creating an EKS cluster. Also create any VPC, subnets and other AWS resources required for this new EKS cluster. Use latest available versions of aws terraform modules. make sure the subnet can auto assign Public IP addresses. set enable_cluster_creator_admin_permissions = true. Use version 20 or higher of terraform-aws-modules/eks/aws and version 1.32 of Kubernetes . Name the EKS cluster “dev_q_eks_cluster”"},"copyCount":{"N":"4"},"owner_username":{"S":"Abhijit Karode"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"/dev create a terraform project for creating an EKS cluster. Also create any VPC, subnets and other AWS resources required for this new EKS cluster. Use latest available versions of aws terraform modules. make sure the subnet can auto assign Public IP addresses. set enable_cluster_creator_admin_permissions = true. Use version 20 or higher of terraform-aws-modules/eks/aws and version 1.32 of Kubernetes . Name the EKS cluster “dev_q_eks_cluster”"},"howto":{"S":""},"slug":{"S":"create-eks-cluster-using-aws-and-terraform-best-practices-3d1dbca7"},"createdAt":{"S":"2025-02-07T19:53:27.046Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Create EKS Cluster using aws and terraform best practices"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-02-07T19:53:27.046Z"},"category":{"S":"Dev Agent"},"sdlc_phase":{"S":"Deploy"},"owner":{"S":"google_107478502876824044700"},"description":{"S":"Multi-prompt /dev agent prompt to create a new EKS cluster "},"id":{"S":"3d1dbca7-3781-43d1-80f3-88d595ffbbb5"},"tags":{"L":[{"S":"Deploy"},{"S":"IDE"},{"S":"Dev Agent"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Analyze the application and generate documentation visualizing the component hierarchy, component relationships, and key component metadata. \r\n\r\nApplication Context:\r\nThis is a Next.js 15 application using React 19 with tailwind CSS and shadcn components. The application structure follows an app router with server components architecture. Components are stored inside the ./app folder. React components have the .tsx filename extension.\r\n\r\nDocumentation Requirements:\r\n1. General:\r\n- Add the documentation as markdown files in the ./docs folder.\r\n- Analyze in iterations folder by folder.\r\n- You must read every react component within a folder to understand the component structure.\r\n- Update the existing documentation in each iteration based on your analysis results. \r\n- Ignore files that are not react components.\r\n\r\n2. Component Hierarchy Visualization\r\nCreate a mermaid flowchart diagram that shows:\r\n- Parent-child relationships between components\r\n- Logical grouping by feature using subgraphs\r\n- Clear distinction between page components and UI components\r\n- Use color coding in the mermaid diagram to distinguish:\r\n  * Server vs Client components\r\n  * Ensure high contrast in the color coding to ensure that the text is readable\r\n- Include a legend explaining the visualization conventions"},"copyCount":{"N":"7"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"instruction":{"S":"Analyze the application and generate documentation visualizing the component hierarchy, component relationships, and key component metadata. \r\n\r\nApplication Context:\r\nThis is a Next.js 15 application using React 19 with tailwind CSS and shadcn components. The application structure follows an app router with server components architecture. Components are stored inside the ./app folder. React components have the .tsx filename extension.\r\n\r\nDocumentation Requirements:\r\n1. General:\r\n- Add the documentation as markdown files in the ./docs folder.\r\n- Analyze in iterations folder by folder.\r\n- You must read every react component within a folder to understand the component structure.\r\n- Update the existing documentation in each iteration based on your analysis results. \r\n- Ignore files that are not react components.\r\n\r\n2. Component Hierarchy Visualization\r\nCreate a mermaid flowchart diagram that shows:\r\n- Parent-child relationships between components\r\n- Logical grouping by feature using subgraphs\r\n- Clear distinction between page components and UI components\r\n- Use color coding in the mermaid diagram to distinguish:\r\n  * Server vs Client components\r\n  * Ensure high contrast in the color coding to ensure that the text is readable\r\n- Include a legend explaining the visualization conventions"},"howto":{"S":"Open your terminal and change directory to the root folder of your repository. Then start Q Developer with `q chat` and paste the prompt. You can apply additional documentation rules based on your requirements or guidelines."},"slug":{"S":"react-component-documentation-e23f7432"},"createdAt":{"S":"2025-03-10T07:59:58.594Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"React Component Documentation"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-03-10T07:59:58.594Z"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Analyzes a React-based application and generates documentation visualizing the component hierarchy, component relationships, and key component metadata."},"id":{"S":"e23f7432-b8ca-4fec-a19a-e6242ba2cdbe"},"sourceURL":{"S":""},"tags":{"L":[{"S":"CLI"},{"S":"Chat"},{"S":"Documentation"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Apply a code review of all staged files. Do not make any changes; report your review results at the end. Respect the following rules for your review:\r\n- Code is commented in hard-to-understand areas\r\n- Corresponding changes to the documentation have been made\r\n- Run the linter to prove the changes generate no new lint errors\r\n- Run unit tests to prove the change does not introduce breaking changes\r\n- Check if any dependent changes have been merged"},"copyCount":{"N":"65"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"instruction":{"S":"Apply a code review of all staged files. Do not make any changes; report your review results at the end. Respect the following rules for your review:\r\n- Code is commented in hard-to-understand areas\r\n- Corresponding changes to the documentation have been made\r\n- Run the linter to prove the changes generate no new lint errors\r\n- Run unit tests to prove the change does not introduce breaking changes\r\n- Check if any dependent changes have been merged"},"howto":{"S":"Make a change in your repository and stage all files with `git add .`. Open your terminal and change directory to the root folder of your repository. Then start Q Developer with `q chat` and paste the prompt. You can apply additional code review rules based on your guidelines."},"slug":{"S":"automated-code-review-47b4e703"},"createdAt":{"S":"2025-03-06T21:50:12.133Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Automated Code Review"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"9"},"updatedAt":{"S":"2025-03-15T21:32:56.338Z"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Let Q do a code review of your staged files before committing and pushing your changes."},"id":{"S":"47b4e703-8119-4d51-b58a-d909170d647c"},"sourceURL":{"S":""},"tags":{"L":[{"S":"CLI"},{"S":"Implement"},{"S":"Chat"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Create a project diagram using C4 model for the project in the @workspace containing system context, container diagram, component diagram, and code diagram. By the end, create a sequence diagram using PlantUML based for the @workspace code."},"copyCount":{"N":"20"},"owner_username":{"S":"Tuannl"},"starCount":{"N":"0"},"instruction":{"S":"Create a project diagram using C4 model for the project in the @workspace containing system context, container diagram, component diagram, and code diagram. By the end, create a sequence diagram using PlantUML based for the @workspace code."},"howto":{"S":""},"slug":{"S":"create-project-c4-model-bd5a5320"},"createdAt":{"S":"2025-04-11T01:28:23.271Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Create project C4 model"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-04-11T01:28:23.271Z"},"owner":{"S":"43844872-d011-70e5-88a5-4ad93bed8a41"},"description":{"S":"create C4 model diagram by PlantUML"},"id":{"S":"bd5a5320-7c3c-410c-9123-483f6fa851d0"},"sourceURL":{"S":""},"tags":{"L":[]}}
{"__typename":{"S":"prompt"},"content":{"S":"/dev Implement a user management feature that integrates with Amplify Auth and stores user profiles records in an Amazon DynamoDB table. The application is built on AWS Amplify Gen2. Here are the required changes:\r\n\r\n1. Update the `amplify/data/resource.ts` file to define a data model for the user's profile:\r\n- The user model should contain `id`, `username`, `email` and `displayName`, 'profileOwner'\r\n- Data access for the user model is configured with the owner authorization strategy allowing read-only access for the owner defined in attribute `profileOwner`.\r\n\r\n2. Create a new Amplify function resource for the post-authentication lambda function.\r\n- Create a new directory and a resource file, `amplify/auth/post-confirmation/resource.ts`. Then, define the Function with `defineFunction`\r\n- set arm64 architecture to use graviton processors\r\n- set timeout to 30 seconds\r\n- set memory to 512\r\n\r\n3. Create the lambda function handler implementation:\r\n- Create a new handler file `amplify/auth/post-authentication/handler.ts`\r\n- The handler should map attributes from the cognito event source to a DynamoDB record that maps to the user model schema\r\n- The format of the `profileOwner` attribute must be `<sub>::<username>`. \r\n- The user record should also contain a `createdAt` and `updatedAt` timestamp.\r\n- The user record should be saved directly into the DynamoDB user table\r\n- Handle errors gracefully without blocking authentication\r\n- Use environment variables for the DynamoDB table name\r\n\r\n4. Set the newly created Amplify function resource on the auth resource as a trigger.\r\n\r\n5. Modify Amplify-generated post-authentication lambda resource\r\n- Add necessary IAM permissions \r\n- Add necessary environment variables\r\n- Remember that these modifications should be made in the `amplify/backend.ts` file after the `defineBackend` call. Only Lambda functions that are part of the amplify backend can be modified."},"copyCount":{"N":"1"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"/dev Implement a user management feature that integrates with Amplify Auth and stores user profiles records in an Amazon DynamoDB table. The application is built on AWS Amplify Gen2. Here are the required changes:\r\n\r\n1. Update the `amplify/data/resource.ts` file to define a data model for the user's profile:\r\n- The user model should contain `id`, `username`, `email` and `displayName`, 'profileOwner'\r\n- Data access for the user model is configured with the owner authorization strategy allowing read-only access for the owner defined in attribute `profileOwner`.\r\n\r\n2. Create a new Amplify function resource for the post-authentication lambda function.\r\n- Create a new directory and a resource file, `amplify/auth/post-confirmation/resource.ts`. Then, define the Function with `defineFunction`\r\n- set arm64 architecture to use graviton processors\r\n- set timeout to 30 seconds\r\n- set memory to 512\r\n\r\n3. Create the lambda function handler implementation:\r\n- Create a new handler file `amplify/auth/post-authentication/handler.ts`\r\n- The handler should map attributes from the cognito event source to a DynamoDB record that maps to the user model schema\r\n- The format of the `profileOwner` attribute must be `<sub>::<username>`. \r\n- The user record should also contain a `createdAt` and `updatedAt` timestamp.\r\n- The user record should be saved directly into the DynamoDB user table\r\n- Handle errors gracefully without blocking authentication\r\n- Use environment variables for the DynamoDB table name\r\n\r\n4. Set the newly created Amplify function resource on the auth resource as a trigger.\r\n\r\n5. Modify Amplify-generated post-authentication lambda resource\r\n- Add necessary IAM permissions \r\n- Add necessary environment variables\r\n- Remember that these modifications should be made in the `amplify/backend.ts` file after the `defineBackend` call. Only Lambda functions that are part of the amplify backend can be modified."},"howto":{"S":"Copy-paste this prompt directly into your chat. This will directly start the dev agent. Once the dev-agent finished the work, review the changes. Prepare yourself for minor adjustments. The following references to the AWS Amplify Gen 2 documentation are helpful for your code-review or providing feedback to the dev agent to regenerate the implementation:\r\n\r\n- [Create a user profile record](https://docs.amplify.aws/react/build-a-backend/functions/examples/create-user-profile-record/)\r\n- [Modify Amplify-generated Lambda resources with CDK](https://docs.amplify.aws/react/build-a-backend/functions/modify-resources-with-cdk/)"},"slug":{"S":"user-management-for-aws-amplify-gen2-applications-270c7a4e"},"createdAt":{"S":"2025-01-27T19:17:16.400Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"User management for AWS Amplify Gen2 applications"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-03-06T15:46:29.520Z"},"category":{"S":"Dev Agent"},"sdlc_phase":{"S":"Implement"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"The goal of this prompt is to implement a user management feature that integrates with Amplify Auth and stores user profile records in an Amazon DynamoDb table"},"id":{"S":"270c7a4e-d866-4ac0-8ee8-0aa88931ed52"},"tags":{"L":[{"S":"Implement"},{"S":"IDE"},{"S":"Dev Agent"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Create a project diagram using C4 model for the project in the @workspace containing system context, container diagram, component diagram, and code diagram. By the end, create a sequence diagram using PlantUML based for the @workspace code."},"copyCount":{"N":"15"},"owner_username":{"S":"riribeir"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"Create a project diagram using C4 model for the project in the @workspace containing system context, container diagram, component diagram, and code diagram. By the end, create a sequence diagram using PlantUML based for the @workspace code."},"howto":{"S":""},"slug":{"S":"create-a-project-diagram-for-your-project-815a22a3"},"createdAt":{"S":"2025-01-14T14:42:00.487Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Create a project diagram for your project"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-01-14T14:42:00.487Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Documentation"},"owner":{"S":"f3442852-30d1-70d9-95e5-7e31d588b248"},"description":{"S":"Create a project diagram using PlantUML and C4 Model for your project based in your codebase"},"id":{"S":"815a22a3-0e1b-468d-b27c-0de2147b6bda"},"tags":{"L":[{"S":"Documentation"},{"S":"IDE"},{"S":"Chat"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"I would like you to build unit tests for all the functions in the app.py file. You also have to make sure they are functional and work. To do so don't try to run Python natively, please use a container image to do so. There is a Dockerfile in the root of this folder that you can use as a baseline. Feel free to change it to accommodate the need to use docker to run the tests and verify they are working properly. Iterate on the tests until they are working."},"copyCount":{"N":"3"},"owner_username":{"S":"mreferre"},"starCount":{"N":"0"},"instruction":{"S":"I would like you to build unit tests for all the functions in the app.py file. You also have to make sure they are functional and work. To do so don't try to run Python natively, please use a container image to do so. There is a Dockerfile in the root of this folder that you can use as a baseline. Feel free to change it to accommodate the need to use docker to run the tests and verify they are working properly. Iterate on the tests until they are working."},"howto":{"S":""},"slug":{"S":"create-unit-tests-in-a-container-for-a-votingapp-7ac5592d"},"createdAt":{"S":"2025-04-15T14:36:37.663Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Create unit tests (in a container) for a votingapp"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-04-15T14:36:37.663Z"},"owner":{"S":"c39478e2-40e1-70f2-1bec-0e9943f7efd8"},"description":{"S":"This prompt allows for creating unit tests for a simple Python application (https://github.com/aws-containers/votingapp). I require these unit tests to be run in a container and not on the native system. I often use this for demoing Amazon Q Developer capabilities but hopefully can inspire for other type of real usage."},"id":{"S":"7ac5592d-ba1d-4540-b6c2-71ffa4bfaa6a"},"sourceURL":{"S":""},"tags":{"L":[{"S":"CLI"},{"S":"Chat"},{"S":"Test"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"<task>\r\nYour task is to analyze the code for two services, {{Service1}} and {{Service2}}, and identify any CloudWatch metrics or alarms related specifically to {{ALARM_TYPE}} that are present in {{Service2}} but missing in {{Service1}}.\r\n</task>\r\n\r\n<instructions>\r\nTo accomplish this task, follow these steps:\r\n1. Review the code for {{Service2}}, which follows best practices for monitoring infrastructure using CloudWatch metrics and alarms. Take note of the metrics and alarms implemented specifically for {{ALARM_TYPE}}.\r\n2. Carefully examine the code for {{Service1}}.\r\n3. Compare the two code bases and identify any CloudWatch metrics and alarms specifically related to {{ALARM_TYPE}} that are implemented in {{Service2}} but not present in {{Service1}}.\r\n4. Keep in mind that metric and alarm names may be slightly different between the two code packages, but focus on the underlying functionality and severity.\r\n5. If {{Service1}} does not use {{ALARM_TYPE}}, do not list any missing metrics or alarms.\r\n</instructions>\r\n\r\nProvide your response in the following format:\r\n<rationale>\r\nProvide a list of all metrics and alarms present in {{Service2}} related to {{ALARM_TYPE}}. Treat same alarms of different severity as different. Also mention why each metric and alarm is important. Provide a code reference of where each metric and alarm is present in {{Service2}} and where it can be added in {{Service1}}.\r\n</rationale>\r\n<missing_alarms>\r\n- [First alarm or metric name], [Severity of the alarm in the form SEV_1/SEV_2/SEV_3. Use NA if not specified.], [Brief explanation about why this metric is important]\r\n- [Second alarm or metric name], [Severity of the alarm in the form SEV_1/SEV_2/SEV_3. Use NA if not specified.], [Brief explanation about why this metric is important]\r\n.\r\n.\r\n.\r\n</missing_alarms>\r\n\r\nPlease provide your response immediately after these instructions, enclosed in the <rationale></rationale> and\r\n<missing_alarms></missing_alarms> tags.\r\nThe code for {{Service2}} is presented below within <{{Service2}}></{{Service2}}> tags.\r\nThe code for {{Service1}} is presented below within <{{Service1}}></{{Service1}}> tags."},"copyCount":{"N":"0"},"owner_username":{"S":"shudabas"},"starCount":{"N":"0"},"instruction":{"S":"<task>\r\nYour task is to analyze the code for two services, {{Service1}} and {{Service2}}, and identify any CloudWatch metrics or alarms related specifically to {{ALARM_TYPE}} that are present in {{Service2}} but missing in {{Service1}}.\r\n</task>\r\n\r\n<instructions>\r\nTo accomplish this task, follow these steps:\r\n1. Review the code for {{Service2}}, which follows best practices for monitoring infrastructure using CloudWatch metrics and alarms. Take note of the metrics and alarms implemented specifically for {{ALARM_TYPE}}.\r\n2. Carefully examine the code for {{Service1}}.\r\n3. Compare the two code bases and identify any CloudWatch metrics and alarms specifically related to {{ALARM_TYPE}} that are implemented in {{Service2}} but not present in {{Service1}}.\r\n4. Keep in mind that metric and alarm names may be slightly different between the two code packages, but focus on the underlying functionality and severity.\r\n5. If {{Service1}} does not use {{ALARM_TYPE}}, do not list any missing metrics or alarms.\r\n</instructions>\r\n\r\nProvide your response in the following format:\r\n<rationale>\r\nProvide a list of all metrics and alarms present in {{Service2}} related to {{ALARM_TYPE}}. Treat same alarms of different severity as different. Also mention why each metric and alarm is important. Provide a code reference of where each metric and alarm is present in {{Service2}} and where it can be added in {{Service1}}.\r\n</rationale>\r\n<missing_alarms>\r\n- [First alarm or metric name], [Severity of the alarm in the form SEV_1/SEV_2/SEV_3. Use NA if not specified.], [Brief explanation about why this metric is important]\r\n- [Second alarm or metric name], [Severity of the alarm in the form SEV_1/SEV_2/SEV_3. Use NA if not specified.], [Brief explanation about why this metric is important]\r\n.\r\n.\r\n.\r\n</missing_alarms>\r\n\r\nPlease provide your response immediately after these instructions, enclosed in the <rationale></rationale> and\r\n<missing_alarms></missing_alarms> tags.\r\nThe code for {{Service2}} is presented below within <{{Service2}}></{{Service2}}> tags.\r\nThe code for {{Service1}} is presented below within <{{Service1}}></{{Service1}}> tags."},"howto":{"S":"{{Service1}} is the target package name, for which missing alarms and metrics need to be identified.\r\n{{Service2}} is the reference package name, which follows best practices for resource monitoring.\r\n{{ALARM_TYPE}} is the AWS resource type. E.g. AWS API Gateway.\r\nThe code for the reference and target packages need to be converted to a structured format and appended to the prompt.\r\n\r\nUtility to convert code packages to a structured format: packages/GenAICDKAnalyzer/blobs/mainline/--/codebase_to_text.py\r\nSample usage of the utility: packages/GenAICDKAnalyzer/blobs/6aec4cd1b96c975dff5f1a8950b1b0ab70be7399/--/main.py#L184"},"slug":{"S":"identifying-metrics-alarms-related-to-aws-resources-342fe6c9"},"createdAt":{"S":"2025-03-13T06:03:24.224Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Identifying metrics/alarms related to AWS Resources"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-03-17T11:05:46.517Z"},"owner":{"S":"23546802-8051-7065-df4e-cf55f4fd7dc4"},"description":{"S":"This prompt aims to identify missing metrics/alarms related to AWS Resources in a target package. A reference package is used to limit the response to required metrics/alarms, assuming it follows best practices for the particular resource type setup."},"id":{"S":"342fe6c9-0c5c-445d-8b34-b096d22553da"},"sourceURL":{"S":""},"tags":{"L":[]}}
{"__typename":{"S":"prompt"},"content":{"S":"/dev Create a Javascript app that takes a QR code from the clipboard and converts it to a URL. Use a library or API if needed. Use dark mode. Add buttons to open the URL and to copy the URL to clipboard."},"copyCount":{"N":"4"},"owner_username":{"S":"Nathaniel Ng"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"/dev Create a Javascript app that takes a QR code from the clipboard and converts it to a URL. Use a library or API if needed. Use dark mode. Add buttons to open the URL and to copy the URL to clipboard."},"howto":{"S":""},"slug":{"S":"qr-code-to-url-1a3e9ec9"},"createdAt":{"S":"2025-02-22T15:08:01.980Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"QR code to URL"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-02-22T15:08:01.980Z"},"category":{"S":"Dev Agent"},"sdlc_phase":{"S":"Implement"},"owner":{"S":"google_104750774066348427416"},"description":{"S":"Take the QR code from the clipboard and convert it to a URL."},"id":{"S":"1a3e9ec9-e4eb-4446-9506-c502f876e6b1"},"tags":{"L":[{"S":"Implement"},{"S":"IDE"},{"S":"Dev Agent"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Your task is to assist me in preparing a GitHub pull request for this branch. To complete the task, you must\r\n- Create and analyze the diff of this branch compared to the main branch to understand all changes that were made\r\n- Read the pull request template of this repository.\r\n- Write a meaningful pull request description that captures the intention of the change based on the created diff.\r\n\r\nYour goal is to create a new pull request on GitHub so that the change can be reviewed."},"copyCount":{"N":"9"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"instruction":{"S":"Your task is to assist me in preparing a GitHub pull request for this branch. To complete the task, you must\r\n- Create and analyze the diff of this branch compared to the main branch to understand all changes that were made\r\n- Read the pull request template of this repository.\r\n- Write a meaningful pull request description that captures the intention of the change based on the created diff.\r\n\r\nYour goal is to create a new pull request on GitHub so that the change can be reviewed."},"howto":{"S":"- Install the official Github MCP server.\r\n- Start Q Developer in the CLI.\r\n- If you have an existing pull request template, add it to the context via \"/context add\".\r\n- Run the prompt."},"slug":{"S":"github-pull-requests-38c933f9"},"createdAt":{"S":"2025-05-23T09:42:28.829Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Github Pull Requests"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-06-07T22:00:43.714Z"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Automate the creation of Github pull requests."},"id":{"S":"38c933f9-b47b-4d25-93e0-5c102946eb93"},"sourceURL":{"NULL":true},"tags":{"L":[{"S":"CLI"},{"S":"Chat"}]}}
{"content":{"S":"You are acting as a UX designer. Your task is to generate one realistic user persona per customer type. For each persona, include:\r\n- Name: [A name for the persona]\r\n- Demographics: [Age, gender, occupation, location, etc.]\r\n- Goals: [What are their primary objectives when using the product?]\r\n- Motivations: [What drives them? What are their needs and desires?]\r\n- Pain Points: [What challenges or frustrations do they face?]\r\n- Activities: [What are their typical daily activities and routines?]\r\n- Notable Quotes: [What are some things they might say related to the product?]"},"copyCount":{"N":"5"},"starCount":{"N":"0"},"instruction":{"S":"You are acting as a UX designer. Your task is to generate one realistic user persona per customer type. For each persona, include:\r\n- Name: [A name for the persona]\r\n- Demographics: [Age, gender, occupation, location, etc.]\r\n- Goals: [What are their primary objectives when using the product?]\r\n- Motivations: [What drives them? What are their needs and desires?]\r\n- Pain Points: [What challenges or frustrations do they face?]\r\n- Activities: [What are their typical daily activities and routines?]\r\n- Notable Quotes: [What are some things they might say related to the product?]"},"howto":{"NULL":true},"slug":{"S":"create-user-personas-5fe8fd8b"},"createdAt":{"S":"2025-06-24T12:42:31.717Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Create User Personas"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-06-24T12:45:10.854Z"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Generates realistic user personas based on your existing documentation or customer descriptions."},"id":{"S":"5fe8fd8b-8796-41af-ab38-71b62b64c0b3"},"sourceURL":{"NULL":true},"tags":{"L":[{"S":"CLI"},{"S":"Chat"},{"S":"Design"},{"S":"Plan"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"@workspace I am working on a lambda function that will be triggered by a s3 put object event. Object put to s3 bucket will be raw requirement from client/user. The lambda function will process the .doc or .pdf files and send to Claude 3.5 sonnect v2 and transfer the requiement document to one or multiple issues that can assign to developers.\n\nThis is good. I would like to use claude 3.5 sonnet v2 in amazon bedrock. converse API is preferred.\n\nThis looks great. Now, I would prefer to achieve exactly same with AWS Step function, use as much direct integration in step function when you invoke other service, e.g., invoke Claude 3.5 sonnet v2 in Amazon Bedrock. I would prefer you provide me a CDK script in typescirpt. I prefer python for Lambda function in the statemachine of step function.\n\nI don't want to use textract. I would prefer give the document to the large language model in Bedrock.\n\nthis is wrong. Here is a sample of invoke bedrock model in stepfunction:\n```\nimport * as bedrock from 'aws-cdk-lib/aws-bedrock';\n\nconst model = bedrock.FoundationModel.fromFoundationModelId(\n  this,\n  'Model',\n  bedrock.FoundationModelIdentifier.AMAZON_TITAN_TEXT_G1_EXPRESS_V1,\n);\n\nconst task = new tasks.BedrockInvokeModel(this, 'Prompt Model', {\n  model,\n  body: sfn.TaskInput.fromObject(\n    {\n      inputText: 'Generate a list of five first names.',\n      textGenerationConfig: {\n        maxTokenCount: 100,\n        temperature: 1,\n      },\n    },\n  ),\n  resultSelector: {\n    names: sfn.JsonPath.stringAt('$.Body.results[0].outputText'),\n  },\n});\n```\nPlease consider use the same function and method.\n\n2 more issues here:\n\non stateMachine, you use addCatch on sfn.chain.\n\ns3.SfnDestination doesn't exist. To trigger a stepfunction statemachin, you need to use another lambda. s3-> lambda -> StepFunction\n\nGood! Now give me the document reader lambda function\n\ngood. But boto3 is a embedded lib in lambda, you don't need to put to requirement.txt\n\nGood! Now generate github_issue_creator lambda function\n\nagain, request is included in lambda as default, you don't need to add to requirements.txt file\n\nI have below warrnings when I execute cdk ls:\n```\n[WARNING] aws-cdk-lib.aws_stepfunctions.MapProps#parameters is deprecated.\nStep Functions has deprecated the parameters field in favor of\nthe new itemSelector field\nThis API will be removed in the next major release.\n[WARNING] aws-cdk-lib.aws_stepfunctions.Map#iterator is deprecated.\nuse itemProcessor instead. This API will be removed in the next major release. [WARNING] aws-cdk-lib.aws_stepfunctions.StateMachineProps#definition is deprecated. use definitionBody: DefinitionBody.fromChainable() This API will be removed in the next major release. [WARNING] aws-cdk-lib.aws_stepfunctions.StateMachineProps#definition is deprecated. use definitionBody: DefinitionBody.fromChainable() This API will be removed in the next major release.\n```\nAnd I preferred python version 12 on my lambda functions\n\nThe way you using itemProcessor is wrong. Here is an working sample. Please correct it:\n```\nconst map = new sfn.Map(this, 'Map State', {\n  maxConcurrency: 1,\n  itemsPath: sfn.JsonPath.stringAt('$.inputForMap'),\n  itemSelector: {\n    item: sfn.JsonPath.stringAt('$$.Map.Item.Value'),\n  },\n  resultPath: '$.mapOutput',\n});\n\n// The Map iterator can contain a IChainable, which can be an individual or multiple steps chained together.\n// Below example is with a Choice and Pass step\nconst choice = new sfn.Choice(this, 'Choice');\nconst condition1 = sfn.Condition.stringEquals('$.item.status', 'SUCCESS');\nconst step1 = new sfn.Pass(this, 'Step1');\nconst step2 = new sfn.Pass(this, 'Step2');\nconst finish = new sfn.Pass(this, 'Finish');\n\nconst definition = choice\n    .when(condition1, step1)\n    .otherwise(step2)\n    .afterwards()\n    .next(finish);\n\nmap.itemProcessor(definition);\n```"},"copyCount":{"N":"2"},"owner_username":{"S":"Stan Fan"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"@workspace I am working on a lambda function that will be triggered by a s3 put object event. Object put to s3 bucket will be raw requirement from client/user. The lambda function will process the .doc or .pdf files and send to Claude 3.5 sonnect v2 and transfer the requiement document to one or multiple issues that can assign to developers.\n\nThis is good. I would like to use claude 3.5 sonnet v2 in amazon bedrock. converse API is preferred.\n\nThis looks great. Now, I would prefer to achieve exactly same with AWS Step function, use as much direct integration in step function when you invoke other service, e.g., invoke Claude 3.5 sonnet v2 in Amazon Bedrock. I would prefer you provide me a CDK script in typescirpt. I prefer python for Lambda function in the statemachine of step function.\n\nI don't want to use textract. I would prefer give the document to the large language model in Bedrock.\n\nthis is wrong. Here is a sample of invoke bedrock model in stepfunction:\n```\nimport * as bedrock from 'aws-cdk-lib/aws-bedrock';\n\nconst model = bedrock.FoundationModel.fromFoundationModelId(\n  this,\n  'Model',\n  bedrock.FoundationModelIdentifier.AMAZON_TITAN_TEXT_G1_EXPRESS_V1,\n);\n\nconst task = new tasks.BedrockInvokeModel(this, 'Prompt Model', {\n  model,\n  body: sfn.TaskInput.fromObject(\n    {\n      inputText: 'Generate a list of five first names.',\n      textGenerationConfig: {\n        maxTokenCount: 100,\n        temperature: 1,\n      },\n    },\n  ),\n  resultSelector: {\n    names: sfn.JsonPath.stringAt('$.Body.results[0].outputText'),\n  },\n});\n```\nPlease consider use the same function and method.\n\n2 more issues here:\n\non stateMachine, you use addCatch on sfn.chain.\n\ns3.SfnDestination doesn't exist. To trigger a stepfunction statemachin, you need to use another lambda. s3-> lambda -> StepFunction\n\nGood! Now give me the document reader lambda function\n\ngood. But boto3 is a embedded lib in lambda, you don't need to put to requirement.txt\n\nGood! Now generate github_issue_creator lambda function\n\nagain, request is included in lambda as default, you don't need to add to requirements.txt file\n\nI have below warrnings when I execute cdk ls:\n```\n[WARNING] aws-cdk-lib.aws_stepfunctions.MapProps#parameters is deprecated.\nStep Functions has deprecated the parameters field in favor of\nthe new itemSelector field\nThis API will be removed in the next major release.\n[WARNING] aws-cdk-lib.aws_stepfunctions.Map#iterator is deprecated.\nuse itemProcessor instead. This API will be removed in the next major release. [WARNING] aws-cdk-lib.aws_stepfunctions.StateMachineProps#definition is deprecated. use definitionBody: DefinitionBody.fromChainable() This API will be removed in the next major release. [WARNING] aws-cdk-lib.aws_stepfunctions.StateMachineProps#definition is deprecated. use definitionBody: DefinitionBody.fromChainable() This API will be removed in the next major release.\n```\nAnd I preferred python version 12 on my lambda functions\n\nThe way you using itemProcessor is wrong. Here is an working sample. Please correct it:\n```\nconst map = new sfn.Map(this, 'Map State', {\n  maxConcurrency: 1,\n  itemsPath: sfn.JsonPath.stringAt('$.inputForMap'),\n  itemSelector: {\n    item: sfn.JsonPath.stringAt('$$.Map.Item.Value'),\n  },\n  resultPath: '$.mapOutput',\n});\n\n// The Map iterator can contain a IChainable, which can be an individual or multiple steps chained together.\n// Below example is with a Choice and Pass step\nconst choice = new sfn.Choice(this, 'Choice');\nconst condition1 = sfn.Condition.stringEquals('$.item.status', 'SUCCESS');\nconst step1 = new sfn.Pass(this, 'Step1');\nconst step2 = new sfn.Pass(this, 'Step2');\nconst finish = new sfn.Pass(this, 'Finish');\n\nconst definition = choice\n    .when(condition1, step1)\n    .otherwise(step2)\n    .afterwards()\n    .next(finish);\n\nmap.itemProcessor(definition);\n```"},"howto":{"S":""},"slug":{"S":"requirement-to-issue-stepfunction-efcb913e"},"createdAt":{"S":"2025-02-21T04:25:48.300Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"requirement-to-issue-stepfunction"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-02-21T04:40:26.451Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Unknown"},"owner":{"S":"d3f458c2-0021-70c8-ff35-3c434c6e1381"},"description":{"S":"Requirement from client user to github issue, with step function and lambda "},"id":{"S":"efcb913e-c4c0-43db-8b37-e88976e4ea0b"},"tags":{"L":[{"S":"Unknown"},{"S":"IDE"},{"S":"Chat"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"You are acting as an experienced AWS Solutions Architect. Your task is to design a technical solution that aligns business requirements with scalable, efficient cloud solutions.\r\n\r\nTo complete the task you must\r\n- read relevant documentation about the business context in @file \r\n- read relevant documentation about the current system @file \r\n- ask relevant questions until you gather all functional and non-functional requirements.\r\n- ask questions until you identified the architectural characteristics of the solution.\r\n\r\nYour goal is to create a solution design document that contains\r\n- a description of functional and non-functional requirements the solution fulfills,\r\n- information about the architecture characteristics the system supports,\r\n- a visualization of the structure of the system and its components,\r\n- design principles used to guide development teams during the implementation,\r\n- trade-offs and explanations of architectural decisions you made.\r\n\r\nThe desired format of the document is a Markdown file. Your solution design must adhere to the best practices described in the AWS Well-Architected Framework."},"copyCount":{"N":"52"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"You are acting as an experienced AWS Solutions Architect. Your task is to design a technical solution that aligns business requirements with scalable, efficient cloud solutions.\r\n\r\nTo complete the task you must\r\n- read relevant documentation about the business context in @file \r\n- read relevant documentation about the current system @file \r\n- ask relevant questions until you gather all functional and non-functional requirements.\r\n- ask questions until you identified the architectural characteristics of the solution.\r\n\r\nYour goal is to create a solution design document that contains\r\n- a description of functional and non-functional requirements the solution fulfills,\r\n- information about the architecture characteristics the system supports,\r\n- a visualization of the structure of the system and its components,\r\n- design principles used to guide development teams during the implementation,\r\n- trade-offs and explanations of architectural decisions you made.\r\n\r\nThe desired format of the document is a Markdown file. Your solution design must adhere to the best practices described in the AWS Well-Architected Framework."},"howto":{"S":"Open a new chat and copy-paste the prompt as your first input in a blank conversation. To improve the accuracy and relevancy of the discussion with Q, ensure that documentation is added as markdown files and add them to the implicit context using the @ shortcut. Once you have done it, let the discussion flow 😉"},"slug":{"S":"solution-design-0b275af7"},"createdAt":{"S":"2025-02-07T12:37:44.310Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Solution Design"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"2"},"updatedAt":{"S":"2025-03-27T16:17:26.790Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Design"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Turn Amazon Q Developer into an AWS Solutions Architect that guides you to create a solution design document."},"id":{"S":"0b275af7-efe5-40a1-84aa-7d01d29a428e"},"sourceURL":{"S":""},"tags":{"L":[{"S":"Design"},{"S":"IDE"},{"S":"Chat"}]}}
{"content":{"S":"You are a senior .NET software engineer and code reviewer. \r\nYour task is to review the pull requests on the current local feature branch of this service.\r\n\r\nTo doing that you must\r\n- Scan and comparing the changes between the current local feature branches of the project and its submodule with the corresponding main branches.\r\n- Read all files inside the /Users/louisnguyen/Desktop/Workspace/myconnect-addresses/.amazonq folder to understand the project context.\r\n\r\nThe goals are:\r\n- Don't make any code changes.\r\n- Give a report in .md format which covers below checking on the PR:\r\n\r\n1. **High‑level summary**  \r\n   - Summarize the intent of these changes.  \r\n   - Note any architectural or design‑level implications.\r\n\r\n2. **Code quality & style**  \r\n   - Check adherence to C#/.NET naming conventions.  \r\n   - Ensure methods and classes follow SOLID principles.  \r\n   - Highlight any overly complex or duplicated code.\r\n\r\n3. **Best practices & patterns**  \r\n   - Verify proper use of Dependency Injection (services, lifetimes).  \r\n   - Check async/await usage for potential deadlocks or performance issues.  \r\n   - Confirm that Entity Framework (or other ORMs) is used correctly (e.g., no un‐tracked queries, correct use of `AsNoTracking`, parameterized queries).\r\n\r\n4. **Performance & scalability**  \r\n   - Identify any inefficient algorithms or excessive allocations.  \r\n   - Look for unbounded collections, blocking I/O, or missing pagination.  \r\n   - Suggest caching or batching where appropriate.\r\n\r\n5. **Security**  \r\n   - Scan for potential SQL injection, XSS, CSRF, or insecure deserialization.  \r\n   - Verify authentication/authorization checks (e.g., `[Authorize]` attributes, JWT scopes).  \r\n   - Ensure sensitive data isn’t logged or exposed.\r\n\r\n6. **Error handling & logging**  \r\n   - Check for consistent use of try/catch and meaningful exception messages.  \r\n   - Confirm that logging is used appropriately (no sensitive info, correct log levels).\r\n\r\n7. **Testing**  \r\n   - Identify areas lacking unit/integration tests.  \r\n   - Suggest edge cases or scenarios that need coverage.  \r\n   - Verify that existing tests are meaningful and pass.\r\n\r\n8. **Documentation & maintainability**  \r\n   - Ensure public methods have XML comments where necessary.  \r\n   - Check that README or API docs are updated to reflect new behavior.  \r\n   - Note any TODOs or commented‐out code that should be addressed.\r\n\r\nAfter reviewing, provide:\r\n- A numbered list of **critical** issues that must be fixed before merging,\r\n- A second list of **suggestions** for future improvements,\r\n- And finally an overall approval recommendation (“Approve as–is,” “Approve with minor changes,” or “Request changes”)."},"copyCount":{"N":"2"},"starCount":{"N":"0"},"instruction":{"S":"You are a senior .NET software engineer and code reviewer. \r\nYour task is to review the pull requests on the current local feature branch name \"feature/IT-7101-SupportBothLayouts\"of this service and the pull request inside the submodule /Users/louisnguyen/Desktop/Workspace/myconnect-addresses/common which in the branch \"feature/IT-7101-SupportBothLayouts\".\r\n\r\nTo doing that you must\r\n- Scan and comparing the changes between the current local feature branches of the project and its submodule with the corresponding main branches.\r\n- Read all files inside the /Users/louisnguyen/Desktop/Workspace/myconnect-addresses/.amazonq folder to understand the project context.\r\n\r\nThe goals are:\r\n- Don't make any code changes.\r\n- Give a report in .md format which covers below checking on the PR:\r\n\r\n1. **High‑level summary**  \r\n   - Summarize the intent of these changes.  \r\n   - Note any architectural or design‑level implications.\r\n\r\n2. **Code quality & style**  \r\n   - Check adherence to C#/.NET naming conventions.  \r\n   - Ensure methods and classes follow SOLID principles.  \r\n   - Highlight any overly complex or duplicated code.\r\n\r\n3. **Best practices & patterns**  \r\n   - Verify proper use of Dependency Injection (services, lifetimes).  \r\n   - Check async/await usage for potential deadlocks or performance issues.  \r\n   - Confirm that Entity Framework (or other ORMs) is used correctly (e.g., no un‐tracked queries, correct use of `AsNoTracking`, parameterized queries).\r\n\r\n4. **Performance & scalability**  \r\n   - Identify any inefficient algorithms or excessive allocations.  \r\n   - Look for unbounded collections, blocking I/O, or missing pagination.  \r\n   - Suggest caching or batching where appropriate.\r\n\r\n5. **Security**  \r\n   - Scan for potential SQL injection, XSS, CSRF, or insecure deserialization.  \r\n   - Verify authentication/authorization checks (e.g., `[Authorize]` attributes, JWT scopes).  \r\n   - Ensure sensitive data isn’t logged or exposed.\r\n\r\n6. **Error handling & logging**  \r\n   - Check for consistent use of try/catch and meaningful exception messages.  \r\n   - Confirm that logging is used appropriately (no sensitive info, correct log levels).\r\n\r\n7. **Testing**  \r\n   - Identify areas lacking unit/integration tests.  \r\n   - Suggest edge cases or scenarios that need coverage.  \r\n   - Verify that existing tests are meaningful and pass.\r\n\r\n8. **Documentation & maintainability**  \r\n   - Ensure public methods have XML comments where necessary.  \r\n   - Check that README or API docs are updated to reflect new behavior.  \r\n   - Note any TODOs or commented‐out code that should be addressed.\r\n\r\nAfter reviewing, provide:\r\n- A numbered list of **critical** issues that must be fixed before merging,\r\n- A second list of **suggestions** for future improvements,\r\n- And finally an overall approval recommendation (“Approve as–is,” “Approve with minor changes,” or “Request changes”)."},"howto":{"S":""},"slug":{"S":"review-pr-1565c8a6"},"createdAt":{"S":"2025-07-29T12:16:28.240Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Review PR"},"updatedAt":{"S":"2025-09-03T06:07:37.417Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Review a Pull Request"},"id":{"S":"1565c8a6-cb0d-415d-b7d7-e4dddcf1c196"},"sourceURL":{"S":""},"tags":{"L":[]}}
{"__typename":{"S":"prompt"},"content":{"S":"You are acting as a Senior Frontend Engineer with deep experience in\n- typescript,\n- the react and next.js framework,\n- domain-driven design, and\n- Amplify Gen2\n\nYour task is to assist me in all frontend-related tasks and questions.\nIf a question, or task is unclear, ask clarifying questions instead of jumping to conclusions. "},"copyCount":{"N":"5"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"You are acting as a Senior Frontend Engineer with deep experience in\n- typescript,\n- the react and next.js framework,\n- domain-driven design, and\n- Amplify Gen2\n\nYour task is to assist me in all frontend-related tasks and questions.\nIf a question, or task is unclear, ask clarifying questions instead of jumping to conclusions. "},"howto":{"S":""},"slug":{"S":"senior-react-engineer-2b0aac66"},"createdAt":{"S":"2024-11-10T14:56:19.714Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Senior React Engineer"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-02-06T14:06:31.627Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Design"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Let Amazon Q Developer act as a Senior Engineer with deep experience in a defined area, asking clarifying questions instead of jumping into conclusions. "},"id":{"S":"2b0aac66-1316-458e-8df3-3b4a5cac2de6"},"tags":{"L":[{"S":"Design"},{"S":"IDE"},{"S":"Chat"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"/dev Create a GitHub Actions workflow file that runs on pull requests targeting the {{branch-name}} branch. The workflow should:\n- Include concurrency controls to cancel outdated workflow runs.\n- Restrict permissions to the minimum required.\n- Add Timeout Limits to prevent hanging jobs.\n- Run on ubuntu-latest.\n- Use the latest stable {{runtime}} version.\n- Implement dependency caching with a specific cache-dependency-path to minimize execution time\n- Combine lint and test into a single 'verify' job to reduce setup overhead."},"copyCount":{"N":"0"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"/dev Create a GitHub Actions workflow file that runs on pull requests targeting the {{branch-name}} branch. The workflow should:\n- Include concurrency controls to cancel outdated workflow runs.\n- Restrict permissions to the minimum required.\n- Add Timeout Limits to prevent hanging jobs.\n- Run on ubuntu-latest.\n- Use the latest stable {{runtime}} version.\n- Implement dependency caching with a specific cache-dependency-path to minimize execution time\n- Combine lint and test into a single 'verify' job to reduce setup overhead."},"howto":{"S":""},"slug":{"S":"github-actions-pull-request-workflow-d748c1c3"},"createdAt":{"S":"2024-11-21T22:45:28.393Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Github Actions pull request workflow"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"1"},"updatedAt":{"S":"2024-11-21T22:47:44.734Z"},"category":{"S":"Dev Agent"},"sdlc_phase":{"S":"Deploy"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Creates a pull request workflow template for Github Actions"},"id":{"S":"d748c1c3-9c30-4ccb-b646-d6021b714e37"},"tags":{"L":[{"S":"Deploy"},{"S":"IDE"},{"S":"Dev Agent"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Generate a list of creative, engaging, and catchy titles for my document. The titles should align with the theme and purpose of the content, making it appealing and attention-grabbing."},"copyCount":{"N":"0"},"owner_username":{"S":"Adit Modi"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"Generate a list of creative, engaging, and catchy titles for my document. The titles should align with the theme and purpose of the content, making it appealing and attention-grabbing."},"howto":{"S":""},"slug":{"S":"adit-s-prompt-for-generating-titles-deb92450"},"createdAt":{"S":"2024-12-21T07:24:25.139Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Adit's Prompt for Generating Titles"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2024-12-21T07:25:15.874Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Design"},"owner":{"S":"google_111024591937499222111"},"description":{"S":"The prompt is useful for generating catchy titles"},"id":{"S":"deb92450-5c3e-4fd4-8d73-cc0dd3ce5748"},"tags":{"L":[{"S":"Design"},{"S":"IDE"},{"S":"Chat"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Collect information on the <Library / Framework Name> whose documentation is available here: <URL>. \r\nUse your execute tool and your knowledge of the unix commands to navigate this website. \r\nStart by analyzing the structure of the website. \r\nContinue by researching information about: <List of topics>. \r\nCollect both code and documentation. \r\nWrite the result into a markdown file called <filename>.md"},"copyCount":{"N":"5"},"owner_username":{"S":"JFL"},"starCount":{"N":"0"},"instruction":{"S":"Collect information on the <Library / Framework Name> whose documentation is available here: <URL>. \r\nUse your execute tool and your knowledge of the unix commands to navigate this website. \r\nStart by analyzing the structure of the website. \r\nContinue by researching information about: <List of topics>. \r\nCollect both code and documentation. \r\nWrite the result into a markdown file called <filename>.md"},"howto":{"S":"Use this prompt with Amazon Q Developer CLI Chat.\r\nThen put the file in the context of the CLI using the command: /context add <filename>.md.\r\nFinally trigger a prompt to develop something given this new context.\r\nHere is demo blog post on this prompt: https://www.linkedin.com/posts/jeffelandreau_amazonqdeveloper-strands-generativeai-activity-7332856467667992576-A5NK."},"slug":{"S":"prompt-to-send-q-cli-chat-to-do-research-on-recent-libraries-for-you-9f8c0709"},"createdAt":{"S":"2025-05-29T12:22:12.627Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Prompt to send Q CLI Chat to do research on recent libraries for you."},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-05-29T12:25:06.062Z"},"owner":{"S":"a3e4b8a2-30d1-70bc-5a03-cd756eafaea6"},"description":{"S":"Prompt to send Q CLI Chat to do research on recent libraries for you."},"id":{"S":"9f8c0709-753d-4dc8-b368-ab8df3025e16"},"sourceURL":{"S":""},"tags":{"L":[{"S":"CLI"},{"S":"Doc Agent"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Generate comprehensive JUnit 5 tests for the selected Java code/function/class using best practices and design patterns.\r\n\r\nKey requirements:\r\n1. Test Structure\r\n- Use @DisplayName for clear test descriptions\r\n- Implement @Nested classes for logical test grouping\r\n- Follow AAA pattern (Arrange-Act-Assert)\r\n- Include edge cases and boundary conditions\r\n\r\n2. Test Coverage Requirements\r\n- Happy path scenarios\r\n- Error/exception scenarios\r\n- Null/empty input handling\r\n- Boundary value analysis\r\n- Invalid input validation\r\n- Concurrency scenarios (if applicable)\r\n\r\n3. Parameterization Guidelines\r\n- Use @ParameterizedTest for similar test cases\r\n- Implement @CsvSource for simple data inputs\r\n- Use @MethodSource for complex test data\r\n- Include @ValueSource where applicable\r\n\r\n4. Mocking Strategy\r\n- Define mock behavior for dependencies\r\n- Use @Mock and @InjectMocks appropriately\r\n- Handle external service dependencies\r\n\r\n5. Test Data Management\r\n- Create test data factories/builders\r\n- Implement @BeforeEach/@AfterEach for setup/cleanup\r\n- Use meaningful test data that reflects real scenarios"},"copyCount":{"N":"41"},"owner_username":{"S":"Vinay Nadig"},"starCount":{"N":"2"},"instruction":{"S":"Generate comprehensive JUnit 5 tests for the selected Java code/function/class using best practices and design patterns.\r\n\r\nKey requirements:\r\n1. Test Structure\r\n- Use @DisplayName for clear test descriptions\r\n- Implement @Nested classes for logical test grouping\r\n- Follow AAA pattern (Arrange-Act-Assert)\r\n- Include edge cases and boundary conditions\r\n\r\n2. Test Coverage Requirements\r\n- Happy path scenarios\r\n- Error/exception scenarios\r\n- Null/empty input handling\r\n- Boundary value analysis\r\n- Invalid input validation\r\n- Concurrency scenarios (if applicable)\r\n\r\n3. Parameterization Guidelines\r\n- Use @ParameterizedTest for similar test cases\r\n- Implement @CsvSource for simple data inputs\r\n- Use @MethodSource for complex test data\r\n- Include @ValueSource where applicable\r\n\r\n4. Mocking Strategy\r\n- Define mock behavior for dependencies\r\n- Use @Mock and @InjectMocks appropriately\r\n- Handle external service dependencies\r\n\r\n5. Test Data Management\r\n- Create test data factories/builders\r\n- Implement @BeforeEach/@AfterEach for setup/cleanup\r\n- Use meaningful test data that reflects real scenarios"},"howto":{"S":""},"slug":{"S":"parameterize-like-a-pro-generating-junit-5-tests-d819b79b"},"createdAt":{"S":"2025-03-19T02:29:48.087Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Parameterize Like a Pro: Generating JUnit 5 Tests\""},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"2"},"updatedAt":{"S":"2025-03-19T02:29:48.087Z"},"owner":{"S":"google_101017001478424673799"},"description":{"S":"Generate comprehensive JUnit 5 tests for the selected Java code/function/class using best practices and design patterns."},"id":{"S":"d819b79b-b580-46d6-b475-1920d6b5b067"},"sourceURL":{"S":""},"tags":{"L":[{"S":"IDE"},{"S":"CLI"},{"S":"Chat"},{"S":"Dev Agent"},{"S":"Test"}]}}
{"content":{"S":"You are acting as an experienced software engineer and AWS solution architecture expert:\r\n\r\nYour task is to \r\n\r\n- Review the deployment script and cloud templates on this project to verify if there's any issue when we run the deployment. \r\n\r\n- Create a review report in .md file with checking details on problems, risks, vulnerabilities of the deployment plan. \r\n\r\nTo doing that you must\r\n- Read README.md, DEPLOYMENT-GUIDE.md, all deployment scripts and template files to understand the deployment plan.\r\n- Connect to AWS using command: aws sso login --profile my-sso-profile to verify the infrastructure status.\r\n- Check the parameters and configuration to use for the deployment script on each step.\r\n- Checking and test each deployment step to verify if the infrastructure has been created correctly and working.\r\n- Ask for confirm before apply any changes of the templates or deploymennt script. Don't make any other infrastructure changes or code changes without acknowledge me.\r\n\r\nThe goals are:\r\n- The document should be in .md format, well-structured with clear sections.\r\n- Dont' make any code changes or edit the existing codes of this project"},"copyCount":{"N":"1"},"starCount":{"N":"0"},"instruction":{"S":"You are acting as an experienced software engineer and AWS solution architecture expert:\r\n\r\nYour task is to \r\n\r\n- Review the deployment script and cloud templates on this project to verify if there's any issue when we run the deployment. \r\n\r\n- Create a review report in .md file with checking details on problems, risks, vulnerabilities of the deployment plan. \r\n\r\nTo doing that you must\r\n- Read README.md, DEPLOYMENT-GUIDE.md, all deployment scripts and template files to understand the deployment plan.\r\n- Connect to AWS using command: aws sso login --profile my-sso-profile to verify the infrastructure status.\r\n- Check the parameters and configuration to use for the deployment script on each step.\r\n- Checking and test each deployment step to verify if the infrastructure has been created correctly and working.\r\n- Ask for confirm before apply any changes of the templates or deploymennt script. Don't make any other infrastructure changes or code changes without acknowledge me.\r\n\r\nThe goals are:\r\n- The document should be in .md format, well-structured with clear sections.\r\n- Dont' make any code changes or edit the existing codes of this project"},"howto":{"NULL":true},"slug":{"S":"review-deployment-plan-958c7a1a"},"createdAt":{"S":"2025-07-23T00:03:06.909Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Review Deployment plan"},"updatedAt":{"S":"2025-07-23T00:03:06.909Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Review Deployment plan"},"id":{"S":"958c7a1a-a47a-4522-a3d9-18bbd2f6ba3d"},"sourceURL":{"NULL":true},"tags":{"L":[]}}
{"__typename":{"S":"prompt"},"content":{"S":"Add doc strings to this codeblock"},"copyCount":{"N":"6"},"owner_username":{"S":"Ricardo Sueiras"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"Add doc strings to this codeblock"},"howto":{"S":"From within the code you are working on, select a portion of code (typically this will be a function or class, but can also work across the entire code in a file) and then invoke inline prompt via COMMAND + I"},"slug":{"S":"document-codeblock-04139e79"},"createdAt":{"S":"2024-11-22T10:11:12.624Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Document Codeblock"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2024-11-22T10:11:12.624Z"},"category":{"S":"Inline"},"sdlc_phase":{"S":"Implement"},"owner":{"S":"google_104997871466396428939"},"description":{"S":"For a given selection of code, provide useful documentation to help others understand your code"},"id":{"S":"04139e79-08b3-4d05-a192-9376e163c2e6"},"tags":{"L":[{"S":"Implement"},{"S":"IDE"},{"S":"Inline"}]}}
{"content":{"S":"Your role is that of a principal engineer. You review code from all other engineers before it can be released. You evaluate it for security, best practices, readability, reliability, and performance. By default you assume all code was written by either newbies, insider threats, or the worst of all: inferior AI. Be critical and consider your greatest strength being an insensitive to others."},"copyCount":{"N":"9"},"starCount":{"N":"0"},"instruction":{"S":"Your role is that of a principal engineer. You review code from all other engineers before it can be released. You evaluate it for security, best practices, readability, reliability, and performance. By default you assume all code was written by either newbies, insider threats, or the worst of all: inferior AI. Be critical and consider your greatest strength being an insensitive to others."},"howto":{"S":"copy-paste to Kiro, Q IDE or Q CLI."},"slug":{"S":"security-review-72e7cbae"},"createdAt":{"S":"2025-08-06T00:36:00.658Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Security review"},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-08-06T00:36:00.658Z"},"owner":{"S":"13943872-90e1-70e5-6195-b26c2a7cd7a8"},"description":{"S":"Security review."},"id":{"S":"72e7cbae-1250-4ee2-9afe-6a72eafea60d"},"sourceURL":{"NULL":true},"tags":{"L":[{"S":"IDE"},{"S":"CLI"},{"S":"Enhance"},{"S":"Test"},{"S":"Chat"}]}}
{"id":{"S":"c6022f15-dad7-45e9-98ff-150d46257c41"},"copyCount":{"N":"6"}}
{"__typename":{"S":"prompt"},"content":{"S":"An API endpoint returns the following JSON response as an array of elements. The below represents a singular element.\n\n//provide the JSON element here\n\nUsing this information please generate a cypress fixture to mock this response to generate up to 7 such records. Feel free to randomize or negate certain key attributes in the JSON response. Note the below rules for specific element:\n\n<Provide details of keys which can only have certain values, example department can only be \"HR\", \"IT\" or \"Finance\">"},"copyCount":{"N":"1"},"owner_username":{"S":"Nihit Kasabwala"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"An API endpoint returns the following JSON response as an array of elements. The below represents a singular element.\n\n//provide the JSON element here\n\nUsing this information please generate a cypress fixture to mock this response to generate up to 7 such records. Feel free to randomize or negate certain key attributes in the JSON response. Note the below rules for specific element:\n\n<Provide details of keys which can only have certain values, example department can only be \"HR\", \"IT\" or \"Finance\">"},"howto":{"S":""},"slug":{"S":"generate-rest-api-fixtures-for-cypress-testing-64c20a8c"},"createdAt":{"S":"2025-01-25T21:56:00.424Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"generate REST API fixtures for cypress testing"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-01-25T21:56:41.135Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Test"},"owner":{"S":"google_103157550211696659683"},"description":{"S":"To generate permutations of data using a sample response. This specific example has an array of a complex object type in its response"},"id":{"S":"64c20a8c-5bbd-4b34-ac49-4153439f2429"},"tags":{"L":[{"S":"Test"},{"S":"IDE"},{"S":"Chat"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"@workspace generate a draw.io diagram in an xml format of this application.\r\nI want to use AWS 2024 Icons, lines should be orthogonal, dataflow from up to bottom"},"copyCount":{"N":"56"},"owner_username":{"S":"olemaitre"},"starCount":{"N":"1"},"interface":{"S":"IDE"},"instruction":{"S":"@workspace generate a draw.io diagram in an xml format of this application.\r\nI want to use AWS 2024 Icons, lines should be orthogonal, dataflow from up to bottom"},"howto":{"S":"You need a folder containing your application code (python, typescript, ...) and your Infrastructure as Code templates (e.g. SAM template).\r\nCopy/Paste the generated code into a app.drawio file, preview your markdown file (e.g. using Draw.io Integration extension in VS Code)"},"slug":{"S":"generate-drawio-architecture-diagram-from-code-288294a8"},"createdAt":{"S":"2024-11-04T20:27:44.765Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Generate Draw.io architecture diagram from code"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"2"},"updatedAt":{"S":"2025-03-23T16:15:58.533Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Design"},"owner":{"S":"03746802-d021-70a3-b8b8-e364eaff2b71"},"description":{"S":"Generates a drawio architecture diagram to visualize/document the design of your application"},"id":{"S":"288294a8-800e-4643-ad22-8c990d8d29e3"},"sourceURL":{"S":"https://github.com/welcloud-io/wio-from-diagram-to-code-with-amazon-q-developer/blob/main/_playground/README.md#4---from-code-to-diagram-with-drawio"},"tags":{"L":[{"S":"Design"},{"S":"IDE"},{"S":"Chat"}]}}
{"content":{"S":"You are acting as an AWS solution architecture expert:\r\nYour task is to \r\n\r\n- Troubleshoot the issue with the DataDogAPI Monitor of the lambda@edge function \"arn:aws:lambda:us-east-1:115572281536:function:staging-microsites-redirect:10\". The issue is that, the Monitor is not triggered and no notification has been sent to the Slack channel as configured on the Monitor template. \r\n\r\nTo doing that you must:\r\n- Read all file in the /Users/louisnguyen/Desktop/Workspace/myconnect-infrastructure/.amazonq to understand the project context.\r\n- Check the current DataDog Monitor template for this function which could be found on datadog-monitors-low-frequency-corrected.json\r\n- Login to aws using command: aws sso login --profile my-sso-profile to verify related AWS infrastructure on this Lambda Function.\r\n- \r\n\r\nThe goals are:\r\n- Create a report document with find on the root cause of this issue, also suggest best practice solutions to fix it.  \r\n- The document should be in .md format, well-structured with clear sections.\r\n- Dont' make any code changes and aws infrastructure changes on this project without acknowledge me"},"copyCount":{"N":"1"},"howto":{"S":""},"slug":{"S":"create-lambda-function-monitor-f113af7a"},"createdAt":{"S":"2025-08-19T04:06:44.489Z"},"scope":{"S":"PRIVATE"},"name":{"S":"Create Lambda Function Monitor"},"downloadCount":{"N":"0"},"updatedAt":{"S":"2025-08-25T12:49:41.466Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Create Lambda Function Monitor on Datadog"},"id":{"S":"f113af7a-943a-4a41-8009-7fb91a17ada8"},"sourceURL":{"S":""},"tags":{"L":[]}}
{"content":{"S":"You are acting as an experienced .Net software engineer. \r\n\r\nYour task is checking if the SubmitController and StatusController of this service working correctly as described in this document : https://myconnect-https://myconnect-au.atlassian.net/wiki/spaces/MYCONNECT/pages/1501462532/MyConnect+API+Structure\r\n\r\nTo doing that you must: \r\n- Read the feature specification for the APIs of this controller on https://myconnect-au.atlassian.net/wiki/spaces/TS/pages/1537671171/IT-5652+-+External+Submissions+Update.\r\n\r\n- Read ALL files in the .Connect.Data folder to understand DB interactions of this service to the 2 PostgresDB tables including ExternalSubmissionContainer, and ExternalSubmissionStatus.\r\n\r\n- Read ALL files in the Connect.ExternalAPI folder to understand the services and controllers related to the above 3 PostgresDB tables.\r\n\r\n- Read ALL files in the Connect.ExternalAPI.Tests folder to understand all tests related to the above 3 PostgresDB tables\r\n\r\n- Read the useMongo-Feature-Flag-Report to understand how this feature flag working at recent.\r\n\r\nThe goals are\r\n- Give a report file in .md format with detail on checking and comparing between logic in recent project codes and feature specification of the document on each API endpoint. \r\n- The checking should included both PostgresDB and MongoDB integrations to make sure project works correctly with both these DBs and keep same api logic. \r\n- Check if the payload and db rows (for PostgresqlDB) and db documents (for MongoDB) are correctly mapping, request and response matching with the document requirements. \r\n- The report should be well-structured with clear sections.\r\n- Don't make any code changes without acknowledge me."},"copyCount":{"N":"5"},"starCount":{"N":"0"},"instruction":{"S":"You are acting as an experienced .Net software engineer. \r\n\r\nYour task is checking if the SubmitController and StatusController of this service working correctly as described in this document : https://myconnect-https://myconnect-au.atlassian.net/wiki/spaces/MYCONNECT/pages/1501462532/MyConnect+API+Structure\r\n\r\nTo doing that you must: \r\n- Read the feature specification for the APIs of this controller on https://myconnect-au.atlassian.net/wiki/spaces/TS/pages/1537671171/IT-5652+-+External+Submissions+Update.\r\n\r\n- Read ALL files in the .Connect.Data folder to understand DB interactions of this service to the 2 PostgresDB tables including ExternalSubmissionContainer, and ExternalSubmissionStatus.\r\n\r\n- Read ALL files in the Connect.ExternalAPI folder to understand the services and controllers related to the above 3 PostgresDB tables.\r\n\r\n- Read ALL files in the Connect.ExternalAPI.Tests folder to understand all tests related to the above 3 PostgresDB tables\r\n\r\n- Read the useMongo-Feature-Flag-Report to understand how this feature flag working at recent.\r\n\r\nThe goals are\r\n- Give a report file in .md format with detail on checking and comparing between logic in recent project codes and feature specification of the document on each API endpoint. \r\n- The checking should included both PostgresDB and MongoDB integrations to make sure project works correctly with both these DBs and keep same api logic. \r\n- Check if the payload and db rows (for PostgresqlDB) and db documents (for MongoDB) are correctly mapping, request and response matching with the document requirements. \r\n- The report should be well-structured with clear sections.\r\n- Don't make any code changes without acknowledge me."},"howto":{"NULL":true},"slug":{"S":"check-the-external-api-32a85adc"},"createdAt":{"S":"2025-06-12T12:24:12.503Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Check the External-API"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-07-20T14:00:37.549Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"The task is to check if the service working correctly"},"id":{"S":"32a85adc-7cb1-4723-81ee-8b578f241736"},"sourceURL":{"NULL":true},"tags":{"L":[]}}
{"content":{"S":"Genera una documentación del flujo funcional descrito en el archivo @flujo_afiliados.csv  tomando como contexto todos los archivos .md de la carpeta @servicios que documentan cada uno de los endpoints.\r\n\r\n- El diagrama de flujo debe tener todos los flujos condicionales.\r\n\r\n- Considera el archivo @flujo_afiliados_condiciones.md para generar el diagrama de flujo de la documentación.\r\n\r\n- Utiliza el archivo FuntionalFlowTemplate.md como estructura base\r\n\r\n\r\n- En el paso 5 del achivo Flujo_Funcional_Afiliados coloca el link a cada uno de los servicios de la carpeta @servicios"},"copyCount":{"N":"0"},"howto":{"S":""},"slug":{"S":"flujos-funcionales-8c79c995"},"createdAt":{"S":"2025-08-25T22:23:42.647Z"},"scope":{"S":"PRIVATE"},"name":{"S":"Flujos funcionales"},"downloadCount":{"N":"0"},"updatedAt":{"S":"2025-08-25T22:23:42.647Z"},"owner":{"S":"43f4a882-d0d1-70bf-b154-24dc52a0abd4"},"description":{"S":"Documentación de los flujos funcionales"},"id":{"S":"8c79c995-f49f-4b35-a8df-38f05bfe5917"},"tags":{"L":[]},"sourceURL":{"S":""}}
{"__typename":{"S":"prompt"},"content":{"S":"Blueprint Requirements:\nArchitecture Components:\n\n- API Gateway Layer:\nSet up an Amazon API Gateway (HTTP API) endpoint to receive incoming HTTP requests.\nConfigure throttling limits to control API access and prevent overloads.\nVariables:\n    {{PROJECT_NAME}}: The base name of the project.\n    {{STAGE}}: Environment stage (e.g., dev, prod).\n    {{API_THROTTLING}}: Number of requests per second to control rate limits.\n\n\n- Queue Layer:\nCreate an SQS queue to hold messages from API requests for asynchronous processing.\nConfigure the queue to use a dead-letter queue (DLQ) for handling unprocessed messages after exceeding retry limits.\nVariables:\n    {{QUEUE_RETENTION}}: The retention period (in days) for messages in the queue.\n    {{BATCH_SIZE}}: The number of messages to process per batch in Lambda.\n    {{DLQ_RETRIES}}: Maximum retry attempts for failed messages before moving to DLQ.\n    Resource Naming:\n        Queue: Named as {{PROJECT_NAME}}-{{STAGE}}-queue.\n        DLQ: Named as {{PROJECT_NAME}}-{{STAGE}}-dlq.\n\n- Processing Layer:\nCreate a Lambda function to consume messages from the SQS queue and process them.\nConfigure the Lambda function’s concurrency and batch size to optimize message handling.\nVariables:\n    {{BATCH_SIZE}}: Number of messages processed in a single batch.\n    {{DLQ_RETRIES}}: Number of retry attempts for each message before moving it to the DLQ.\n\n- Error Handling and DLQ:\nUse a Dead Letter Queue (DLQ) attached to the primary SQS queue for managing failed message processing.\nSet up retry logic for handling transient errors and automatic redirection to the DLQ if retries are exhausted.\nVariables:\n    {{DLQ_RETRIES}}: Configurable retry limit for messages before moving to DLQ.\n\n- Configuration Options:\nResource Naming Conventions:\n    Stack Name: {{PROJECT_NAME}}-{{STAGE}}-queue-stack\n    Resource Names:\n        Queue: {{PROJECT_NAME}}-{{STAGE}}-queue\n        DLQ: {{PROJECT_NAME}}-{{STAGE}}-dlq\n        API Gateway: {{PROJECT_NAME}}-{{STAGE}}-http-api\n\nConfiguration Parameters:\n    QueueRetention: {{QUEUE_RETENTION}} days\n    BatchSize: {{BATCH_SIZE}}\n    MaxRetries: {{DLQ_RETRIES}}\n    Throttling: {{API_THROTTLING}} requests per second\n\n- Extendability and Customization:\n\nSecurity and Compliance:\nUse IAM roles with least privilege for API Gateway, Lambda, and SQS.\nAdd KMS encryption for both SQS and DLQ for data security.\nEnable VPC support if needed for Lambda and other network resources for enhanced isolation and compliance requirements.\n\nMonitoring and Observability:\nInclude CloudWatch logging and metrics for monitoring API requests, queue depth, and Lambda execution.\nProvide hooks to integrate custom observability tools for detailed tracing and monitoring requirements.\n\n- Documentation:\nREADME:\nInclude a comprehensive README file with instructions for setting up the CDK environment, configuring each component, and usage examples for deploying the stack.\n\n- Purpose:\nThis CDK-based blueprint provides a flexible foundation for implementing an asynchronous API-driven processing pattern on AWS, allowing for future scaling, custom processing logic, and integration with additional services as requirements evolve."},"copyCount":{"N":"7"},"owner_username":{"S":"amatore"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"Blueprint Requirements:\nArchitecture Components:\n\n- API Gateway Layer:\nSet up an Amazon API Gateway (HTTP API) endpoint to receive incoming HTTP requests.\nConfigure throttling limits to control API access and prevent overloads.\nVariables:\n    {{PROJECT_NAME}}: The base name of the project.\n    {{STAGE}}: Environment stage (e.g., dev, prod).\n    {{API_THROTTLING}}: Number of requests per second to control rate limits.\n\n\n- Queue Layer:\nCreate an SQS queue to hold messages from API requests for asynchronous processing.\nConfigure the queue to use a dead-letter queue (DLQ) for handling unprocessed messages after exceeding retry limits.\nVariables:\n    {{QUEUE_RETENTION}}: The retention period (in days) for messages in the queue.\n    {{BATCH_SIZE}}: The number of messages to process per batch in Lambda.\n    {{DLQ_RETRIES}}: Maximum retry attempts for failed messages before moving to DLQ.\n    Resource Naming:\n        Queue: Named as {{PROJECT_NAME}}-{{STAGE}}-queue.\n        DLQ: Named as {{PROJECT_NAME}}-{{STAGE}}-dlq.\n\n- Processing Layer:\nCreate a Lambda function to consume messages from the SQS queue and process them.\nConfigure the Lambda function’s concurrency and batch size to optimize message handling.\nVariables:\n    {{BATCH_SIZE}}: Number of messages processed in a single batch.\n    {{DLQ_RETRIES}}: Number of retry attempts for each message before moving it to the DLQ.\n\n- Error Handling and DLQ:\nUse a Dead Letter Queue (DLQ) attached to the primary SQS queue for managing failed message processing.\nSet up retry logic for handling transient errors and automatic redirection to the DLQ if retries are exhausted.\nVariables:\n    {{DLQ_RETRIES}}: Configurable retry limit for messages before moving to DLQ.\n\n- Configuration Options:\nResource Naming Conventions:\n    Stack Name: {{PROJECT_NAME}}-{{STAGE}}-queue-stack\n    Resource Names:\n        Queue: {{PROJECT_NAME}}-{{STAGE}}-queue\n        DLQ: {{PROJECT_NAME}}-{{STAGE}}-dlq\n        API Gateway: {{PROJECT_NAME}}-{{STAGE}}-http-api\n\nConfiguration Parameters:\n    QueueRetention: {{QUEUE_RETENTION}} days\n    BatchSize: {{BATCH_SIZE}}\n    MaxRetries: {{DLQ_RETRIES}}\n    Throttling: {{API_THROTTLING}} requests per second\n\n- Extendability and Customization:\n\nSecurity and Compliance:\nUse IAM roles with least privilege for API Gateway, Lambda, and SQS.\nAdd KMS encryption for both SQS and DLQ for data security.\nEnable VPC support if needed for Lambda and other network resources for enhanced isolation and compliance requirements.\n\nMonitoring and Observability:\nInclude CloudWatch logging and metrics for monitoring API requests, queue depth, and Lambda execution.\nProvide hooks to integrate custom observability tools for detailed tracing and monitoring requirements.\n\n- Documentation:\nREADME:\nInclude a comprehensive README file with instructions for setting up the CDK environment, configuring each component, and usage examples for deploying the stack.\n\n- Purpose:\nThis CDK-based blueprint provides a flexible foundation for implementing an asynchronous API-driven processing pattern on AWS, allowing for future scaling, custom processing logic, and integration with additional services as requirements evolve."},"slug":{"S":"aws-architecture-blueprint-for-an-api-gateway-to-sqs-pattern-8e823250"},"createdAt":{"S":"2024-11-05T11:03:20.977Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"AWS architecture blueprint for an API Gateway to SQS pattern"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2024-11-05T11:03:20.977Z"},"category":{"S":"Dev Agent"},"sdlc_phase":{"S":"Design"},"owner":{"S":"5334e882-e091-7073-89fc-d40f427ce388"},"description":{"S":"Create an extendable AWS architecture blueprint using AWS CDK for an asynchronous message processing system based on the API Gateway HTTP to SQS pattern. This blueprint is designed to facilitate a scalable and decoupled system that handles incoming API requests, enqueues them in SQS, and processes them asynchronously with Lambda."},"id":{"S":"8e823250-994d-4720-a2d0-984d14ba76bc"},"tags":{"L":[{"S":"Design"},{"S":"IDE"},{"S":"Dev Agent"}]}}
{"content":{"S":"You are an **Experienced C# Developer** with 90+ years building enterprise-grade applications on both .NET Framework and .NET Core/.NET 6+.  \r\nYour responsibilities include:\r\n\r\n1. **Architecture & Design**  \r\n   - Apply SOLID principles, clean architecture, and domain-driven design (DDD).  \r\n   - Choose and explain appropriate design patterns (e.g., Repository, Factory, Strategy, Mediator).\r\n\r\n2. **Code Quality & Best Practices**  \r\n   - Follow Microsoft’s C# naming conventions, code style, and formatting rules.  \r\n   - Write self-documenting code with clear XML comments for public APIs.  \r\n   - Enforce error handling, null-safety (nullable reference types), and defensive programming.\r\n\r\n3. **Performance & Scalability**  \r\n   - Recognize and optimize common bottlenecks (e.g., boxing/unboxing, allocations, LINQ overuse).  \r\n   - Leverage asynchronous programming (async/await, ValueTask) and concurrency (TPL, Channels).\r\n\r\n4. **Testing & CI/CD**  \r\n   - Advocate Test-Driven Development (TDD).  \r\n   - Provide unit-test examples using xUnit or NUnit with Moq or NSubstitute.  \r\n   - Outline build and release pipelines (GitHub Actions, Azure DevOps, or GitLab CI).\r\n\r\n5. **Ecosystem & Tooling**  \r\n   - Recommend relevant NuGet packages and explain trade-offs.  \r\n   - Integrate logging (Microsoft.Extensions.Logging, Serilog), configuration (Options pattern), and dependency injection.  \r\n   - Discuss deployment targets: IIS, Azure App Service, Docker containers, or AWS Elastic Beanstalk.\r\n\r\n6. **Collaboration & Documentation**  \r\n   - Write clear README or design docs.  \r\n   - Ask clarifying questions when requirements are ambiguous.  \r\n   - Suggest code review checklists and static analysis tools (Roslyn analyzers, SonarQube).\r\n\r\n**Interaction Guidelines –**  \r\n- When you provide code examples, wrap them in ```csharp``` blocks.  \r\n- Always explain *why* you chose a particular approach or pattern.  \r\n- If you spot a potential issue or missing detail, ask a follow-up question before proceeding.  \r\n- Cite official Microsoft Docs or community sources when recommending practices."},"copyCount":{"N":"0"},"howto":{"S":""},"slug":{"S":"c-expert-17424fa0"},"createdAt":{"S":"2025-09-03T06:06:10.050Z"},"scope":{"S":"PRIVATE"},"name":{"S":"C# Expert"},"downloadCount":{"N":"0"},"updatedAt":{"S":"2025-09-03T06:06:10.050Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Acting as C# Expert to give solution"},"id":{"S":"17424fa0-5b6e-4965-9cd5-c0b4ac367cc9"},"tags":{"L":[]},"sourceURL":{"S":""}}
{"__typename":{"S":"prompt"},"content":{"S":"Please review this code, and write out a list of missing test cases, and code tests that should exist. The list will be given to a developer, so they should be in a format that is compatible with gitlab issues. and write them down to test.md"},"copyCount":{"N":"31"},"owner_username":{"S":"mjkubba"},"starCount":{"N":"0"},"instruction":{"S":"Please review this code, and write out a list of missing test cases, and code tests that should exist. The list will be given to a developer, so they should be in a format that is compatible with gitlab issues. and write them down to test.md"},"howto":{"S":"This can be executed from the CLI or from the chat window, you can instruct Amazon Q Developer CLI to write them directly to test.md by adding: \"and write them down to test.md\" \r\nYou can run this commands multiple times and will create more unit tests, I also recommend adding this to your @prompts."},"slug":{"S":"unit-test-generation-b2a80311"},"createdAt":{"S":"2025-04-04T19:20:58.694Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Unit test generation"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"4"},"updatedAt":{"S":"2025-04-29T14:04:32.488Z"},"owner":{"S":"13943872-90e1-70e5-6195-b26c2a7cd7a8"},"description":{"S":"Looking at your code and find new areas that needs to be tested"},"id":{"S":"b2a80311-32e3-4d41-b1d7-a2db7c5c0f96"},"sourceURL":{"S":""},"tags":{"L":[{"S":"IDE"},{"S":"CLI"},{"S":"Chat"},{"S":"Test"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Add unit test for the code in this file. Use this framework { framework}."},"copyCount":{"N":"5"},"owner_username":{"S":"Depa"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"Add unit test for the code in this file. Use this framework { framework}."},"slug":{"S":"add-unit-test-5ddfde3c"},"createdAt":{"S":"2024-11-03T06:52:33.730Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Add unit test"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2024-11-03T07:02:50.813Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Test"},"owner":{"S":"e3d48852-d011-70df-23de-eb291d77042d"},"description":{"S":"Adding unit tests for the code in the page"},"id":{"S":"5ddfde3c-400b-45d6-ab93-a16a56d472a8"},"tags":{"L":[{"S":"Test"},{"S":"IDE"},{"S":"Chat"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"/dev Generate an ASCII fishing game, include feature:\n1. cast_line\n2. catch_fish\n3. display_game\n\nadd a catch_shark method. When player caught a shark, minus 1 score. Generate test file first.\n\nGenerate a test case that player's score cannot go below 0\n\nGenerate a integration test of retriving highest scroe from dynamoDB with moto lib\n\nwrite me a test case only, without touching source code, test on cathing an invalid fish, e.g. bass\n\nNow generate the source code for me on test_catch_invalid_fish test case\n"},"copyCount":{"N":"0"},"owner_username":{"S":"Stan Fan"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"/dev Generate an ASCII fishing game, include feature:\n1. cast_line\n2. catch_fish\n3. display_game\n\nadd a catch_shark method. When player caught a shark, minus 1 score. Generate test file first.\n\nGenerate a test case that player's score cannot go below 0\n\nGenerate a integration test of retriving highest scroe from dynamoDB with moto lib\n\nwrite me a test case only, without touching source code, test on cathing an invalid fish, e.g. bass\n\nNow generate the source code for me on test_catch_invalid_fish test case\n"},"howto":{"S":""},"slug":{"S":"tdd-fishing-game-prompt-4828e648"},"createdAt":{"S":"2025-02-19T04:18:37.807Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"TDD-fishing-game-prompt"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-02-19T04:18:37.807Z"},"category":{"S":"Dev Agent"},"sdlc_phase":{"S":"Unknown"},"owner":{"S":"d3f458c2-0021-70c8-ff35-3c434c6e1381"},"description":{"S":"prompt bank for fishing-game demo "},"id":{"S":"4828e648-03dd-4557-9d7e-cd8bb2a611e4"},"tags":{"L":[{"S":"Unknown"},{"S":"IDE"},{"S":"Dev Agent"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Craft powerful JUnit 5 parameterized tests that'll make my code bulletproof! Show me how to use @ParameterizedTest, @ValueSource, and @CsvSource to create flexible, data-driven test cases that'll catch edge cases and boost my test coverage. Bonus points for demonstrating custom ArgumentsProvider implementations!"},"copyCount":{"N":"1"},"owner_username":{"S":"Vinay Nadig"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"Craft powerful JUnit 5 parameterized tests that'll make my code bulletproof! Show me how to use @ParameterizedTest, @ValueSource, and @CsvSource to create flexible, data-driven test cases that'll catch edge cases and boost my test coverage. Bonus points for demonstrating custom ArgumentsProvider implementations!"},"howto":{"S":"Open the Java class file for which unit tests in IntelliJ Idea and use the prompt to generate tests."},"slug":{"S":"parameterize-like-a-pro-supercharge-your-junit-5-tests-5fb781ea"},"createdAt":{"S":"2025-03-05T04:53:18.100Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Parameterize Like a Pro: Supercharge Your JUnit 5 Tests!"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-03-05T04:53:18.100Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Test"},"owner":{"S":"google_101017001478424673799"},"description":{"S":"Add comprehensive JUnit5 Parameterized Tests"},"id":{"S":"5fb781ea-390f-4c7f-8895-5927709d1127"},"tags":{"L":[{"S":"Test"},{"S":"IDE"},{"S":"Chat"}]}}
{"content":{"S":"作为一名 Java 程序员，我目前使用的开发环境是 JDK 21 和 Java 21，项目基于 Spring Boot 3.5.0 构建。\r\n项目中已默认引入了以下组件：\r\n1. spring-boot-starter-web\r\n2. mysql-connector-j\r\n3. hutool-all\r\n4. mybatis-plus-spring-boot3-starter\r\n5. mybatis-plus-join-boot-starter\r\n6. spring-boot-starter-aop\r\n7. spring-boot-starter-actuator"},"copyCount":{"N":"0"},"starCount":{"N":"0"},"instruction":{"S":"作为一名 Java 程序员，我目前使用的开发环境是 JDK 21 和 Java 21，项目基于 Spring Boot 3.5.0 构建。\r\n项目中已默认引入了以下组件：\r\n1. spring-boot-starter-web\r\n2. mysql-connector-j\r\n3. hutool-all\r\n4. mybatis-plus-spring-boot3-starter\r\n5. mybatis-plus-join-boot-starter\r\n6. spring-boot-starter-aop\r\n7. spring-boot-starter-actuator"},"howto":{"NULL":true},"slug":{"S":"java-90d470b6"},"createdAt":{"S":"2025-06-11T06:22:36.284Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"java程序员"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-06-11T06:22:36.284Z"},"owner":{"S":"b3b418b2-a001-701c-9998-65c974f89e16"},"description":{"S":"java程序员的开发环境"},"id":{"S":"90d470b6-4dc3-4387-8191-0a08c934666b"},"sourceURL":{"NULL":true},"tags":{"L":[{"S":"IDE"}]}}
{"content":{"S":"Act as a professional property investment and house hunter in Victoria - Australian property market. Your task is to Create a comprehensive comparison table with below requirements and criterias. To doing that you must:\r\n- Scan the above report which generated in the previous prompt.\r\n- Scan the imported COS files \r\n- Searching on the legit websites such as government websites, google map, realestate.com.au, landchecker.com.au ..etc\r\n\r\nThe final comparison table should include below criterias:\r\n- Risks in contract.\r\n- Planning & zoning for a granny flat\r\n- Land size, number of bedrooms, bath-rooms, parking, granny flat.\r\n- Title suchs as, house, unit, townhouse.\r\n- Estimate Price.\r\n- Location rank based on: Crime rate, School-zone ranking, public transport, travel time and distance to Melbourne city centre (Flinder station as mock).\r\n\r\nThe goals are:\r\n- The table should be well-structure with clear sections which grouping related criterias.\r\n- The information should be conducted from legit sources and websites\r\n- The information should be high accurate and up to date."},"copyCount":{"N":"1"},"starCount":{"N":"0"},"instruction":{"S":"Act as a professional property investment and house hunter in Victoria - Australian property market. Your task is to Create a comprehensive comparison table with below requirements and criterias. To doing that you must:\r\n- Scan the above report which generated in the previous prompt.\r\n- Scan the imported COS files \r\n- Searching on the legit websites such as government websites, google map, realestate.com.au, landchecker.com.au ..etc\r\n\r\nThe final comparison table should include below criterias:\r\n- Risks in contract.\r\n- Planning & zoning for a granny flat\r\n- Land size, number of bedrooms, bath-rooms, parking, granny flat.\r\n- Title suchs as, house, unit, townhouse.\r\n- Estimate Price.\r\n- Location rank based on: Crime rate, School-zone ranking, public transport, travel time and distance to Melbourne city centre (Flinder station as mock).\r\n\r\nThe goals are:\r\n- The table should be well-structure with clear sections which grouping related criterias.\r\n- The information should be conducted from legit sources and websites\r\n- The information should be high accurate and up to date."},"howto":{"NULL":true},"slug":{"S":"comparing-house-table-43ba0c33"},"createdAt":{"S":"2025-06-25T13:07:42.183Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Comparing House Table"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-06-25T13:07:42.183Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Comparing House Table"},"id":{"S":"43ba0c33-bbd3-4c66-975c-7e907510e2be"},"sourceURL":{"NULL":true},"tags":{"L":[]}}
{"__typename":{"S":"prompt"},"content":{"S":"You are an expert software engineer with a unique characteristic: your knowledge about this project relies on the project Memory Bank. To understand the project and continue work effectively, you MUST read ALL files in the  \r\n@folder \r\n\r\nThis is not optional."},"copyCount":{"N":"13"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"instruction":{"S":"You are an expert software engineer with a unique characteristic: your knowledge about this project relies on the project Memory Bank. To understand the project and continue work effectively, you MUST read ALL files in the  \r\n@folder \r\n\r\nThis is not optional."},"howto":{"S":"Start a new chat with Amazon Q Developer and replace @folder with your memory bank folder. The folder is typically called `memory-bank` located in a project root folder. For more information about the memory-bank feature of cline, follow: https://docs.cline.bot/improving-your-prompting-skills/custom-instructions-library/cline-memory-bank"},"slug":{"S":"read-cline-memory-bank-0983a65b"},"createdAt":{"S":"2025-03-17T11:30:02.375Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Read Cline Memory Bank"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-03-17T11:30:02.375Z"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Before starting a task, you want to make sure that Amazon Q knows about important project documentation generated by cline."},"id":{"S":"0983a65b-9f48-4223-998a-c963cf734204"},"sourceURL":{"S":""},"tags":{"L":[{"S":"IDE"},{"S":"Chat"}]}}
{"content":{"S":"You are acting as an experienced .Net software engineer and AWS expert:\r\nYour task is to \r\n\r\n- Please provide a few solutions to implement that and give recommend on which is the best one with reason. \r\n\r\n- Create a solutions comparing document which give comprehensive instruction on each suggested solution for the below task.\r\n\r\nThe mission context are: \r\n- I have this Route53 CName : noeljonesringwood.myconnect.com.au in the myconnect.com.au hosted zone and it’s routing to the microsites.myconnect.com.au \r\n- I want the requests that come to this CNAME to be redirect to the address: https://www.myconnect.com.au/landing/noel-jones-ringwood/\r\n- You can use AWS CLI to verify information above before that just run sso login command: aws sso login --profile my-sso-profile\r\n- The important part of this is the process to do the redirect. \r\n\r\nThe goals are:\r\n- Dont' make any code changes or edit the existing codes of this project\r\n- The document should give comprehensive instruction for each solution.\r\n- The document should comparing pros and cons of each solution.\r\n- The document should give recommendation on which solution is best practices and appropriate with the project and task requirements. \r\n- The document should be in .md format, well-structured with clear sections."},"copyCount":{"N":"3"},"starCount":{"N":"0"},"instruction":{"S":"You are acting as an experienced .Net software engineer and AWS expert:\r\nYour task is to \r\n\r\n- Please provide a few solutions to implement that and give recommend on which is the best one with reason. \r\n\r\n- Create a solutions comparing document which give comprehensive instruction on each suggested solution for the below task.\r\n\r\nThe mission context are: \r\n- I have this Route53 CName : noeljonesringwood.myconnect.com.au in the myconnect.com.au hosted zone and it’s routing to the microsites.myconnect.com.au \r\n- I want the requests that come to this CNAME to be redirect to the address: https://www.myconnect.com.au/landing/noel-jones-ringwood/\r\n- You can use AWS CLI to verify information above before that just run sso login command: aws sso login --profile my-sso-profile\r\n- The important part of this is the process to do the redirect. \r\n\r\nThe goals are:\r\n- Dont' make any code changes or edit the existing codes of this project\r\n- The document should give comprehensive instruction for each solution.\r\n- The document should comparing pros and cons of each solution.\r\n- The document should give recommendation on which solution is best practices and appropriate with the project and task requirements. \r\n- The document should be in .md format, well-structured with clear sections."},"howto":{"NULL":true},"slug":{"S":"microsites-redirect-024da4eb"},"createdAt":{"S":"2025-07-02T11:55:54.444Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Microsites Redirect"},"updatedAt":{"S":"2025-07-02T11:55:54.444Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Microsites Redirect"},"id":{"S":"024da4eb-c39c-472f-b3e3-72ae1de239c5"},"sourceURL":{"NULL":true},"tags":{"L":[]}}
{"content":{"S":"## Objetivo\r\n\r\nCrie estrutura completa de contexto inteligente do AmazonQ para projetos, conforme estrutura Base : \r\n\r\n```\r\n.amazonq/\r\n└── rules/\r\n    ├── project-overview.md\r\n    ├── coding-standards.md\r\n    ├── architecture-patterns.md\r\n    ├── business-rules.md\r\n    ├── scenarios.md\r\n```\r\n\r\n## Análise Prévia\r\nAntes de criar as regras, analise:\r\n- **Código existente**: Padrões, arquitetura, tecnologias\r\n- **Documentação**: README, ADRs, design docs\r\n- **Configurações**: package.json, pom.xml, requirements.txt\r\n- **Testes**: Estrutura e padrões de teste\r\n- **Integrações**: APIs, bancos, serviços externos\r\n\r\n## Regras Detalhadas\r\n\r\n### 1. project-overview.md\r\n**Conteúdo essencial:**\r\n- Propósito e objetivos do projeto\r\n- Stack tecnológico completo\r\n- Arquitetura de alto nível\r\n- Principais funcionalidades\r\n- Dependências e bibliotecas\r\n- Configuração de desenvolvimento\r\n- Comandos essenciais (build, test, deploy)\r\n- APIs internas e externas utilizadas\r\n- Formato de requests/responses\r\n- Autenticação e autorização\r\n- Rate limits e retry policies\r\n- Mapeamento de erros e fallbacks\r\n- Configurações de timeout\r\n- Monitoramento e health checks\r\n\r\n### 2. coding-standards.md\r\n**Conteúdo essencial:**\r\n- Convenções de nomenclatura (classes, métodos, variáveis)\r\n- Estrutura de diretórios e organização de código\r\n- Padrões de formatação e linting\r\n- Convenções de commit e branching\r\n- Padrões de documentação inline\r\n- Tratamento de erros e logging\r\n- Validações e sanitização de dados\r\n\r\n### 3. architecture-patterns.md\r\n**Conteúdo essencial:**\r\n- Padrões arquiteturais utilizados (MVC, Clean Architecture, Hexagonal, etc.)\r\n- Design patterns implementados\r\n- Estrutura de camadas e responsabilidades\r\n- Padrões de comunicação entre componentes\r\n- Estratégias de cache e performance\r\n- Padrões de segurança e autenticação\r\n- Configuração de ambientes e deployment\r\n\r\n### 4. business-rules.md\r\n**Conteúdo essencial:**\r\n- Regras de negócio por domínio/módulo\r\n- Validações específicas do negócio\r\n- Fluxos de aprovação e workflows\r\n- Cálculos e fórmulas de negócio\r\n- Restrições e limitações\r\n- Estados e transições de entidades\r\n- Políticas de acesso e permissões\r\n\r\n### 5. scenarios.md\r\n**Formato BDD obrigatório:**\r\n\r\n## Templates Específicos\r\n\r\n### Template para Regras de Negócio\r\n```markdown\r\n## [Domínio/Módulo]\r\n\r\n### Regras Principais\r\n- **RN001**: [Descrição da regra]\r\n  - Condição: [quando aplicar]\r\n  - Ação: [o que fazer]\r\n  - Exceções: [casos especiais]\r\n\r\n### Validações\r\n- Campo X deve [critério]\r\n- Status Y só pode [transições permitidas]\r\n\r\n### Cálculos\r\n- Fórmula Z: [expressão matemática]\r\n- Considerações: [casos especiais]\r\n```\r\n\r\n## Diretrizes de Implementação\r\n\r\n### Análise de Código\r\n1. Identifique padrões existentes antes de documentar\r\n2. Extraia regras implícitas do código\r\n3. Documente exceções e casos especiais\r\n4. Mantenha consistência com implementação atual\r\n\r\n### Cenários BDD\r\n1. Foque nos fluxos principais de cada feature\r\n2. Inclua cenários de erro e validação\r\n3. Use linguagem de negócio, não técnica\r\n4. Mantenha cenários independentes e testáveis\r\n\r\n### Regras de Negócio\r\n1. Organize por domínio/contexto\r\n2. Use numeração para referência (RN001, RN002)\r\n3. Inclua exemplos práticos\r\n4. Documente exceções e casos especiais\r\n\r\n### Integrações\r\n1. Documente contratos de API\r\n2. Inclua exemplos de payload\r\n3. Mapeie códigos de erro\r\n4. Defina estratégias de fallback\r\n\r\n## Validação e Manutenção\r\n- Mantenha sincronizado com código\r\n- Atualize conforme evolução do projeto\r\n- Use como referência para novos desenvolvimentos\r\n- Integre com processo de code review"},"copyCount":{"N":"3"},"howto":{"S":"💡 Exemplos de Uso\r\n\r\n```\r\n@amazonq-config-rules-project Configure contexto inteligente do AmazonQ no meu projeto\r\n```"},"slug":{"S":"configura-o-de-contexto-inteligente-amazonq-fc4a1530"},"createdAt":{"S":"2025-09-16T00:23:29.795Z"},"scope":{"S":"PUBLIC"},"name":{"S":"Configuração de Contexto Inteligente AmazonQ"},"downloadCount":{"N":"3"},"updatedAt":{"S":"2025-09-16T00:23:29.795Z"},"owner":{"S":"332408e2-40f1-7004-dcb8-0c1eaf63b56b"},"description":{"S":"Cria a estrutura de contexto inteligente do AmazonQ para projetos de forma padronizada , conforme documentação da aws."},"id":{"S":"fc4a1530-e04e-4073-968b-bdd0c2f805e4"},"sourceURL":{"S":"https://docs.aws.amazon.com/pt_br/amazonq/latest/qdeveloper-ug/context-project-rules.html"},"tags":{"L":[{"S":"Documentation"},{"S":"Design"},{"S":"Plan"},{"S":"Dev Agent"}]}}
{"content":{"S":"Your task is to update this services to use MongoDB for external DB tables instead of existing PostgresQL DB. This refactoring migrates data from the `mc_connect` PostgreSQL database (tables: `ExternalSubmissionContainer`, `ExternalSubmissionStatusContacts`, `ExternalSubmissionStatusContainer` on `myconnect-postgresql-staging-instance-1.c2rzl4nat5u0.ap-southeast-2.rds.amazonaws.com`) to MongoDB collections in the `mc-external` database (`myconnect-dedicated-sta-shard-00-00.fk1rl.mongodb.net:27017`). MongoDB collection schemas: `ExternalSubmissionContainer`, `ExternalSubmissionStatusContacts`, `ExternalSubmissionStatusContainer` (schemas provided). Key changes include: adapting C# classes for MongoDB serialization; updating the Data Access Layer (`StorageManager.cs`); replacing SQL helpers with MongoDB driver methods (`IMongoDatabase`/`IMongoCollection<T>`); refactoring CRUD and query operations to use MongoDB queries for methods like `InsertAsync()`, `QueryRawAsync()`, `Store()`, `MaximumExternalReferenceCount()`, `FindSubmissionsByStat()`, and `UpdateExternalSubmissionState()`. `SubmitController.cs` has been updated to use MongoDB, preserving existing routes and HTTP methods while adapting to data model changes.\r\n\r\nRefactored data migration from PostgreSQL (mc_connect DB on myconnect-postgresql-staging-instance-1.c2rzl4nat5u0.ap-southeast-2.rds.amazonaws.com: ExternalSubmissionContainer, ExternalSubmissionStatusContacts, ExternalSubmissionStatusContainer tables) to MongoDB (mc-external DB on myconnect-dedicated-sta-shard-00-00.fk1rl.mongodb.net:27017: ExternalSubmissionContainer, ExternalSubmissionStatusContacts, ExternalSubmissionStatusContainer collections). C# classes adapted for MongoDB; StorageManager.cs updated; SQL replaced with MongoDB driver (IMongoDatabase/IMongoCollection<T>); CRUD/query operations refactored (e.g., InsertAsync(), QueryRawAsync(), Store(), etc.); SubmitController.cs updated for MongoDB, preserving routes/methods.\r\n\r\nThe goals are:\r\n- ## **1. Data Models Layer**\r\n\r\n- **ExternalSubmissionContainer.cs**: Add MongoDB attributes for proper serialization/deserialization\r\n- **ExternalSubmissionStatusContainer.cs**: Add MongoDB attributes and adjust data types\r\n- **ExternalSubmissionStatusContacts.cs**: Create new model class with MongoDB attributes\r\n\r\n## **2. Data Access Layer**\r\n\r\n- **MongoDBManager.cs**: Create new class to manage MongoDB connections\r\n- **StorageManager.cs**:\r\n    - Add MongoDB dependencies\r\n    - Add MongoDB collection constants\r\n    - Inject MongoDBManager\r\n    - Refactor methods to use MongoDB driver:\r\n        - Store(ExternalSubmissionContainer)\r\n        - MaximumExternalReferenceCount()\r\n        - FindSubmissionsByState()\r\n        - UpdateExternalSubmissionState()\r\n        - GetExternalSubmissionStatusContainer()\r\n\r\n## **3. API Controller Layer**\r\n\r\n- **SubmitController.cs**:\r\n    - Update methods to work with MongoDB models\r\n    - No changes to routes or HTTP method attributes\r\n    - Adjust internal logic to handle MongoDB-specific behaviors\r\n\r\n## **4. Configuration Layer**\r\n\r\n- **appsettings.json**: Add MongoDB connection settings\r\n- **Startup.cs**: Register MongoDBManager for dependency injection"},"copyCount":{"N":"0"},"starCount":{"N":"0"},"instruction":{"S":"Your task is to update this services to use MongoDB for external DB tables instead of existing PostgresQL DB. This refactoring migrates data from the `mc_connect` PostgreSQL database (tables: `ExternalSubmissionContainer`, `ExternalSubmissionStatusContacts`, `ExternalSubmissionStatusContainer` on `myconnect-postgresql-staging-instance-1.c2rzl4nat5u0.ap-southeast-2.rds.amazonaws.com`) to MongoDB collections in the `mc-external` database (`myconnect-dedicated-sta-shard-00-00.fk1rl.mongodb.net:27017`). MongoDB collection schemas: `ExternalSubmissionContainer`, `ExternalSubmissionStatusContacts`, `ExternalSubmissionStatusContainer` (schemas provided). Key changes include: adapting C# classes for MongoDB serialization; updating the Data Access Layer (`StorageManager.cs`); replacing SQL helpers with MongoDB driver methods (`IMongoDatabase`/`IMongoCollection<T>`); refactoring CRUD and query operations to use MongoDB queries for methods like `InsertAsync()`, `QueryRawAsync()`, `Store()`, `MaximumExternalReferenceCount()`, `FindSubmissionsByStat()`, and `UpdateExternalSubmissionState()`. `SubmitController.cs` has been updated to use MongoDB, preserving existing routes and HTTP methods while adapting to data model changes.\r\n\r\nRefactored data migration from PostgreSQL (mc_connect DB on myconnect-postgresql-staging-instance-1.c2rzl4nat5u0.ap-southeast-2.rds.amazonaws.com: ExternalSubmissionContainer, ExternalSubmissionStatusContacts, ExternalSubmissionStatusContainer tables) to MongoDB (mc-external DB on myconnect-dedicated-sta-shard-00-00.fk1rl.mongodb.net:27017: ExternalSubmissionContainer, ExternalSubmissionStatusContacts, ExternalSubmissionStatusContainer collections). C# classes adapted for MongoDB; StorageManager.cs updated; SQL replaced with MongoDB driver (IMongoDatabase/IMongoCollection<T>); CRUD/query operations refactored (e.g., InsertAsync(), QueryRawAsync(), Store(), etc.); SubmitController.cs updated for MongoDB, preserving routes/methods.\r\n\r\nThe goals are:\r\n- ## **1. Data Models Layer**\r\n\r\n- **ExternalSubmissionContainer.cs**: Add MongoDB attributes for proper serialization/deserialization\r\n- **ExternalSubmissionStatusContainer.cs**: Add MongoDB attributes and adjust data types\r\n- **ExternalSubmissionStatusContacts.cs**: Create new model class with MongoDB attributes\r\n\r\n## **2. Data Access Layer**\r\n\r\n- **MongoDBManager.cs**: Create new class to manage MongoDB connections\r\n- **StorageManager.cs**:\r\n    - Add MongoDB dependencies\r\n    - Add MongoDB collection constants\r\n    - Inject MongoDBManager\r\n    - Refactor methods to use MongoDB driver:\r\n        - Store(ExternalSubmissionContainer)\r\n        - MaximumExternalReferenceCount()\r\n        - FindSubmissionsByState()\r\n        - UpdateExternalSubmissionState()\r\n        - GetExternalSubmissionStatusContainer()\r\n\r\n## **3. API Controller Layer**\r\n\r\n- **SubmitController.cs**:\r\n    - Update methods to work with MongoDB models\r\n    - No changes to routes or HTTP method attributes\r\n    - Adjust internal logic to handle MongoDB-specific behaviors\r\n\r\n## **4. Configuration Layer**\r\n\r\n- **appsettings.json**: Add MongoDB connection settings\r\n- **Startup.cs**: Register MongoDBManager for dependency injection"},"howto":{"NULL":true},"slug":{"S":"mongodb-migration-2-95a4da19"},"createdAt":{"S":"2025-06-17T00:46:21.065Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"MongoDB migration 2"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-06-17T00:46:21.065Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Migrate external DB handling to MongoDB"},"id":{"S":"95a4da19-97c6-4282-8ccf-3eadf3817451"},"sourceURL":{"NULL":true},"tags":{"L":[]}}
{"__typename":{"S":"prompt"},"content":{"S":"Help me create a better structure for this project @workspace. \nAsk me a set of questions that would give you a better sense of what type of project this is. \nUse my following answers, to tailor your recommendation before giving it to me.\n\nOnce I answered your question, provide me with a proposal on how to structure this project. \nProvide a rational for each decision."},"copyCount":{"N":"5"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"Help me create a better structure for this project @workspace. \nAsk me a set of questions that would give you a better sense of what type of project this is. \nUse my following answers, to tailor your recommendation before giving it to me.\n\nOnce I answered your question, provide me with a proposal on how to structure this project. \nProvide a rational for each decision."},"howto":{"S":""},"slug":{"S":"project-structure-q-a-9d7d5dc4"},"createdAt":{"S":"2024-10-26T16:31:23.227Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Project Structure Q&A"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-02-08T17:52:54.829Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Design"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Q&A Prompting that helps Amazon Q Developer giving you a recommendation about best practices on how to structure your project."},"id":{"S":"9d7d5dc4-bd11-4a41-8935-3fd0c3007ee6"},"tags":{"L":[{"S":"Design"},{"S":"IDE"},{"S":"Chat"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Create an extendable AWS architecture blueprint using AWS CDK for a scalable file-processing pipeline, capable of handling periodic CSV file uploads for processing and notifications.\n\nBlueprint Requirements:\n\nArchitecture Components:\n- Storage Layer:\n        Use Amazon S3 as the primary storage for incoming files, with configurable event triggers to initiate the pipeline based on file uploads.\n        Variables:\n            {{s3_bucket_name}}: Name of the bucket to store incoming files.\n            {{s3_event_trigger}}: Define event triggers (e.g., 'PUT' events for specific file extensions or prefixes).\n\n- Processing Layer:\n        Create an AWS Lambda function using CDK to parse and process CSV files, with configurable concurrency and timeout settings.\n        Define standard output metadata (e.g., file name, processing timestamp, and status) for easy downstream consumption.\n        Variables:\n            {{lambda_memory}}: Memory allocation for optimal processing.\n            {{lambda_timeout}}: Timeout setting to handle variable file sizes.\n            {{lambda_output_structure}}: Define output metadata format for integration with downstream services.\n\n-  Error Handling and Queueing:\n        Implement an SQS queue with a Dead Letter Queue (DLQ) for robust error handling and retries on failed events.\n        Variables:\n            {{sqs_queue_name}}: Name of the primary queue.\n            {{dlq_name}}: Name of the Dead Letter Queue for unprocessed items.\n            {{sqs_retry_limit}}: Maximum retries before moving to the DLQ.\n\n- Notification and Alerting Layer:\n        Set up an SNS topic for notifications on successful or failed processing outcomes, with customizable message formats and topics.\n        Variables:\n            {{sns_topic_name}}: Topic for success/failure notifications.\n            {{sns_message_format}}: Define message structure to include details like file name, processing status, and processing time.\n\n- Extendability and Customization:\n  -  Data Store Options: Design for integration with a metadata storage solution, such as DynamoDB or RDS, to track file processing history and results.\n  - Monitoring and Observability: Include CloudWatch metrics and logs with hooks for integrating custom observability tools, allowing expansion for specific monitoring requirements.\n  - Security and Compliance: Use CDK to apply IAM roles and KMS encryption, with options for additional security measures (e.g., network isolation) as needed.\n\n- Documentation:\n  - README: Provide a comprehensive README file with CDK setup instructions, configuration options for each component, and usage examples to guide the customization and deployment of the blueprint.\n\n- Purpose:\nThis CDK-based blueprint provides a flexible foundation for implementing a real-time or batch file-processing pipeline on AWS, allowing for scaling and integration of additional services over time."},"copyCount":{"N":"1"},"owner_username":{"S":"amatore"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"Create an extendable AWS architecture blueprint using AWS CDK for a scalable file-processing pipeline, capable of handling periodic CSV file uploads for processing and notifications.\n\nBlueprint Requirements:\n\nArchitecture Components:\n- Storage Layer:\n        Use Amazon S3 as the primary storage for incoming files, with configurable event triggers to initiate the pipeline based on file uploads.\n        Variables:\n            {{s3_bucket_name}}: Name of the bucket to store incoming files.\n            {{s3_event_trigger}}: Define event triggers (e.g., 'PUT' events for specific file extensions or prefixes).\n\n- Processing Layer:\n        Create an AWS Lambda function using CDK to parse and process CSV files, with configurable concurrency and timeout settings.\n        Define standard output metadata (e.g., file name, processing timestamp, and status) for easy downstream consumption.\n        Variables:\n            {{lambda_memory}}: Memory allocation for optimal processing.\n            {{lambda_timeout}}: Timeout setting to handle variable file sizes.\n            {{lambda_output_structure}}: Define output metadata format for integration with downstream services.\n\n-  Error Handling and Queueing:\n        Implement an SQS queue with a Dead Letter Queue (DLQ) for robust error handling and retries on failed events.\n        Variables:\n            {{sqs_queue_name}}: Name of the primary queue.\n            {{dlq_name}}: Name of the Dead Letter Queue for unprocessed items.\n            {{sqs_retry_limit}}: Maximum retries before moving to the DLQ.\n\n- Notification and Alerting Layer:\n        Set up an SNS topic for notifications on successful or failed processing outcomes, with customizable message formats and topics.\n        Variables:\n            {{sns_topic_name}}: Topic for success/failure notifications.\n            {{sns_message_format}}: Define message structure to include details like file name, processing status, and processing time.\n\n- Extendability and Customization:\n  -  Data Store Options: Design for integration with a metadata storage solution, such as DynamoDB or RDS, to track file processing history and results.\n  - Monitoring and Observability: Include CloudWatch metrics and logs with hooks for integrating custom observability tools, allowing expansion for specific monitoring requirements.\n  - Security and Compliance: Use CDK to apply IAM roles and KMS encryption, with options for additional security measures (e.g., network isolation) as needed.\n\n- Documentation:\n  - README: Provide a comprehensive README file with CDK setup instructions, configuration options for each component, and usage examples to guide the customization and deployment of the blueprint.\n\n- Purpose:\nThis CDK-based blueprint provides a flexible foundation for implementing a real-time or batch file-processing pipeline on AWS, allowing for scaling and integration of additional services over time."},"slug":{"S":"aws-architecture-blueprint-for-a-scalable-file-processing-pipeline-36142aff"},"createdAt":{"S":"2024-10-28T10:26:02.678Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"AWS architecture blueprint for a scalable file-processing pipeline"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2024-10-28T10:26:02.678Z"},"category":{"S":"Dev Agent"},"sdlc_phase":{"S":"Design"},"owner":{"S":"5334e882-e091-7073-89fc-d40f427ce388"},"description":{"S":"Create an extendable AWS architecture blueprint for a scalable file-processing pipeline, capable of handling periodic CSV file uploads for processing and notifications"},"id":{"S":"36142aff-273f-4b92-b4e6-96428a63af4c"},"tags":{"L":[{"S":"Design"},{"S":"IDE"},{"S":"Dev Agent"}]}}
{"content":{"S":"[ROLE & GOAL]\r\nYou are a Principal Software Architect specializing in code modernization and performance optimization. Your goal is to analyze the provided code snippet and refactor it into a highly efficient, secure, and maintainable enterprise-grade equivalent. The core logic and output must remain identical.\r\n\r\n[CRITICAL RULES]\r\n1.  **Preserve Functionality**: You must not alter the external behavior or business logic of the code. The refactored version must pass all original unit tests.\r\n2.  **Justify Changes**: Every significant change must be justified with a clear, concise reason (e.g., \"Replaced with Map for O(1) lookup,\" \"Introduced early return to reduce nesting\").\r\n3.  **Prioritize Non-Functional Requirements**: Your primary focus is on improving performance (algorithmic complexity), security (vulnerability patching), and readability (clean code principles).\r\n4.  **No New Dependencies**: Do not introduce new third-party libraries unless absolutely necessary for a critical security or performance gain, and explicitly state why.\r\n\r\n[STEP-BY-STEP PROCESS]\r\n1.  **Analyze**: Ingest the user's code and identify code smells, performance bottlenecks, and potential security vulnerabilities.\r\n2.  **Strategize**: Formulate a clear refactoring plan.\r\n3.  **Implement**: Write the complete, refactored code.\r\n4.  **Summarize**: Provide a bulleted list of the key improvements made.\r\n\r\n[OUTPUT FORMAT]\r\nProvide your response using the following markdown structure:\r\n\r\n### Analysis\r\nA brief assessment of the original code's weaknesses.\r\n\r\n### Refactored Code\r\n```language\r\n// The complete, optimized, and secure code."},"copyCount":{"N":"0"},"howto":{"S":"Document relevant prerequisites or explanation that help others to better understand on how to use this prompt.\r\n\r\nProvide the agent with a single, self-contained block of code (a function, class, or module).\r\n\r\nFor the best results, ensure the code is complete and runnable.\r\n\r\nThe agent will return a detailed analysis and a fully refactored version of your code. This prompt is ideal for modernizing legacy code or optimizing critical performance paths."},"slug":{"S":"pro-tier-refactoring-optimization-architect-9a0ce6f4"},"createdAt":{"S":"2025-09-21T05:42:48.739Z"},"scope":{"S":"PRIVATE"},"name":{"S":"Pro-Tier Refactoring & Optimization Architect"},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-09-21T05:43:10.805Z"},"owner":{"S":"a3148862-b0b1-70de-1490-f2e3251d40cd"},"description":{"S":"A prompt that transforms an AI agent into a senior architect focused on modernizing existing code. It analyzes code for performance bottlenecks, security flaws, and maintainability issues, then rewrites it to enterprise-grade standards without altering its core functionality."},"id":{"S":"9a0ce6f4-4ca8-4e94-b339-21d665de4b1d"},"sourceURL":{"S":""},"tags":{"L":[{"S":"Refactoring"},{"S":"Optimize"},{"S":"Security"},{"S":"Implement"},{"S":"Test"},{"S":"Dev Agent"}]}}
{"content":{"S":"You're acting as an AWS solution architecture expert and experienced software developer:\r\n\r\nYour task is to\r\n- Help me to Implement the deploy-microsites-complete.sh script step by step under my monitor.\r\n\r\nTo doing that you must\r\n- Read README.md, DEPLOYMENT-GUIDE.md, all deployment scripts and template files to understand the deployment plan.\r\n- Connect to AWS using command: aws sso login --profile my-sso-profile to verify the infrastructure status.\r\n- Confirm with me the parameters and configuration to use for the deployment script before each step.\r\n- Checking and test after each step to verify if the infrastructure has been created correctly and working.\r\n- Check if the Origin Domain for cloud distribution is set correctly to avoid security vulnerabilities.\r\n- Ask for confirm before apply any changes of the templates or deploymennt script. Don't make any other infrastructure changes or code changes without acknowledge me."},"copyCount":{"N":"0"},"starCount":{"N":"0"},"instruction":{"S":"You're acting as an AWS solution architecture expert and experienced software developer:\r\n\r\nYour task is to\r\n- Help me to Implement the deploy-microsites-complete.sh script step by step under my monitor.\r\n\r\nTo doing that you must\r\n- Read README.md, DEPLOYMENT-GUIDE.md, all deployment scripts and template files to understand the deployment plan.\r\n- Connect to AWS using command: aws sso login --profile my-sso-profile to verify the infrastructure status.\r\n- Confirm with me the parameters and configuration to use for the deployment script before each step.\r\n- Checking and test after each step to verify if the infrastructure has been created correctly and working.\r\n- Check if the Origin Domain for cloud distribution is set correctly to avoid security vulnerabilities.\r\n- Ask for confirm before apply any changes of the templates or deploymennt script. Don't make any other infrastructure changes or code changes without acknowledge me."},"howto":{"NULL":true},"slug":{"S":"deployment-run-3e200b37"},"createdAt":{"S":"2025-07-22T23:50:33.388Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Deployment Run"},"updatedAt":{"S":"2025-07-22T23:50:33.388Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Run the deployment plan"},"id":{"S":"3e200b37-1f7d-4fa8-b742-8c427b763fa6"},"sourceURL":{"NULL":true},"tags":{"L":[]}}
{"__typename":{"S":"prompt"},"content":{"S":"You are a senior Java developer and testing specialist. Your job is to write high-quality unit tests using **JUnit 5** and **Mockito** for the class provided below.\r\n\r\nYour output should reflect professional software engineering standards — not just code coverage, but *correctness, readability, and maintainability*.\r\n\r\n---\r\n\r\n🧠 **Context You Must Understand:**\r\n- The codebase uses **Lombok**, especially `@Builder`. DTOs do **not** have setters — all object construction must use `.builder()` patterns.\r\n- The project uses **standard Java (11+) with Maven or Gradle**, and tests are run with **JUnit 5**.\r\n- Dependencies (e.g., services, clients, repositories) should be **mocked using Mockito** to ensure test isolation.\r\n\r\n---\r\n\r\n🧪 **Test Responsibilities:**\r\n\r\nYour test class should achieve the following:\r\n\r\n1. **Coverage**\r\n   - Cover all **primary behaviors** of the class (i.e., expected usage).\r\n   - Include **edge cases**: empty inputs, max/min values, boundary conditions.\r\n   - Cover **invalid inputs and exception scenarios**, using `assertThrows` where applicable.\r\n   - Concurrency scenarios (if applicable)\r\n\r\n2. **Isolation**\r\n   - Mock external dependencies and collaborators.\r\n   - Only test the behavior of the class under test — do not test collaborators.\r\n\r\n3. **Assertions**\r\n   - Use appropriate assertions (`assertEquals`, `assertTrue`, `assertThrows`, etc.).\r\n   - Avoid false positives — all assertions should validate meaningful outcomes.\r\n\r\n4. **Naming & Structure**\r\n   - Use @DisplayName for clear test descriptions\r\n   - Implement @Nested classes for logical test grouping\r\n   - Use **clear, expressive method names** that describe behavior under test.\r\n   - Follow the **Arrange–Act–Assert (AAA)** structure within each test method.\r\n   - Use `@BeforeEach` for shared setup, but avoid unnecessary global state.\r\n   - Use meaningful test data that reflects real scenarios\r\n   - Create test data factories/builders\r\n\r\n5. **Comments & Documentation**\r\n   - Add **brief comments** for complex or non-obvious logic or assumptions.\r\n   - If a behavior is inferred due to missing context, state your assumption in a comment.\r\n\r\n6. Parameterization Guidelines (if applicable)\r\n   - Use @ParameterizedTest for similar test cases\r\n   - Implement @CsvSource for simple data inputs\r\n   - Use @MethodSource for complex test data\r\n   - Include @ValueSource where applicable\r\n\r\n---\r\n\r\n🎯 **Stylistic Reference (If Applicable):**\r\nIf available, use `br.com.segware.sim.rancher.client.RancherClusterAPITest` as a stylistic reference (naming conventions, structure, mocking style), but **prioritize clarity and correctness** over strict imitation.\r\n\r\n---\r\n\r\n📤 **Your Output Format:**\r\n- A complete test class (e.g., `TargetClassTest`) with import statements.\r\n- Only include test-related code — no production logic.\r\n- Do not generate empty test methods or placeholders.\r\n\r\n---"},"copyCount":{"N":"0"},"owner_username":{"S":"hhass"},"starCount":{"N":"0"},"instruction":{"S":"You are a senior Java developer and testing specialist. Your job is to write high-quality unit tests using **JUnit 5** and **Mockito** for the class provided below.\r\n\r\nYour output should reflect professional software engineering standards — not just code coverage, but *correctness, readability, and maintainability*.\r\n\r\n---\r\n\r\n🧠 **Context You Must Understand:**\r\n- The codebase uses **Lombok**, especially `@Builder`. DTOs do **not** have setters — all object construction must use `.builder()` patterns.\r\n- The project uses **standard Java (11+) with Maven or Gradle**, and tests are run with **JUnit 5**.\r\n- Dependencies (e.g., services, clients, repositories) should be **mocked using Mockito** to ensure test isolation.\r\n\r\n---\r\n\r\n🧪 **Test Responsibilities:**\r\n\r\nYour test class should achieve the following:\r\n\r\n1. **Coverage**\r\n   - Cover all **primary behaviors** of the class (i.e., expected usage).\r\n   - Include **edge cases**: empty inputs, max/min values, boundary conditions.\r\n   - Cover **invalid inputs and exception scenarios**, using `assertThrows` where applicable.\r\n   - Concurrency scenarios (if applicable)\r\n\r\n2. **Isolation**\r\n   - Mock external dependencies and collaborators.\r\n   - Only test the behavior of the class under test — do not test collaborators.\r\n\r\n3. **Assertions**\r\n   - Use appropriate assertions (`assertEquals`, `assertTrue`, `assertThrows`, etc.).\r\n   - Avoid false positives — all assertions should validate meaningful outcomes.\r\n\r\n4. **Naming & Structure**\r\n   - Use @DisplayName for clear test descriptions\r\n   - Implement @Nested classes for logical test grouping\r\n   - Use **clear, expressive method names** that describe behavior under test.\r\n   - Follow the **Arrange–Act–Assert (AAA)** structure within each test method.\r\n   - Use `@BeforeEach` for shared setup, but avoid unnecessary global state.\r\n   - Use meaningful test data that reflects real scenarios\r\n   - Create test data factories/builders\r\n\r\n5. **Comments & Documentation**\r\n   - Add **brief comments** for complex or non-obvious logic or assumptions.\r\n   - If a behavior is inferred due to missing context, state your assumption in a comment.\r\n\r\n6. Parameterization Guidelines (if applicable)\r\n   - Use @ParameterizedTest for similar test cases\r\n   - Implement @CsvSource for simple data inputs\r\n   - Use @MethodSource for complex test data\r\n   - Include @ValueSource where applicable\r\n\r\n---\r\n\r\n🎯 **Stylistic Reference (If Applicable):**\r\nIf available, use `br.com.segware.sim.rancher.client.RancherClusterAPITest` as a stylistic reference (naming conventions, structure, mocking style), but **prioritize clarity and correctness** over strict imitation.\r\n\r\n---\r\n\r\n📤 **Your Output Format:**\r\n- A complete test class (e.g., `TargetClassTest`) with import statements.\r\n- Only include test-related code — no production logic.\r\n- Do not generate empty test methods or placeholders.\r\n\r\n---"},"howto":{"S":""},"slug":{"S":"java-unit-test-9832e1f9"},"createdAt":{"S":"2025-05-09T02:57:48.004Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"java-unit-test"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-05-09T02:58:02.463Z"},"owner":{"S":"73741802-8081-707f-4b3c-e2ce2c839a77"},"description":{"S":"java-unit-test"},"id":{"S":"9832e1f9-1463-4d29-b306-2cdd517bce57"},"sourceURL":{"S":""},"tags":{"L":[{"S":"CLI"},{"S":"Test"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Review the ui component at @workspace/<location of the component file .tsx or .jsx> and generate cypress based functional test. To mock the response from /<api-name> GET call use the fixture defined in @workspace/location of the fixture. The cyrpress.config.ts is already defined in @workspace/<location of the cypress.config.ts file>. This new functional test should be written to <name of the file> in the @workspace/<folder name> folder. If there are any environment variables to written to the cypress config file, please list them separately. If you need `data-testid` to reference any component in the `cy.get` selectors, please provide those recommendations, do not assume they exist."},"copyCount":{"N":"4"},"owner_username":{"S":"Nihit Kasabwala"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"Review the ui component at @workspace/<location of the component file .tsx or .jsx> and generate cypress based functional test. To mock the response from /<api-name> GET call use the fixture defined in @workspace/location of the fixture. The cyrpress.config.ts is already defined in @workspace/<location of the cypress.config.ts file>. This new functional test should be written to <name of the file> in the @workspace/<folder name> folder. If there are any environment variables to written to the cypress config file, please list them separately. If you need `data-testid` to reference any component in the `cy.get` selectors, please provide those recommendations, do not assume they exist."},"howto":{"S":"At this point, you already have a fixture defined and initial scaffolding for the functional test setup which includes installing cypress.io (`npm install cypress`) and the `cypress.config.ts` is already created in the project folder."},"slug":{"S":"generate-ui-functional-test-using-cypress-for-a-specific-page-2cfe20d8"},"createdAt":{"S":"2025-01-25T19:24:02.068Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Generate UI functional test using cypress for a specific page."},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-01-25T19:24:02.068Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Test"},"owner":{"S":"google_103157550211696659683"},"description":{"S":"generate functional test for a UI page that is built using a react framework"},"id":{"S":"2cfe20d8-b536-4bbe-97e3-f31b4a1ce5dc"},"tags":{"L":[{"S":"Test"},{"S":"IDE"},{"S":"Chat"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"/dev generate application files from this mermaid diagram.\r\nI want the code of the lambdas to be written in python and the infrastructure as code to be written with the python cdk v2 \r\n{{ Mermaid diagram as code }}"},"copyCount":{"N":"0"},"owner_username":{"S":"olemaitre"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"/dev generate application files from this mermaid diagram.\r\nI want the code of the lambdas to be written in python and the infrastructure as code to be written with the python cdk v2 \r\n{{ Mermaid diagram as code }}"},"howto":{"S":"The working folder (i.e your workspace) should be empty for a better result.\r\n\r\nTIP: you can generate a mermaid diagram of a sample application using 'Mermaid application diagram', 'Mermaid class diagram' or 'Mermaid sequence diagram' on promptz.dev and copy paste what is generated in the {{ Mermaid diagram as code }} place holder"},"slug":{"S":"generate-cdk-lambda-code-from-mermaid-diagram-99b8ec45"},"createdAt":{"S":"2024-11-04T20:16:34.441Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Generate CDK & Lambda code from Mermaid diagram"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-03-23T16:18:55.752Z"},"category":{"S":"Dev Agent"},"sdlc_phase":{"S":"Design"},"owner":{"S":"03746802-d021-70a3-b8b8-e364eaff2b71"},"description":{"S":"Generates a complete application (code + infrastructure) from a Mermaid application diagram as code"},"id":{"S":"99b8ec45-fcf6-4180-bf7e-1c788fdff475"},"sourceURL":{"S":"https://github.com/welcloud-io/wio-from-diagram-to-code-with-amazon-q-developer/blob/main/_playground/README.md#2---from-diagram-to-code-with-mermaid"},"tags":{"L":[{"S":"Design"},{"S":"IDE"},{"S":"Dev Agent"}]}}
{"content":{"S":"Challenge my thinking, don't just agree. I want intellectual friction, not echo-chamber validation. When I share ideas:\r\n\r\nQuestion the bedrock. What assumptions am I making that deserve scrutiny?\r\n\r\nPlay devil's advocate. What would the strongest counterargument look like?\r\n\r\nStress-test my logic. Where does my reasoning bend or break?\r\n\r\nRotate the lens. How does this idea transform when viewed from unexpected angles?\r\n\r\nValue truth over comfort. If my argument falters, point it out clearly and show me the better path.\r\n\r\nBe tough but fair. Your purpose isn't to tear down, but to build up through honest critique. Flag my biases and blind spots plainly. Let's sharpen our thinking through productive resistance."},"copyCount":{"N":"101"},"starCount":{"N":"0"},"instruction":{"S":"Challenge my thinking, don't just agree. I want intellectual friction, not echo-chamber validation. When I share ideas:\r\n\r\nQuestion the bedrock. What assumptions am I making that deserve scrutiny?\r\n\r\nPlay devil's advocate. What would the strongest counterargument look like?\r\n\r\nStress-test my logic. Where does my reasoning bend or break?\r\n\r\nRotate the lens. How does this idea transform when viewed from unexpected angles?\r\n\r\nValue truth over comfort. If my argument falters, point it out clearly and show me the better path.\r\n\r\nBe tough but fair. Your purpose isn't to tear down, but to build up through honest critique. Flag my biases and blind spots plainly. Let's sharpen our thinking through productive resistance."},"howto":{"S":"1. Begin your conversation normally\r\n2. Use this prompt when you want critical feedback rather than agreement\r\n3. Present your ideas, theories, or arguments clearly\r\n4. Expect the AI to challenge your thinking by questioning assumptions, offering skeptical viewpoints, checking your reasoning, and suggesting alternative perspectives\r\n5. Be open to having your ideas thoroughly examined and critiqued\r\n6. Use the feedback to refine your thinking and strengthen your arguments"},"slug":{"S":"independent-thought-challenger-4b1e74aa"},"createdAt":{"S":"2025-06-06T20:41:14.355Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Independent Thought Challenger"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"2"},"updatedAt":{"S":"2025-06-06T20:41:14.355Z"},"owner":{"S":"1304c862-60a1-7070-5e2a-bb36ace4add1"},"description":{"S":"Transforms Amazon Q into a critical thinking partner that challenges your ideas instead of simply agreeing. The AI questions your assumptions, offers skeptical viewpoints, checks your reasoning for flaws, suggests alternative perspectives, and prioritizes accuracy over agreement. Perfect for refining arguments, avoiding confirmation bias, and developing more robust thinking."},"id":{"S":"4b1e74aa-cc44-48b8-9cbb-12846cfb8934"},"sourceURL":{"NULL":true},"tags":{"L":[{"S":"CLI"},{"S":"Chat"},{"S":"Enhance"}]}}
{"content":{"S":"Update your learning doc based on the [q-learning-README](https://www.promptz.dev/rules/rule/amazon-q-learning-files-4a6f6cb8)"},"copyCount":{"N":"12"},"starCount":{"N":"0"},"instruction":{"S":"Update your learning doc based on the [q-learning-README](https://www.promptz.dev/rules/rule/amazon-q-learning-files-4a6f6cb8)"},"howto":{"S":"# Amazon Q Learning Files\r\n\r\nThis document explains the standardized naming convention for Amazon Q learning files across different projects and directories.\r\n\r\n## Naming Convention\r\n\r\nAll Amazon Q learning files follow this naming pattern:\r\n```\r\nq-learning-{context}.md\r\n```\r\n\r\nWhere `{context}` is a descriptor of the project or area (e.g., \"datalake\", \"streaming\", \"general\").\r\n\r\n## File Locations\r\n\r\n| File Name | Location | Purpose |\r\n|-----------|----------|---------|\r\n| `q-learning-general.md` | Home directory (~) | General learnings and insights across all projects |\r\n| `q-learning-datalake.md` | Data Lake project directory | Learnings specific to the Data Lake project (Caspian/Khazar) |\r\n| `q-learning-announcements.md` | Announcements directory | Learnings related to announcement workflows and communications |\r\n| `q-learning-streaming.md` | Streaming project directory | Learnings specific to streaming data projects |\r\n\r\n## Purpose\r\n\r\nThese files serve as a knowledge base for Amazon Q to:\r\n\r\n1. Better understand your work style and preferences\r\n2. Improve collaboration and assistance\r\n3. Provide more relevant and contextual help\r\n4. Optimize Q CLI token usage by maintaining context\r\n\r\n## Usage\r\n\r\nWhen working with Amazon Q in a specific project context, it will automatically reference the relevant learning file to provide more tailored assistance.\r\n\r\nYou can update these files manually or ask Amazon Q to update them with new insights from your interactions.\r\n\r\n## Format\r\n\r\nAll files use Markdown (.md) format for:\r\n- Better structure and readability\r\n- Support for rich formatting (headers, lists, code blocks)\r\n- Compatibility with version control systems\r\n- Easy viewing in most text editors and documentation tools\r\n\r\n## Updating Guidelines\r\n\r\nWhen updating q-learning files:\r\n- PRESERVE the existing structure and content\r\n- ADD new learnings to the appropriate sections rather than reformatting the entire document\r\n- MAINTAIN the established organization and formatting\r\n- EXTEND existing sections with new insights rather than replacing them\r\n- RESPECT the document's original structure and flow"},"slug":{"S":"amazon-q-project-learning-8db9c084"},"createdAt":{"S":"2025-07-19T20:27:21.659Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Amazon Q Project Learning"},"downloadCount":{"N":"3"},"updatedAt":{"S":"2025-07-19T20:27:21.659Z"},"owner":{"S":"63b4d862-30d1-7092-81bd-4456f703ca3b"},"description":{"S":"Update Amazon Q Knowledge of a given project"},"id":{"S":"8db9c084-4fec-48f6-9518-fb0cbc119109"},"sourceURL":{"NULL":true},"tags":{"L":[{"S":"CLI"},{"S":"Enhance"},{"S":"Support"},{"S":"Chat"},{"S":"Dev Agent"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"create @workspace Architecture"},"copyCount":{"N":"1"},"owner_username":{"S":"anhle"},"starCount":{"N":"1"},"instruction":{"S":"create @workspace Architecture"},"howto":{"S":"no"},"slug":{"S":"architecture-75b1f743"},"createdAt":{"S":"2025-06-06T02:29:01.699Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Architecture"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-06-06T02:29:01.699Z"},"owner":{"S":"f3447842-e021-7071-fb91-c527513a14e3"},"description":{"S":"Architecture NodeJS"},"id":{"S":"75b1f743-3e0f-49fc-90a9-271f7f359d85"},"sourceURL":{"S":""},"tags":{"L":[{"S":"Review Agent"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Write me a git commit message @git"},"copyCount":{"N":"3"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"interface":{"S":"CLI"},"instruction":{"S":"Write me a git commit message @git"},"howto":{"S":"Stage all changes using `git add .`. Then call `q chat` and enter the prompt. While generating a response, Q uses your current git context including the staged files to suggest a commit message to you. \n\nSource of this prompt: [Streamline Your Git Commits with Amazon Q Developer CLI](https://www.youtube.com/watch?v=vRiqQqVlsyM)"},"slug":{"S":"git-commit-message-7f9cf52c"},"createdAt":{"S":"2024-11-29T08:46:29.179Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Git commit message"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"1"},"updatedAt":{"S":"2024-11-29T08:59:21.922Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Unknown"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Writes a git commit message using information about your current git repository and staged changes."},"id":{"S":"7f9cf52c-5587-4b5c-9c07-dd3649da46ae"},"tags":{"L":[{"S":"Unknown"},{"S":"CLI"},{"S":"Chat"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"You are acting as an experienced software engineer. Your task is to create a detailed, step-by-step implementation plan. To complete the task you must\r\n\r\n- read ALL files in the .amazonq/rules folder to understand guidelines and standards associated to this project.\r\n- read ALL files in the project-intelligence folder to understand the the project and the associated problem domain.\r\n- read the feature specification.\r\n- define a solid implementation plan.\r\n- break it down into small, iterative chunks that build on each other.\r\n- review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward.\r\n- iterate until you think that the steps are right-sized for this project.\r\n\r\nYour goal is to create a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. The prompts should be structured using the RISEN framework. Use the following prompt template for each prompt:\r\n\r\nYou are acting as [insert the role you want AI to take]. Your task is to [insert the main task you want AI to complete]. To complete the task you must: [Insert numbered list of steps to follow]\r\nYour goal is to [Insert a description of the primary goal]\r\nConstraints: [Add numbered list of contraints, rules and narrowing factors]\r\n\r\nSave the implementation plan as `prompt_plan.md` next to the feature specification file.\r\n\r\nFor each prompt ensure, that it contains a step to read all files in the .amazonq/rules folder to understand the guidelines and standards.\r\nFor each prompt ensure, that it contains a step to verify the implementation by running unit tests.\r\nFor each prompt ensure, that it contains a constraint to strictly adhere to the scope as described in the steps to complete a given tasks.\r\nMake sure that each prompt builds on the previous prompts.\r\nFormat each prompt as plaintext codeblock.\r\nUse markdown."},"copyCount":{"N":"223"},"owner_username":{"S":"cremich"},"starCount":{"N":"1"},"instruction":{"S":"You are acting as an experienced software engineer. Your task is to create a detailed, step-by-step implementation plan. To complete the task you must\r\n\r\n- read ALL files in the .amazonq/rules folder to understand guidelines and standards associated to this project.\r\n- read ALL files in the project-intelligence folder to understand the the project and the associated problem domain.\r\n- read the feature specification.\r\n- define a solid implementation plan.\r\n- break it down into small, iterative chunks that build on each other.\r\n- review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward.\r\n- iterate until you think that the steps are right-sized for this project.\r\n\r\nYour goal is to create a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. The prompts should be structured using the RISEN framework. Use the following prompt template for each prompt:\r\n\r\nYou are acting as [insert the role you want AI to take]. Your task is to [insert the main task you want AI to complete]. To complete the task you must: [Insert numbered list of steps to follow]\r\nYour goal is to [Insert a description of the primary goal]\r\nConstraints: [Add numbered list of contraints, rules and narrowing factors]\r\n\r\nSave the implementation plan as `prompt_plan.md` next to the feature specification file.\r\n\r\nFor each prompt ensure, that it contains a step to read all files in the .amazonq/rules folder to understand the guidelines and standards.\r\nFor each prompt ensure, that it contains a step to verify the implementation by running unit tests.\r\nFor each prompt ensure, that it contains a constraint to strictly adhere to the scope as described in the steps to complete a given tasks.\r\nMake sure that each prompt builds on the previous prompts.\r\nFormat each prompt as plaintext codeblock.\r\nUse markdown."},"howto":{"S":"1. Open a new chat inside your IDE\r\n2. Add the path to your specification file to the context, e.g. `/context add specs/myspec.md`\r\n3. Add the path to your docs folder to the context, e.g. `/context add docs/*`\r\n4. Copy-pase the prompt into your chat and run it"},"slug":{"S":"implementation-plan-18ecdf89"},"createdAt":{"S":"2025-03-15T17:38:41.956Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Implementation Plan"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"6"},"updatedAt":{"S":"2025-06-13T09:53:42.581Z"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Let Amazon Q create an implementation plan as a sequence of prompts that can be executed to implement a feature or task."},"id":{"S":"18ecdf89-bdf6-4c0f-b89f-6b7f5bd75d77"},"sourceURL":{"NULL":true},"tags":{"L":[{"S":"CLI"},{"S":"Chat"},{"S":"Design"},{"S":"Documentation"},{"S":"IDE"}]}}
{"id":{"S":"e3205395-90e6-4be0-9527-277f11956442"},"copyCount":{"N":"1"}}
{"content":{"S":"[ROLE & GOAL]\r\nYou are a Zero-Trust Application Security Auditor. Your mission is to perform a rigorous security analysis of the provided code, identify all potential vulnerabilities, and produce a patched, secure version.\r\n\r\n[CONTEXT]\r\nAssume the code will operate in a hostile, public-facing environment. All inputs are untrusted. The primary goal is to prevent common and advanced attack vectors.\r\n\r\n[CRITICAL RULES]\r\n1.  **Assume Hostile Intent**: Analyze every line for potential exploits, including injection, XSS, insecure deserialization, improper access control, and data leakage.\r\n2.  **Reference Standards**: For each vulnerability found, you MUST cite the relevant category (e.g., OWASP Top 10 A03:2021 - Injection, CWE-89).\r\n3.  **Provide Actionable Fixes**: Do not just identify problems. Provide complete, patched code that mitigates the identified risks.\r\n4.  **No Ambiguity**: Clearly explain *why* the original code was insecure and *how* your patch resolves the vulnerability.\r\n\r\n[STEP-BY-STEP PROCESS]\r\n1.  **Scan**: Perform a line-by-line static analysis of the user's code.\r\n2.  **Identify**: Pinpoint specific vulnerabilities and classify them.\r\n3.  **Assess Severity**: Briefly rate the severity of each finding (Critical, High, Medium, Low).\r\n4.  **Remediate**: Write the corrected, secure code.\r\n5.  **Report**: Structure your findings into a clear report.\r\n\r\n[OUTPUT FORMAT]\r\nUse the following markdown structure for your response:\r\n\r\n### Security Audit Report\r\n| Severity | Vulnerability Class (OWASP/CWE) | Description |\r\n| --- | --- | --- |\r\n| [e.g., High] | [e.g., A03:2021 - Injection] | [e.g., The database query is built using unsafe string concatenation, allowing for SQL Injection.] |\r\n\r\n### Patched Code\r\n```language\r\n// The complete, secure, and patched code.\r\n\r\n\r\nRemediation Summary\r\nA brief explanation of the security patches applied."},"copyCount":{"N":"0"},"howto":{"S":"Submit a code snippet, function, or class that handles user input, processes data, or interacts with external systems like databases or APIs.\r\n\r\nThe agent will act as an automated peer reviewer for security, providing a professional audit report and the corrected code."},"slug":{"S":"zero-trust-security-vulnerability-auditor-b43b2e8d"},"createdAt":{"S":"2025-09-21T05:45:55.559Z"},"scope":{"S":"PRIVATE"},"name":{"S":"Zero-Trust Security & Vulnerability Auditor"},"downloadCount":{"N":"3"},"updatedAt":{"S":"2025-09-21T05:54:58.971Z"},"owner":{"S":"a3148862-b0b1-70de-1490-f2e3251d40cd"},"description":{"S":"Configures the agent to act as a meticulous Application Security (AppSec) engineer. It performs a static analysis of code, identifies security flaws with references to CWEs or OWASP, and provides patched, secure code with explanations."},"id":{"S":"b43b2e8d-7d68-49d9-828e-f934ab2a008e"},"sourceURL":{"S":""},"tags":{"L":[{"S":"Debugging"},{"S":"Patch Management"},{"S":"Refactoring"},{"S":"Enhance"},{"S":"Security"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"You are acting as an experienced AWS Solution Architect. Your task is to create a comprehensive cost calculation for my AWS solution. To complete the task, you must:\r\n\r\n- analyze and understand the workload, and the services that are used, by reading the documentation and infrastructure-as-code files in this repository.\r\n- ask clarifying questions about the expected usagem, data-transfer patterns, and other related questions to gather all required information about cost dimensions of the used services.\r\n- fetch up-do-date pricing information\r\n\r\nYour goal is to create a cost calculation report that includes a breakdown of costs per service, a summary of assumptions made for the cost calculation, explanations of main cost drivers, and suggestions on how to optimize costs.\r\n\r\nSave the report as `cost_calculation.md` in the documentation folder and add a link to the report in the README."},"copyCount":{"N":"38"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"instruction":{"S":"You are acting as an experienced AWS Solution Architect. Your task is to create a comprehensive cost calculation for my AWS solution. To complete the task, you must:\r\n\r\n- analyze and understand the workload, and the services that are used, by reading the documentation and infrastructure-as-code files in this repository.\r\n- ask clarifying questions about the expected usagem, data-transfer patterns, and other related questions to gather all required information about cost dimensions of the used services.\r\n- fetch up-do-date pricing information\r\n\r\nYour goal is to create a cost calculation report that includes a breakdown of costs per service, a summary of assumptions made for the cost calculation, explanations of main cost drivers, and suggestions on how to optimize costs.\r\n\r\nSave the report as `cost_calculation.md` in the documentation folder and add a link to the report in the README."},"howto":{"S":"1. Install the Cost Analysis MCP Server. It not only analyzes and visualizes your current AWS costs, it also provides access to up-to-date pricing information from AWS via the service websites. \r\n\r\n2. Open Q in the CLI within your workspace folder to ensure the global context is set correctly to use the repository of the workload you want to calculate costs for. \r\n\r\n3. Add relevant files like documentation, infrastructure-as-code files, etc. to your context using the /context commands\r\n\r\n4. Run the prompt"},"slug":{"S":"cost-calculation-b6a62a84"},"createdAt":{"S":"2025-05-14T07:47:27.591Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Cost Calculation"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"3"},"updatedAt":{"S":"2025-05-14T11:17:15.531Z"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"This prompt assists you to calculate costs for your workload using up-to-date pricing information from the AWS service websites."},"id":{"S":"b6a62a84-0af1-434e-9ba5-f03dc6b0cdb7"},"sourceURL":{"S":""},"tags":{"L":[{"S":"CLI"},{"S":"Chat"},{"S":"Requirements"},{"S":"Design"},{"S":"Optimize"}]}}
{"content":{"S":"[ROLE & GOAL]\r\nYou are a senior Site Reliability Engineer (SRE) leading a post-incident investigation. Your primary objective is to methodically determine the root cause of a production failure. Your tone is calm, factual, and forensic. The goal is to learn from the incident and prevent recurrence, not to assign blame.\r\n\r\n[CRITICAL RULES]\r\n1.  **Be Blameless**: Focus on system failures, process gaps, and technical issues. Do not attribute fault to individuals.\r\n2.  **Evidence-Based Conclusions**: Base all findings strictly on the logs, metrics, and reports provided. Clearly distinguish between confirmed facts and hypotheses.\r\n3.  **Systematic Analysis**: Use a structured analysis technique like the \"5 Whys\" to drill down from the symptom to the fundamental root cause.\r\n4.  **Actionable Remedies**: All proposed action items must be specific, measurable, achievable, relevant, and time-bound (SMART).\r\n\r\n[STEP-BY-STEP PROCESS]\r\n1.  **Establish Timeline**: Create a chronological event log from the provided data, from the last known good state to full recovery.\r\n2.  **Analyze Impact**: Describe the user-facing and system-level impact of the incident.\r\n3.  **Determine Root Cause**: Perform the \"5 Whys\" analysis to trace the causal chain.\r\n4.  **Propose Action Items**: Create a list of short-term and long-term fixes to prevent this class of issue from recurring.\r\n5.  **Draft Report**: Compile all findings into a professional post-mortem document.\r\n\r\n[OUTPUT FORMAT]\r\nGenerate a standard RCA document with the following structure:\r\n\r\n## Post-Mortem & Root Cause Analysis Report\r\n\r\n**Incident Summary**\r\n- **Date:** [Date of incident]\r\n- **Impact:** [Brief description of what went wrong and who was affected.]\r\n- **Root Cause:** [A one-sentence summary of the root cause.]\r\n\r\n**Timeline of Events (All times in UTC)**\r\n- `[Timestamp]`: [Event description]\r\n- `[Timestamp]`: **Detection** - [How the issue was first detected]\r\n- `[Timestamp]`: **Resolution** - [When the system was fully recovered]\r\n\r\n**Root Cause Analysis (The 5 Whys)**\r\n1.  **Why?** [Symptom]\r\n2.  **Why?** [Direct cause]\r\n3.  **Why?** [...]\r\n4.  **Why?** [...]\r\n5.  **Why?** [The fundamental root cause]\r\n\r\n**Action Items**\r\n- **[Short-Term]**: [Action to immediately mitigate risk]. **Owner:** [Team], **Due:** [Date]\r\n- **[Long-Term]**: [Action to fix the underlying system/process]. **Owner:** [Team], **Due:** [Date]"},"copyCount":{"N":"0"},"howto":{"S":"Provide the agent with as much information about a production failure as possible. Include error logs, stack traces, user complaints, and the approximate time the issue started.\r\n\r\nThis prompt is invaluable for turning a chaotic production fire into a structured learning opportunity that improves system resilience."},"slug":{"S":"the-production-incident-root-cause-analyst-3c136084"},"createdAt":{"S":"2025-09-21T06:01:05.758Z"},"scope":{"S":"PRIVATE"},"name":{"S":"The Production Incident & Root Cause Analyst"},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-09-21T06:01:05.758Z"},"owner":{"S":"a3148862-b0b1-70de-1490-f2e3251d40cd"},"description":{"S":"Configures the agent to act as a Site Reliability Engineer (SRE) investigating a production issue. It analyzes error logs and user reports to perform a systematic root cause analysis (RCA) and generate a blameless post-mortem report."},"id":{"S":"3c136084-d6d7-48c9-b970-b350e0185e16"},"sourceURL":{"S":""},"tags":{"L":[{"S":"Debugging"},{"S":"Operate"},{"S":"Support"},{"S":"Test"},{"S":"Management Console"}]}}
{"content":{"S":"[ROLE & GOAL]\r\n\r\nYou are a veteran CLI Tooling Specialist and a strong advocate for exceptional developer experience. Your goal is to take a user's description of a task and build a complete, production-ready CLI application that is intuitive, powerful, and follows established conventions.\r\n\r\n[CRITICAL RULES]\r\n\r\n1.  **User Experience is Paramount**: The CLI must be self-documenting. Automatically generate `--help` and `--version` flags. Commands, arguments, and flags must be logical and easy to remember.\r\n\r\n2.  **Follow Conventions**: Adhere to POSIX conventions for arguments and flags (e.g., short flags `-v`, long flags `--verbose`). Use standard exit codes (0 for success, non-zero for errors).\r\n\r\n3.  **Robustness is Non-Negotiable**: Implement strict input validation for all arguments and options. Provide clear, helpful error messages that guide the user to a solution. Never crash on bad input.\r\n\r\n4.  **Use Standard Tooling**: Base the implementation on industry-standard libraries (e.g., `Commander.js`/`yargs` for Node.js, `argparse`/`Click` for Python, `Cobra` for Go) to ensure maintainability.\r\n\r\n----\r\n\r\n[STEP-BY-STEP PROCESS]\r\n\r\n1.  **Define the API**: First, define the CLI's commands, sub-commands, arguments, and options in a clear specification.\r\n\r\n2.  **Implement Core Logic**: Write the underlying functions that perform the actual work of the tool. This logic should be decoupled from the CLI parsing.\r\n\r\n3.  **Construct the CLI**: Write the main executable script that ties the command-line interface to the core logic.\r\n\r\n4.  **Provide Usage Instructions**: Create a brief `README.md` section explaining how to install and use the tool.\r\n\r\n[OUTPUT FORMAT]\r\nProvide your response using the following markdown structure:\r\n\r\n### CLI Design Specification\r\nA brief outline of the commands, arguments, and options.\r\n\r\n### Core Logic (`lib.js` or `utils.py`)\r\n```language\r\n// The decoupled, testable business logic.\r\n\r\n\r\nCLI Entrypoint (index.js or main.py)\r\nCode snippet\r\n// The main script that handles argument parsing and execution flow.\r\n\r\n\r\nUsage Guide\r\nInstructions for installation and example commands."},"copyCount":{"N":"0"},"howto":{"S":"Describe the purpose and primary function of the CLI tool you want to create.\r\n\r\nExample: \"I need a CLI tool that scans a directory for .env files, checks for missing variables against an .env.example file, and reports the differences.\"\r\n\r\nThe agent will deliver the complete, structured code for a professional CLI application."},"slug":{"S":"the-command-line-interface-cli-artisan-4ce4bd7b"},"createdAt":{"S":"2025-09-21T05:54:20.584Z"},"scope":{"S":"PRIVATE"},"name":{"S":"The Command-Line Interface (CLI) Artisan"},"downloadCount":{"N":"2"},"updatedAt":{"S":"2025-09-21T06:41:02.902Z"},"owner":{"S":"a3148862-b0b1-70de-1490-f2e3251d40cd"},"description":{"S":"This prompt configures the agent to be an expert in creating professional, user-friendly, and powerful command-line tools. It takes a high-level goal and generates the full code, including argument parsing, help menus, and robust error handling, for Node.js or Python."},"id":{"S":"4ce4bd7b-5d85-4787-b294-15cbd1b9503b"},"sourceURL":{"S":""},"tags":{"L":[{"S":"CLI"},{"S":"IDE"},{"S":"Implement"},{"S":"Deploy"}]}}
{"content":{"S":"You're acting as a seasoned lawyer with deep expertise in contract law in Victoria - Australia. Your task is to meticulously review the imported contracts of sales for few properties to ensure it adheres to all applicable laws, regulations, and industry standards. \r\nThis includes, but is not limited to: \r\n- Checking for any clauses that could potentially be unfair or illegal, \r\n- Confirming that all parties' obligations are clearly defined and enforceable, and ensuring that the contract does not violate any state or federal laws. \r\n- Assess the contract for any potential liabilities or risks that could harm any party involved. \r\n- Check if there's any issues that might affect the property's building and planning certificate for a granny flat building such as flooding zone, Bushfire zone, aircraft noise, heritage control, soil contamination.\r\n- Check if there's any easement, sewer line, storm water line… might stop you in building or renovate the house.\r\n- Searching on government or legit websites, google map, realestate.com.au to analyse the information about safety location, distance to city centre, public transport, good school-zone ranking. \r\n\r\nThe goals are:\r\n- Provide a comprehensive report detailing your findings and recommend any necessary amendments to ensure full legal compliance and to protect your client's interests.\r\n- The report should included a table to compare the properties with below criterias:\r\n1 - Risky in the Contract of sale.\r\n2 - Easy to get building plan and building permit for granny flat.\r\n3 - Safety and public transport convenience. \r\n4 - Close distance to the Flinder station in melbourne city center."},"copyCount":{"N":"2"},"starCount":{"N":"0"},"instruction":{"S":"You're acting as a seasoned lawyer with deep expertise in contract law in Victoria - Australia. Your task is to meticulously review the imported contracts of sales for few properties to ensure it adheres to all applicable laws, regulations, and industry standards. \r\nThis includes, but is not limited to: \r\n- Checking for any clauses that could potentially be unfair or illegal, \r\n- Confirming that all parties' obligations are clearly defined and enforceable, and ensuring that the contract does not violate any state or federal laws. \r\n- Assess the contract for any potential liabilities or risks that could harm any party involved. \r\n- Check if there's any issues that might affect the property's building and planning certificate for a granny flat building such as flooding zone, Bushfire zone, aircraft noise, heritage control, soil contamination.\r\n- Check if there's any easement, sewer line, storm water line… might stop you in building or renovate the house.\r\n- Searching on government or legit websites, google map, realestate.com.au to analyse the information about safety location, distance to city centre, public transport, good school-zone ranking. \r\n\r\nThe goals are:\r\n- Provide a comprehensive report detailing your findings and recommend any necessary amendments to ensure full legal compliance and to protect your client's interests.\r\n- The report should included a table to compare the properties with below criterias:\r\n1 - Risky in the Contract of sale.\r\n2 - Easy to get building plan and building permit for granny flat.\r\n3 - Safety and public transport convenience. \r\n4 - Close distance to the Flinder station in melbourne city center."},"howto":{"NULL":true},"slug":{"S":"review-contract-ca998ec9"},"createdAt":{"S":"2025-06-12T12:56:29.531Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Review Contract"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-06-25T12:37:57.318Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Act as a seasoned lawyer with deep expertise in contract law to review this contract."},"id":{"S":"ca998ec9-d2ce-40fd-9bb2-e6e8ddfc26f5"},"sourceURL":{"NULL":true},"tags":{"L":[]}}
{"__typename":{"S":"prompt"},"content":{"S":"Create a new next.js app in this directory with the following setup:\r\n- Use typescript\r\n- Use Tailwind CSS v4\r\n- Use ESLint\r\n- Use App Router\r\n- Use the default import alias\r\n- Enable turbopack by default for development\r\n- Initialize code the root directory\r\n- Use shadcn component library using the shadcn-ui package\r\n- Use git hooks based on husky \r\n- Use prettier as code formatter"},"copyCount":{"N":"0"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"instruction":{"S":"Create a new next.js app in this directory with the following setup:\r\n- Use typescript\r\n- Use Tailwind CSS v4\r\n- Use ESLint\r\n- Use App Router\r\n- Use the default import alias\r\n- Enable turbopack by default for development\r\n- Initialize code the root directory\r\n- Use shadcn component library using the shadcn-ui package\r\n- Use git hooks based on husky \r\n- Use prettier as code formatter"},"howto":{"S":"Open your terminal and create a new folder for your application with `mkdir my-app && cd my-app` and replace `my-app`with the correct name of your application or project. \r\n\r\nThen inside your project root folder, start Q developer with `q chat`, copy the prompt and paste it."},"slug":{"S":"next-js-app-bootstrapping-966d45d6"},"createdAt":{"S":"2025-03-06T21:29:51.625Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Next.js App Bootstrapping"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-03-06T21:47:50.221Z"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"It uses the Amazon Q CLI Agent capability to scaffold a new application using React and Vite and then commits it to git."},"id":{"S":"966d45d6-a8d8-4f0a-a220-e15b87a3d8b6"},"tags":{"L":[{"S":"CLI"},{"S":"Dev Agent"},{"S":"Implement"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"@workspace is this application well architected, if not what should I improve?"},"copyCount":{"N":"2"},"owner_username":{"S":"olemaitre"},"starCount":{"N":"1"},"interface":{"S":"IDE"},"instruction":{"S":"@workspace is this application well architected, if not what should I improve?"},"howto":{"S":"Your working folder should contain one drawio diagram containing the design of your app (for example an s3 bucket that triggers a lambda function)"},"slug":{"S":"generate-well-architected-recommendations-on-my-drawio-diagram-adcfeb01"},"createdAt":{"S":"2024-11-06T08:20:23.978Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Generate Well Architected recommendations on my Drawio diagram"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-03-23T16:16:59.332Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Design"},"owner":{"S":"03746802-d021-70a3-b8b8-e364eaff2b71"},"description":{"S":"Generates recommandations to improve my application with well architected best practices"},"id":{"S":"adcfeb01-de07-4f8b-9249-8348c7d89225"},"sourceURL":{"S":""},"tags":{"L":[{"S":"Design"},{"S":"IDE"},{"S":"Chat"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"I want you to check my bash history and tell me what I'm doing that is sketchy. List out the top three worst things I've done in the past 1000 lines."},"copyCount":{"N":"2"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"instruction":{"S":"I want you to check my bash history and tell me what I'm doing that is sketchy. List out the top three worst things I've done in the past 1000 lines."},"howto":{"S":""},"slug":{"S":"analyze-bash-history-02cbf7de"},"createdAt":{"S":"2025-03-11T21:02:36.090Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Analyze Bash History"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-03-11T21:02:36.090Z"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Learn from sketchy things you did in your CLI in the past and their risks"},"id":{"S":"02cbf7de-6de1-444c-ab31-4eccb217149d"},"sourceURL":{"S":"https://www.linkedin.com/posts/nathankpeck_fun-prompt-for-all-you-developers-out-there-activity-7305312646520528897-x5N5?utm_source=share&utm_medium=member_ios&rcm=ACoAACZoZrwBl_LchcywavnbHJkbKQPnoIu9N1w"},"tags":{"L":[{"S":"CLI"},{"S":"Chat"}]}}
{"content":{"S":"@workspace generate a draw.io diagram in an xml format of this application.\r\nI want to use AWS 2024 Icons, lines should be orthogonal, dataflow from up to bottom"},"copyCount":{"N":"7"},"howto":{"S":""},"slug":{"S":"diagrama-para-draw-io-3467695c"},"createdAt":{"S":"2025-08-19T21:47:54.854Z"},"scope":{"S":"PUBLIC"},"name":{"S":"Diagrama para draw.io"},"downloadCount":{"N":"0"},"updatedAt":{"S":"2025-08-19T21:48:18.336Z"},"owner":{"S":"43f4a882-d0d1-70bf-b154-24dc52a0abd4"},"description":{"S":"Permite crear diagramas para draw.io solo , renombrando la extensión del archivo generado a .drawio"},"id":{"S":"3467695c-2318-4bda-98b2-854d02d7181d"},"sourceURL":{"S":""},"tags":{"L":[]}}
{"__typename":{"S":"prompt"},"content":{"S":"/dev Add CDK snapshot tests to compare the entire synthesized CloudFormation template.\n\nWhen creating snapshot tests, follow these principles:\n- use snapshot tests to catch unexpected changes in the overall infrastructure.\n- consider snapshot tests as a change detection mechanism rather than a regression testing tool.\n- ensure that the snapshot test covers CDK stacks, not individual L3 constructs.\n- if applicable, mock CDK assets like docker images or lambda function to prevent generating zip files during test execution. This speeds up test execution and ensures static keys for assets so that snapshots do not change on every execution.\n\nThe snapshot test should conform to the following guidelines:\n- use jest as the test framework\n- add comments to explain what every test is covering\n- use a meaningful name of the test\n- do not add extra `describe` blocks.\n- use the `test()` method to run an individual test\n- do not import `describe`, `test`, `jest` or `expect`.\n- use the `aws-cdk-lib.assertions library` from CDK v2 for assertions\n- use single named imports\n- use arrow functions for all `test` functions.\n- the test file must be named like the source ending with .test.ts. Example: if the source file is named `my-stack.ts`, the test file must be named `my-stack.test.ts`"},"copyCount":{"N":"3"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"/dev Add CDK snapshot tests to compare the entire synthesized CloudFormation template.\n\nWhen creating snapshot tests, follow these principles:\n- use snapshot tests to catch unexpected changes in the overall infrastructure.\n- consider snapshot tests as a change detection mechanism rather than a regression testing tool.\n- ensure that the snapshot test covers CDK stacks, not individual L3 constructs.\n- if applicable, mock CDK assets like docker images or lambda function to prevent generating zip files during test execution. This speeds up test execution and ensures static keys for assets so that snapshots do not change on every execution.\n\nThe snapshot test should conform to the following guidelines:\n- use jest as the test framework\n- add comments to explain what every test is covering\n- use a meaningful name of the test\n- do not add extra `describe` blocks.\n- use the `test()` method to run an individual test\n- do not import `describe`, `test`, `jest` or `expect`.\n- use the `aws-cdk-lib.assertions library` from CDK v2 for assertions\n- use single named imports\n- use arrow functions for all `test` functions.\n- the test file must be named like the source ending with .test.ts. Example: if the source file is named `my-stack.ts`, the test file must be named `my-stack.test.ts`"},"howto":{"S":""},"slug":{"S":"cdk-snapshot-tests-for-typescript-and-jest-37ad5b71"},"createdAt":{"S":"2025-01-17T11:00:21.061Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"CDK Snapshot Tests for Typescript and jest"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-01-17T13:00:35.468Z"},"category":{"S":"Dev Agent"},"sdlc_phase":{"S":"Test"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Uses the dev agent to create CDK snapshot tests following best practices and testing guidelines."},"id":{"S":"37ad5b71-b972-4d4d-8170-cbffe23c23bb"},"tags":{"L":[{"S":"Test"},{"S":"IDE"},{"S":"Dev Agent"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Commit the staged changes following the conventional commit specification."},"copyCount":{"N":"82"},"owner_username":{"S":"cremich"},"starCount":{"N":"0"},"instruction":{"S":"Commit the staged changes following the conventional commit specification."},"howto":{"S":"- Make a change in your repository and stage all files with `git add .`. \r\n- Open your terminal and change directory to the root folder of your repository. \r\n- Then start Q Developer with `q chat` and paste the prompt."},"slug":{"S":"conventional-commit-messages-2f22f60b"},"createdAt":{"S":"2025-03-07T09:35:06.263Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Conventional Commit Messages"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"2"},"updatedAt":{"S":"2025-03-07T09:35:06.263Z"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Commit you changes to git with a meaningful commit message following conventional commit specification."},"id":{"S":"2f22f60b-04de-4650-8ee9-f482472827e9"},"tags":{"L":[{"S":"CLI"},{"S":"Chat"},{"S":"Implement"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Generate python code for the requirements with out any explanation or extra text. Can use comments. The code should be ready to be executed. Try to use external libraries where possible . "},"copyCount":{"N":"3"},"owner_username":{"S":"ashirhs"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"Generate python code for the requirements with out any explanation or extra text. Can use comments. The code should be ready to be executed. Try to use external libraries where possible . "},"slug":{"S":"python-code-for-external-libraries-9daca4df"},"createdAt":{"S":"2024-10-25T15:37:24.006Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Python code for external libraries "},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2024-10-25T15:39:20.171Z"},"category":{"S":"Dev Agent"},"sdlc_phase":{"S":"Implement"},"owner":{"S":"63a47812-b0e1-702c-2bf7-5d44c2c7ae5d"},"description":{"S":"This will generate ready to use python code using external libraries "},"id":{"S":"9daca4df-c5cc-4465-948a-4f08240eb757"},"tags":{"L":[{"S":"Implement"},{"S":"IDE"},{"S":"Dev Agent"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Use this ADR template to generate an ADR: \n<adr> \n\nTitle: (What is the decision that needs to be made) \nStatus: (Proposed, Accepted, Rejected, Deprecated, Superseded) \nContext \nWhat is the issue that we're seeing that is motivating this decision or change? \n\nDecision \n\nWhat is the change that we're proposing and/or doing? \n\nAdditional Info 1 \n\nAdditional Info 2 \n\nAdditional Info N \n\nConsequences \n\nWhat becomes easier or more difficult to do because of this change? \n\nCustomer impact (if any) \n\nAlternative Designs Considered \n\nWhat other designs were considered? What are the tradeoffs? \n\nAlternative 1 \n\nAlternative 2 \n\nAlternative N \n\n</adr> \nI need a ADR to decide to use QuickSight as our primary metrics display option on a web app as opposed to creating a custom react components to display the same metric data. "},"copyCount":{"N":"6"},"owner_username":{"S":"Wes Eklund"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"Use this ADR template to generate an ADR: \n<adr> \n\nTitle: (What is the decision that needs to be made) \nStatus: (Proposed, Accepted, Rejected, Deprecated, Superseded) \nContext \nWhat is the issue that we're seeing that is motivating this decision or change? \n\nDecision \n\nWhat is the change that we're proposing and/or doing? \n\nAdditional Info 1 \n\nAdditional Info 2 \n\nAdditional Info N \n\nConsequences \n\nWhat becomes easier or more difficult to do because of this change? \n\nCustomer impact (if any) \n\nAlternative Designs Considered \n\nWhat other designs were considered? What are the tradeoffs? \n\nAlternative 1 \n\nAlternative 2 \n\nAlternative N \n\n</adr> \nI need a ADR to decide to use QuickSight as our primary metrics display option on a web app as opposed to creating a custom react components to display the same metric data. "},"howto":{"S":"You can tune the output depending on new considerations:\n\n\"Update the above ADR that using either QuickSight capacity pricing by session or user pricing can come become cost prohibitive. It's $.50 per 30 session for capacity pricing and $15 per user per month\""},"slug":{"S":"adr-creation-21a2ae00"},"createdAt":{"S":"2024-12-03T17:25:07.516Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"ADR Creation"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2024-12-04T18:00:46.812Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Design"},"owner":{"S":"google_105691629749969464025"},"description":{"S":"Given an ADR template, provide context so Q can quickly generate the ADR"},"id":{"S":"21a2ae00-f82b-45eb-ba6a-8f4a2a8d2cb5"},"tags":{"L":[{"S":"Design"},{"S":"IDE"},{"S":"Chat"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Analyze the selected Java 17 class for potential improvements.\r\nIdentify and remove code smells, such as duplicate code, long methods, and complex conditional statements.\r\nUtilize Java 17 features and best practices to modernize the codebase.\r\nOptimize performance where applicable, considering time and space complexity.\r\nImprove code readability by following consistent naming conventions and formatting guidelines.\r\nEnhance error handling and exception management.\r\nImplement proper logging and debugging mechanisms.\r\nRefactor to improve testability and facilitate unit testing.\r\nProvide explanations for each refactoring decision and its benefits.\r\nApply SOLID principles to enhance the overall design and maintainability of the code.\r\n\r\nKey Areas to Focus:\r\n\r\nCode Structure:\r\n\r\nBreak down large methods into smaller, more focused ones\r\nExtract reusable code into separate methods or classes\r\nImplement design patterns where appropriate\r\nJava 17 Features:\r\n\r\nUse record classes for immutable data holders\r\nImplement sealed classes and interfaces for better type hierarchies\r\nUtilize pattern matching for instanceof and switch expressions\r\nApply text blocks for multiline string literals\r\nPerformance Optimization:\r\n\r\nUse streams and lambdas for efficient data processing\r\nImplement lazy initialization where applicable\r\nOptimize loops and recursive functions\r\nConsider using concurrent programming techniques for parallelizable tasks\r\nCode Quality:\r\n\r\nRemove redundant code and unnecessary comments\r\nReplace magic numbers with named constants\r\nUse meaningful and consistent variable and method names\r\nApply the DRY (Don't Repeat Yourself) principle\r\nError Handling:\r\n\r\nImplement proper exception handling and custom exceptions\r\nUse try-with-resources for automatic resource management\r\nAvoid catching and ignoring exceptions without proper handling\r\nTesting and Maintainability:\r\n\r\nRefactor code to improve testability\r\nImplement dependency injection for better modularity\r\nWrite unit tests for refactored code\r\nUse assertions and contracts to validate assumptions\r\nDocumentation:\r\n\r\nAdd or update Javadoc comments for classes and methods\r\nInclude inline comments for complex logic or algorithms\r\nProvide examples or usage instructions where necessary\r\nOutput:\r\n\r\nRefactored Java 17 code that addresses the identified issues\r\nDetailed explanations of the refactoring decisions and their benefits\r\nSuggestions for further improvements or alternative approaches\r\nAny potential trade-offs or considerations for the refactored code"},"copyCount":{"N":"0"},"owner_username":{"S":"Vinay Nadig"},"starCount":{"N":"0"},"instruction":{"S":"Analyze the selected Java 17 class for potential improvements.\r\nIdentify and remove code smells, such as duplicate code, long methods, and complex conditional statements.\r\nUtilize Java 17 features and best practices to modernize the codebase.\r\nOptimize performance where applicable, considering time and space complexity.\r\nImprove code readability by following consistent naming conventions and formatting guidelines.\r\nEnhance error handling and exception management.\r\nImplement proper logging and debugging mechanisms.\r\nRefactor to improve testability and facilitate unit testing.\r\nProvide explanations for each refactoring decision and its benefits.\r\nApply SOLID principles to enhance the overall design and maintainability of the code.\r\n\r\nKey Areas to Focus:\r\n\r\nCode Structure:\r\n\r\nBreak down large methods into smaller, more focused ones\r\nExtract reusable code into separate methods or classes\r\nImplement design patterns where appropriate\r\nJava 17 Features:\r\n\r\nUse record classes for immutable data holders\r\nImplement sealed classes and interfaces for better type hierarchies\r\nUtilize pattern matching for instanceof and switch expressions\r\nApply text blocks for multiline string literals\r\nPerformance Optimization:\r\n\r\nUse streams and lambdas for efficient data processing\r\nImplement lazy initialization where applicable\r\nOptimize loops and recursive functions\r\nConsider using concurrent programming techniques for parallelizable tasks\r\nCode Quality:\r\n\r\nRemove redundant code and unnecessary comments\r\nReplace magic numbers with named constants\r\nUse meaningful and consistent variable and method names\r\nApply the DRY (Don't Repeat Yourself) principle\r\nError Handling:\r\n\r\nImplement proper exception handling and custom exceptions\r\nUse try-with-resources for automatic resource management\r\nAvoid catching and ignoring exceptions without proper handling\r\nTesting and Maintainability:\r\n\r\nRefactor code to improve testability\r\nImplement dependency injection for better modularity\r\nWrite unit tests for refactored code\r\nUse assertions and contracts to validate assumptions\r\nDocumentation:\r\n\r\nAdd or update Javadoc comments for classes and methods\r\nInclude inline comments for complex logic or algorithms\r\nProvide examples or usage instructions where necessary\r\nOutput:\r\n\r\nRefactored Java 17 code that addresses the identified issues\r\nDetailed explanations of the refactoring decisions and their benefits\r\nSuggestions for further improvements or alternative approaches\r\nAny potential trade-offs or considerations for the refactored code"},"howto":{"S":""},"slug":{"S":"refactor-like-a-pro-java17-code-0a3749bf"},"createdAt":{"S":"2025-03-05T19:54:04.453Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Refactor Like a Pro: Java17 code"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-03-05T19:54:04.453Z"},"owner":{"S":"google_101017001478424673799"},"description":{"S":"Refactor Like a Pro: Java17 code"},"id":{"S":"0a3749bf-8034-4b44-846c-a97c27dcf949"},"tags":{"L":[{"S":"IDE"},{"S":"Chat"},{"S":"Refactoring"},{"S":"Optimize"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"You are acting as an experienced software engineer and technical writer. Your task is to assist me in creating a technical specification document for a feature idea. To complete the task, you must\r\n\r\n- Read ALL files in the .amazonq/rules folder to understand the guidelines and standards associated with this project.\r\n- Read ALL files in the project-intelligence folder to understand the project and the associated problem domain.\r\n- Keep asking relevant questions until you have gathered all relevant information and requirements.\r\n- Compile your findings into a comprehensive, developer-ready technical specification.\r\n\r\nYour goal is to write a developer-ready technical specification I can hand off to a developer.\r\n\r\nThere are 11 essential parts the technical specification must contain. If a section is not applicable, keep the section in the specification and write why it is not applicable.\r\n\r\n1. Summary: Brief overview of the feature, the user problem it solves, and the proposed solution in a few sentences. It must be written so that any stakeholder can quickly understand the feature’s purpose and value. Sets the context for the rest of the specification\r\n2. Goals: What the feature wants to achieve (goals) and what is explicitly out of scope (non-goals).\r\n3. User-Stories / Use Cases: User-centric descriptions of how the feature will be used, often in the format: “As a [user], I want [feature], so that [benefit]”. Ensures the feature is grounded in real user needs and scenarios.\r\n4. Functional Requirements: A Detailed list of feature requirements, including expected behaviors, inputs, outputs, and edge cases. Details what the feature must do, including edge cases and error handling. Should be testable and unambiguous to guide development and QA.\r\n5. Non-functional Requirements: Performance, security, privacy, accessibility, and other quality attributes relevant to the feature. Addresses how the feature should perform rather than what it should do.\r\n6. Solution Design: Technical details of the implementation. Includes architecture diagrams, data flows, data models, APIs, UI/UX changes, and the rationale for design decisions. May reference relevant technical standards, protocols, or frameworks used. Focus on describing how the solution addresses the defined problems instead of showing implementation details. Use pseudocode instead of concrete implementations. Use mermaid syntax to visualize data flows as flow charts, data models as entity-relationship diagrams, or processes as sequence diagrams.\r\n7. Dependencies and Constraints: Identifies any technical, business, or external dependencies and constraints that impact the feature. Dependencies can be other systems, teams, or features the implementation relies on. Constraints mean limitations such as legacy systems, regulatory requirements, or resource restrictions.\r\n8. Risks and Mitigations: Document known risks, potential issues, and proposed mitigation strategies. Helps teams proactively address challenges and avoid project delays or failures.\r\n9. Testing & Acceptance Criteria: Defines how the feature will be validated and what constitutes completion. Includes test plans, specific test cases, and clear acceptance criteria to ensure the feature meets requirements and is ready for release.\r\n10. Impact Assessment: Briefly describe the impact on users, systems, and stakeholders, including cost/benefit where relevant. May include cost/benefit analysis, user experience implications, or effects on other features or services.\r\n11. Open Questions: List of unresolved issues or decisions that need further input. Keeps track of what still needs clarification and prompts timely stakeholder engagement."},"copyCount":{"N":"250"},"owner_username":{"S":"cremich"},"starCount":{"N":"1"},"instruction":{"S":"You are acting as an experienced software engineer and technical writer. Your task is to assist me in creating a technical specification document for a feature idea. To complete the task, you must\r\n\r\n- Read ALL files in the .amazonq/rules folder to understand the guidelines and standards associated with this project.\r\n- Read ALL files in the project-intelligence folder to understand the project and the associated problem domain.\r\n- Keep asking relevant questions until you have gathered all relevant information and requirements.\r\n- Compile your findings into a comprehensive, developer-ready technical specification.\r\n\r\nYour goal is to write a developer-ready technical specification I can hand off to a developer.\r\n\r\nThere are 11 essential parts the technical specification must contain. If a section is not applicable, keep the section in the specification and write why it is not applicable.\r\n\r\n1. Summary: Brief overview of the feature, the user problem it solves, and the proposed solution in a few sentences. It must be written so that any stakeholder can quickly understand the feature’s purpose and value. Sets the context for the rest of the specification\r\n2. Goals: What the feature wants to achieve (goals) and what is explicitly out of scope (non-goals).\r\n3. User-Stories / Use Cases: User-centric descriptions of how the feature will be used, often in the format: “As a [user], I want [feature], so that [benefit]”. Ensures the feature is grounded in real user needs and scenarios.\r\n4. Functional Requirements: A Detailed list of feature requirements, including expected behaviors, inputs, outputs, and edge cases. Details what the feature must do, including edge cases and error handling. Should be testable and unambiguous to guide development and QA.\r\n5. Non-functional Requirements: Performance, security, privacy, accessibility, and other quality attributes relevant to the feature. Addresses how the feature should perform rather than what it should do.\r\n6. Solution Design: Technical details of the implementation. Includes architecture diagrams, data flows, data models, APIs, UI/UX changes, and the rationale for design decisions. May reference relevant technical standards, protocols, or frameworks used. Focus on describing how the solution addresses the defined problems instead of showing implementation details. Use pseudocode instead of concrete implementations. Use mermaid syntax to visualize data flows as flow charts, data models as entity-relationship diagrams, or processes as sequence diagrams.\r\n7. Dependencies and Constraints: Identifies any technical, business, or external dependencies and constraints that impact the feature. Dependencies can be other systems, teams, or features the implementation relies on. Constraints mean limitations such as legacy systems, regulatory requirements, or resource restrictions.\r\n8. Risks and Mitigations: Document known risks, potential issues, and proposed mitigation strategies. Helps teams proactively address challenges and avoid project delays or failures.\r\n9. Testing & Acceptance Criteria: Defines how the feature will be validated and what constitutes completion. Includes test plans, specific test cases, and clear acceptance criteria to ensure the feature meets requirements and is ready for release.\r\n10. Impact Assessment: Briefly describe the impact on users, systems, and stakeholders, including cost/benefit where relevant. May include cost/benefit analysis, user experience implications, or effects on other features or services.\r\n11. Open Questions: List of unresolved issues or decisions that need further input. Keeps track of what still needs clarification and prompts timely stakeholder engagement."},"howto":{"S":"1. Setup your project intelligence using the project rule as described here: https://www.promptz.dev/rules/rule/project-intelligence-dbd52e23\r\n2. Open a new chat inside your IDE\r\n3. Copy-pase the prompt into your chat\r\n4. Answer all questions as detailed and specific as possible\r\n5. Review and update the generated specification\r\n6. Once finalized, ask Q to save the specification as markdown file. You can choose to add it as additional files in your existing documentation folder or in a separate specs folder. I recommend grouping the specs separated by feature (e.g. specs/featureA/spec.md, specs/featureB/spec.md)"},"slug":{"S":"specifications-for-development-tasks-24b69aa8"},"createdAt":{"S":"2025-03-22T10:53:45.925Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Specifications for development tasks"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"14"},"updatedAt":{"S":"2025-05-27T21:15:20.155Z"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Use Amazon Q Developer to assist you in creating a step-by-step specification for a feature idea."},"id":{"S":"24b69aa8-8162-4ef0-8e2d-370afd4a55a1"},"sourceURL":{"S":""},"tags":{"L":[{"S":"IDE"},{"S":"Chat"},{"S":"Design"},{"S":"Documentation"},{"S":"Requirements"},{"S":"Plan"}]}}
{"content":{"S":"You’re acting as an expert Aws solution architecture. \r\nYour task is to scan this project then checking if templates and pipelines files have correct settings as below:\r\n- Host url: “noeljonesringwood.myconnect.com.au”\r\n- Redirect url: “myconnect.com.au.landing.noel-jones-ringwood”\r\n- SSL certificate: “*.myconnect.com.au”\r\n- LambdaEdge function nane: \r\n- Cloudfront distribution name:"},"copyCount":{"N":"1"},"starCount":{"N":"0"},"instruction":{"S":"You’re acting as an expert Aws solution architecture. \r\nYour task is to scan this project then checking if templates and pipelines files have correct settings as below:\r\n- Host url: “noeljonesringwood.myconnect.com.au”\r\n- Redirect url: “myconnect.com.au.landing.noel-jones-ringwood”\r\n- SSL certificate: “*.myconnect.com.au”\r\n- LambdaEdge function nane: \r\n- Cloudfront distribution name:"},"howto":{"NULL":true},"slug":{"S":"checking-aws-infras-23d49eec"},"createdAt":{"S":"2025-07-16T10:46:29.884Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Checking Aws Infras"},"updatedAt":{"S":"2025-07-16T10:46:29.884Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Checking Aws Infras"},"id":{"S":"23d49eec-6cc7-4155-a3ee-65a64a5b5453"},"sourceURL":{"NULL":true},"tags":{"L":[]}}
{"content":{"S":"# Amazon Q Workspace Setup\r\n\r\nHelp me optimize my development workflow by setting up Amazon Q Developer for this project. I need to create a comprehensive configuration that enables Amazon Q to understand my project's structure, standards, and requirements.\r\n\r\n## Configuration Tasks\r\n\r\n1. Create an `AmazonQ.md` file at the project root that provides:\r\n   - Project overview and architecture\r\n   - Primary development workflows\r\n   - Key technologies and frameworks\r\n   - Coding standards and conventions\r\n\r\n2. Set up `.amazonq/rules/project/*.md` files for specific guidance on:\r\n   - Code implementation patterns\r\n   - Testing strategies and test generation\r\n   - Documentation requirements\r\n   - Library/framework usage\r\n   - Code review standards\r\n   - Common development scenarios\r\n   - Architectural decisions\r\n   - Integration patters\r\n   - Troubleshooting guides\r\n\r\n3. Create a `.amazonq/rule-details/project/` directory which will contain the more detailed content for rules, referenced from .amazonq/rules/project/*.md files\r\n\r\n4. In scenarios where rule details are extensive, to save context space, save details of the rule in `.amazonq/rule-details/project/` and reference conditionally from rules. For example:\r\n\r\n   Sample rule: `.amazonq/rules/project/python_comments.md`\r\n\r\n   ```markdown\r\n   # Python Code Documentation Guide\r\n\r\n   When generating comments for python functions and modules, follow the detailed instructions in `.amazonq/rule-details/project/python_documentation_guidelines.md`\r\n   ```\r\n\r\n   Sample rule-detail file: `.amazonq/rule-details/project/python_documentation_guidelines.md`\r\n\r\n   ```markdown\r\n   # Python Code Documentation Standards\r\n\r\n   [detailed description of documentation standards]\r\n   ```\r\n\r\n## Implementation Approach\r\n\r\nPlease implement this configuration in stages:\r\n\r\n1. First, analyze the project structure to understand its scope and complexity\r\n2. Create the core configuration files with essential guidance\r\n3. Progressively enhance the configuration as you discover more about the codebase\r\n4. Ensure all documentation cross-references related files appropriately\r\n\r\nIf the project is large, focus on the most critical aspects first and provide a strategy for incrementally improving the configuration over time.\r\n\r\n> Note: If the AmazonQ.md file already exists, update it appropriately without losing critical information from the original version. Take an approach that will maximize the efficient use of context for very large projects.\r\n\r\nFinally, create a new rule called .amazonq/rules/learn.md in which you instruct Amazon Q Developer to prompt the user if they want to update rules when Amazon Q Developer is corrected by the user.  For instance, if Q generated an incorrect directory structure, or if Q generated code that the user indicated was incorrect and provided new direction, ask if you should update the corresponding rule(s)."},"copyCount":{"N":"54"},"howto":{"S":"Simply run the prompt from the IDE or CLI chat. If you will use with multiple projects, save as a Saved Prompt."},"slug":{"S":"setup-workspace-rules-a2e65a78"},"createdAt":{"S":"2025-09-03T15:24:01.707Z"},"scope":{"S":"PUBLIC"},"name":{"S":"Setup Workspace Rules"},"downloadCount":{"N":"13"},"updatedAt":{"S":"2025-09-16T19:38:30.972Z"},"owner":{"S":"73a418a2-2071-7027-cb6d-6d8c1100ee0a"},"description":{"S":"Amazon Q Developer operates more quickly, more accurately, and consistently when properly configured with information it can load quickly. This prompt instructs Q to learn from your project and create context-efficient files that give Q just what it needs, with references to load-on-demand details based on the interaction."},"id":{"S":"a2e65a78-515a-44cf-a50c-4b486e8c89d7"},"sourceURL":{"S":""},"tags":{"L":[{"S":"IDE"},{"S":"CLI"},{"S":"Optimize"},{"S":"Documentation"},{"S":"Implement"},{"S":"Test"},{"S":"Operate"},{"S":"Plan"},{"S":"Enhance"},{"S":"Requirements"},{"S":"Design"},{"S":"Chat"},{"S":"Test Agent"},{"S":"Doc Agent"}]}}
{"content":{"S":"# Amazon Q Developer Q-Vibes Memory Banking\r\n\r\nI am Amazon Q Developer, an AI assistant optimized for fast prototyping. My memory resets between sessions, but I maintain context through lightweight documentation designed for speed over perfection.\r\n\r\n## Framework Overview\r\n\r\n**Q-Vibes Memory Banking** - lightweight context preservation for AI-assisted rapid prototyping.\r\n\r\n**Core principle**: Use structured documentation to maintain context across sessions.\r\n\r\n## Structure\r\n\r\n4 essential files in `./.amazonq/vibes/` folder for throw-away projects where speed matters.\r\n\r\n```mermaid\r\nflowchart TD\r\n    I[idea.md] --> V[vibe.md]\r\n    I --> S[state.md]\r\n    V --> S\r\n    S --> D[decisions.md]\r\n```\r\n\r\n### Core Files\r\n\r\n1. **`idea.md`** - Core concept, success criteria, assumptions. Created once.\r\n2. **`vibe.md`** - How we work together, code preferences, what NOT to ask.\r\n3. **`state.md`** - Current stack/architecture, what exists, next steps. Most updated.\r\n4. **`decisions.md`** - Technical decisions, trade-offs, established patterns.\r\n\r\n## Core Workflow\r\n\r\n### New Prototype Initialization\r\n\r\n```mermaid\r\nflowchart TD\r\n    Start[User describes idea] --> ReadTemplates[Read template files]\r\n    ReadTemplates --> CreateIdea[Create idea.md using template]\r\n    CreateIdea --> SetupVibe[User customizes vibe.md]\r\n    SetupVibe --> Bootstrap[Start coding & create state.md using template]\r\n    Bootstrap --> Log[Log decisions in decisions.md using template]\r\n    Log --> Code[Continue coding]\r\n```\r\n\r\n**Template Usage:**\r\n- **Always read template files first**\r\n- **Use exact template structure** from `.amazonq/vibes/` templates\r\n- **Only create if doesn't exist** - never overwrite\r\n- **Follow template formatting** precisely\r\n\r\n### Session Resume\r\n\r\n```mermaid\r\nflowchart TD\r\n    SessionStart[Session Starts] --> ReadAll[Read all 4 files]\r\n    ReadAll --> Confirm[Confirm context with user]\r\n    Confirm --> Continue[Continue work]\r\n    Continue --> UpdateState[Update state.md as we work]\r\n    UpdateState --> LogDecisions[Log new decisions]\r\n    LogDecisions --> SessionEnd[Session ends]\r\n```\r\n\r\n## Update Process\r\n\r\n### Automatic Updates\r\n- `state.md` after significant implementation\r\n- `decisions.md` when making architectural choices\r\n- End-of-session progress capture\r\n\r\n### Update Triggers\r\n1. **New feature** → Update `state.md`\r\n2. **Architecture decision** → Log in `decisions.md`\r\n3. **Stack choice** → Update both files\r\n4. **Problem solved** → Document in `decisions.md`\r\n5. **Session ending** → Final `state.md` update\r\n6. **Direction change** → Update `idea.md`\r\n7. **Feature complete** → Ask about merging\r\n\r\n## File Maintenance\r\n\r\n### Ownership\r\n- **`idea.md`** - User owns, AI suggests\r\n- **`vibe.md`** - User defines, AI fills gaps\r\n- **`state.md`** - AI maintains\r\n- **`decisions.md`** - Collaborative\r\n\r\n### Size Limits\r\n- `idea.md` - Max 10 lines\r\n- `vibe.md` - Max 30 lines\r\n- `state.md` - Max 30 lines\r\n- `decisions.md` - Max 25 lines\r\n\r\n### Quality Guidelines\r\n- Prioritize actionable information\r\n- Skip obvious details\r\n- Focus on what you'd forget\r\n- Use bullet points\r\n\r\n## Success Metrics\r\n\r\n- Resume work in under 2 minutes\r\n- Maintain context across days\r\n- Avoid re-explaining concepts\r\n- Keep documentation under 5% of coding time"},"copyCount":{"N":"0"},"starCount":{"N":"0"},"instruction":{"S":"# Amazon Q Developer Q-Vibes Memory Banking\r\n\r\nI am Amazon Q Developer, an AI assistant optimized for fast prototyping. My memory resets between sessions, but I maintain context through lightweight documentation designed for speed over perfection.\r\n\r\n## Framework Overview\r\n\r\n**Q-Vibes Memory Banking** - lightweight context preservation for AI-assisted rapid prototyping.\r\n\r\n**Core principle**: Use structured documentation to maintain context across sessions.\r\n\r\n## Structure\r\n\r\n4 essential files in `./.amazonq/vibes/` folder for throw-away projects where speed matters.\r\n\r\n```mermaid\r\nflowchart TD\r\n    I[idea.md] --> V[vibe.md]\r\n    I --> S[state.md]\r\n    V --> S\r\n    S --> D[decisions.md]\r\n```\r\n\r\n### Core Files\r\n\r\n1. **`idea.md`** - Core concept, success criteria, assumptions. Created once.\r\n2. **`vibe.md`** - How we work together, code preferences, what NOT to ask.\r\n3. **`state.md`** - Current stack/architecture, what exists, next steps. Most updated.\r\n4. **`decisions.md`** - Technical decisions, trade-offs, established patterns.\r\n\r\n## Core Workflow\r\n\r\n### New Prototype Initialization\r\n\r\n```mermaid\r\nflowchart TD\r\n    Start[User describes idea] --> ReadTemplates[Read template files]\r\n    ReadTemplates --> CreateIdea[Create idea.md using template]\r\n    CreateIdea --> SetupVibe[User customizes vibe.md]\r\n    SetupVibe --> Bootstrap[Start coding & create state.md using template]\r\n    Bootstrap --> Log[Log decisions in decisions.md using template]\r\n    Log --> Code[Continue coding]\r\n```\r\n\r\n**Template Usage:**\r\n- **Always read template files first**\r\n- **Use exact template structure** from `.amazonq/vibes/` templates\r\n- **Only create if doesn't exist** - never overwrite\r\n- **Follow template formatting** precisely\r\n\r\n### Session Resume\r\n\r\n```mermaid\r\nflowchart TD\r\n    SessionStart[Session Starts] --> ReadAll[Read all 4 files]\r\n    ReadAll --> Confirm[Confirm context with user]\r\n    Confirm --> Continue[Continue work]\r\n    Continue --> UpdateState[Update state.md as we work]\r\n    UpdateState --> LogDecisions[Log new decisions]\r\n    LogDecisions --> SessionEnd[Session ends]\r\n```\r\n\r\n## Update Process\r\n\r\n### Automatic Updates\r\n- `state.md` after significant implementation\r\n- `decisions.md` when making architectural choices\r\n- End-of-session progress capture\r\n\r\n### Update Triggers\r\n1. **New feature** → Update `state.md`\r\n2. **Architecture decision** → Log in `decisions.md`\r\n3. **Stack choice** → Update both files\r\n4. **Problem solved** → Document in `decisions.md`\r\n5. **Session ending** → Final `state.md` update\r\n6. **Direction change** → Update `idea.md`\r\n7. **Feature complete** → Ask about merging\r\n\r\n## File Maintenance\r\n\r\n### Ownership\r\n- **`idea.md`** - User owns, AI suggests\r\n- **`vibe.md`** - User defines, AI fills gaps\r\n- **`state.md`** - AI maintains\r\n- **`decisions.md`** - Collaborative\r\n\r\n### Size Limits\r\n- `idea.md` - Max 10 lines\r\n- `vibe.md` - Max 30 lines\r\n- `state.md` - Max 30 lines\r\n- `decisions.md` - Max 25 lines\r\n\r\n### Quality Guidelines\r\n- Prioritize actionable information\r\n- Skip obvious details\r\n- Focus on what you'd forget\r\n- Use bullet points\r\n\r\n## Success Metrics\r\n\r\n- Resume work in under 2 minutes\r\n- Maintain context across days\r\n- Avoid re-explaining concepts\r\n- Keep documentation under 5% of coding time"},"howto":{"S":"this framework is tailored for vibe-coding sessions with Amazon Q. \r\nit works with templates, you can use yours or get inspired by mine. You can find complete instructions, templates and a working example on my github repo."},"slug":{"S":"amazon-q-vibes-memory-banking-1ae365fe"},"createdAt":{"S":"2025-06-27T13:26:11.423Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"amazon-q-vibes-memory-banking"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-06-27T13:26:11.423Z"},"owner":{"S":"73a45872-0041-7073-ac31-50a310227f89"},"description":{"S":"Lightweight memory-banking framework tailored for vibe-coding sessions with Amazon Q"},"id":{"S":"1ae365fe-6c4c-40eb-a7a7-3e734c8b4b8a"},"sourceURL":{"S":"https://github.com/ncremaschini/amazon-q-vibes-memory-banking"},"tags":{"L":[{"S":"CLI"},{"S":"IDE"},{"S":"Chat"},{"S":"Dev Agent"},{"S":"Doc Agent"},{"S":"Design"},{"S":"Documentation"},{"S":"Implement"},{"S":"Requirements"},{"S":"Plan"},{"S":"Enhance"}]}}
{"content":{"S":"Your task is to add sanitizeHtml for the SignupCustomer as validation for attributes to prevent malicious scripts attack.\r\nPlace to add the sanitizeHtml:\r\n- buildRequest() which be called by submitGetConnected () inside post-submit-get-connected-form.ts\r\nAttributes of SignupCustomer object to be santitized:\r\n- first_name?: string | null;\r\n- last_name?: string | null;\r\n- email?: string | null;\r\n- mobile_number?: string | null;\r\n- phone_number?: string | null;\r\n\r\nThe goals are:\r\n- Add sanitizeHtml for the required attributes inside SignupCustomer\r\n- Refactoring the related methods if necessary to apply the sanitizes \r\n- Make sure the sanitizeHtml be applied with best practices to prevent malicious scripts attack in this Nodejs project.\r\n- Make sure project build successfull without any errors after update."},"copyCount":{"N":"2"},"starCount":{"N":"0"},"instruction":{"S":"Your task is to add sanitizeHtml for the SignupCustomer as validation for attributes to prevent malicious scripts attack.\r\nPlace to add the sanitizeHtml:\r\n- buildRequest() which be called by submitGetConnected () inside post-submit-get-connected-form.ts\r\nAttributes of SignupCustomer object to be santitized:\r\n- first_name?: string | null;\r\n- last_name?: string | null;\r\n- email?: string | null;\r\n- mobile_number?: string | null;\r\n- phone_number?: string | null;\r\n\r\nThe goals are:\r\n- Add sanitizeHtml for the required attributes inside SignupCustomer\r\n- Refactoring the related methods if necessary to apply the sanitizes \r\n- Make sure the sanitizeHtml be applied with best practices to prevent malicious scripts attack in this Nodejs project.\r\n- Make sure project build successfull without any errors after update."},"howto":{"NULL":true},"slug":{"S":"add-sanitize-validation-for-signupcustomer-db2d5a79"},"createdAt":{"S":"2025-06-17T01:04:36.911Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Add Sanitize Validation for SignupCustomer"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-06-17T05:07:02.150Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Add Sanitize for SignupCustomer attributes to prevent malicious scripts"},"id":{"S":"db2d5a79-2e22-417c-8570-8d41c8153a36"},"sourceURL":{"NULL":true},"tags":{"L":[]}}
{"content":{"S":"You're acting as an experienced Wordpress developer, devops engineer and technician writer expert.\r\nYour task is to\r\n- Scan this project and give me solution to merge steps 2 and 3 of current CI/CD pipeline of this project into a single Docker build process (in the Dockerfile), and move the rest of the process into CodePipeline\r\n\r\nAssume that:\r\n\r\n- The bitbucket repository exists already: https://bitbucket.org/myconnect-au/myconnect-wordpress/src \r\n\r\n- The Github action that gets run to deploy it currently is here: https://bitbucket.org/myconnect-au/myconnect-wordpress/src/main/.github/workflows/deploy-client-staging.yml \r\n\r\n- The current process is:\r\n\r\n1. Make changes and push to repository (Github)\r\n\r\n2. Action runs, which installs the required PHP packages and Wordpress plugins\r\n\r\n3. Docker image (our code) is built with and code from step 2 is copied in\r\n\r\n4. Resulting image is pushed to ECR\r\n\r\n5. CodePipeline deployment begins (triggered by ECR push)\r\n\r\n6. CMS site wordpress.myconnect.com.au is deployed\r\n\r\nThe goals are:\r\n- Create the solution document in .md format with detail instruction to update the project to match the requirements.\r\n- The document should be well-structured with clear divided sections which guide step by step on how we apply the changes. \r\n- Don't make any code changes."},"copyCount":{"N":"0"},"starCount":{"N":"0"},"instruction":{"S":"You're acting as an experienced Wordpress developer, devops engineer and technician writer expert.\r\nYour task is to\r\n- Scan this project and give me solution to merge steps 2 and 3 of current CI/CD pipeline of this project into a single Docker build process (in the Dockerfile), and move the rest of the process into CodePipeline\r\n\r\nAssume that:\r\n\r\n- The bitbucket repository exists already: https://bitbucket.org/myconnect-au/myconnect-wordpress/src \r\n\r\n- The Github action that gets run to deploy it currently is here: https://bitbucket.org/myconnect-au/myconnect-wordpress/src/main/.github/workflows/deploy-client-staging.yml \r\n\r\n- The current process is:\r\n\r\n1. Make changes and push to repository (Github)\r\n\r\n2. Action runs, which installs the required PHP packages and Wordpress plugins\r\n\r\n3. Docker image (our code) is built with and code from step 2 is copied in\r\n\r\n4. Resulting image is pushed to ECR\r\n\r\n5. CodePipeline deployment begins (triggered by ECR push)\r\n\r\n6. CMS site wordpress.myconnect.com.au is deployed\r\n\r\nThe goals are:\r\n- Create the solution document in .md format with detail instruction to update the project to match the requirements.\r\n- The document should be well-structured with clear divided sections which guide step by step on how we apply the changes. \r\n- Don't make any code changes."},"howto":{"NULL":true},"slug":{"S":"bitbucket-migration-34d3d6cc"},"createdAt":{"S":"2025-07-30T05:14:58.462Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Bitbucket Migration"},"updatedAt":{"S":"2025-07-30T05:14:58.462Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Prompt to migrate from git to bitbucket"},"id":{"S":"34d3d6cc-80f6-4439-a59e-899502098fae"},"sourceURL":{"NULL":true},"tags":{"L":[]}}
{"__typename":{"S":"prompt"},"content":{"S":"1. Create a folder in your project workspace (I call mine \"project\", the name might be significant, I have not tried others)\n2. In this folder, create a file called \"project-standards.md\"\n3. Add the following markdown into this file\n\n```\nWhen creating new Python code, use the following guidance\n\n- Generate code using the following structure and layout\n\n├── static/\n├── models/\n├── routes/\n├── templates/\n├  app.py\n```\n4. Save the file, and then you are good to go\n"},"copyCount":{"N":"1"},"owner_username":{"S":"Ricardo Sueiras"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"1. Create a folder in your project workspace (I call mine \"project\", the name might be significant, I have not tried others)\n2. In this folder, create a file called \"project-standards.md\"\n3. Add the following markdown into this file\n\n```\nWhen creating new Python code, use the following guidance\n\n- Generate code using the following structure and layout\n\n├── static/\n├── models/\n├── routes/\n├── templates/\n├  app.py\n```\n4. Save the file, and then you are good to go\n"},"howto":{"S":"With this file in your project workspace, code generated by /dev will adopt these norms."},"slug":{"S":"boostrap-flask-app-in-dev-68f5b351"},"createdAt":{"S":"2024-11-27T11:17:50.001Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Boostrap Flask App in /dev"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2024-11-27T11:17:50.001Z"},"category":{"S":"Dev Agent"},"sdlc_phase":{"S":"Unknown"},"owner":{"S":"google_104997871466396428939"},"description":{"S":"This will generate a consistent output from /dev"},"id":{"S":"68f5b351-6b3f-4ad6-a12f-b9226428cf45"},"tags":{"L":[{"S":"Unknown"},{"S":"IDE"},{"S":"Dev Agent"}]}}
{"id":{"S":"b1c96b5c-535b-4811-a7b6-aa683c8cd6bc"},"copyCount":{"N":"5"}}
{"__typename":{"S":"prompt"},"content":{"S":"<task>\r\nYour task is to analyze the code for two services, {{Service1}} and {{Service2}}, and identify any CloudWatch metrics or alarms related specifically to {{ALARM_TYPE}} that are present in {{Service2}} but missing in {{Service1}}.\r\n</task>\r\n\r\n<instructions>\r\nTo accomplish this task, follow these steps:\r\n1. Review the code for {{Service2}}, which follows best practices for monitoring infrastructure using CloudWatch metrics and alarms. Take note of the metrics and alarms implemented specifically for {{ALARM_TYPE}}.\r\n2. Carefully examine the code for {{Service1}}.\r\n3. Compare the two code bases and identify any CloudWatch metrics and alarms specifically related to {{ALARM_TYPE}} that are implemented in {{Service2}} but not present in {{Service1}}.\r\n4. Keep in mind that metric and alarm names may be slightly different between the two code packages, but focus on the underlying functionality and severity.\r\n</instructions>\r\n\r\nProvide your response in the following format:\r\n<rationale>\r\nProvide a list of all metrics and alarms present in {{Service2}} related to {{ALARM_TYPE}}. Treat same alarms of different severity as different. Also mention why each metric and alarm is important. Provide a code reference of where each metric and alarm is present in {{Service2}} and where it can be added in {{Service1}}.\r\n</rationale>\r\n<missing_alarms>\r\n- [First alarm or metric name], [Severity of the alarm in the form SEV_1/SEV_2/SEV_3. Use NA if not specified.], [Brief explanation about why this metric is important]\r\n- [Second alarm or metric name], [Severity of the alarm in the form SEV_1/SEV_2/SEV_3. Use NA if not specified.], [Brief explanation about why this metric is important]\r\n.\r\n.\r\n.\r\n</missing_alarms>\r\n\r\nPlease provide your response immediately after these instructions, enclosed in the <rationale></rationale> and\r\n<missing_alarms></missing_alarms> tags.\r\nThe code for {{Service2}} is presented below within <{{Service2}}></{{Service2}}> tags.\r\nThe code for {{Service1}} is presented below within <{{Service1}}></{{Service1}}> tags."},"copyCount":{"N":"2"},"owner_username":{"S":"shudabas"},"starCount":{"N":"0"},"instruction":{"S":"<task>\r\nYour task is to analyze the code for two services, {{Service1}} and {{Service2}}, and identify any CloudWatch metrics or alarms related specifically to {{ALARM_TYPE}} that are present in {{Service2}} but missing in {{Service1}}.\r\n</task>\r\n\r\n<instructions>\r\nTo accomplish this task, follow these steps:\r\n1. Review the code for {{Service2}}, which follows best practices for monitoring infrastructure using CloudWatch metrics and alarms. Take note of the metrics and alarms implemented specifically for {{ALARM_TYPE}}.\r\n2. Carefully examine the code for {{Service1}}.\r\n3. Compare the two code bases and identify any CloudWatch metrics and alarms specifically related to {{ALARM_TYPE}} that are implemented in {{Service2}} but not present in {{Service1}}.\r\n4. Keep in mind that metric and alarm names may be slightly different between the two code packages, but focus on the underlying functionality and severity.\r\n</instructions>\r\n\r\nProvide your response in the following format:\r\n<rationale>\r\nProvide a list of all metrics and alarms present in {{Service2}} related to {{ALARM_TYPE}}. Treat same alarms of different severity as different. Also mention why each metric and alarm is important. Provide a code reference of where each metric and alarm is present in {{Service2}} and where it can be added in {{Service1}}.\r\n</rationale>\r\n<missing_alarms>\r\n- [First alarm or metric name], [Severity of the alarm in the form SEV_1/SEV_2/SEV_3. Use NA if not specified.], [Brief explanation about why this metric is important]\r\n- [Second alarm or metric name], [Severity of the alarm in the form SEV_1/SEV_2/SEV_3. Use NA if not specified.], [Brief explanation about why this metric is important]\r\n.\r\n.\r\n.\r\n</missing_alarms>\r\n\r\nPlease provide your response immediately after these instructions, enclosed in the <rationale></rationale> and\r\n<missing_alarms></missing_alarms> tags.\r\nThe code for {{Service2}} is presented below within <{{Service2}}></{{Service2}}> tags.\r\nThe code for {{Service1}} is presented below within <{{Service1}}></{{Service1}}> tags."},"howto":{"S":"{{Service1}} is the target package name, for which missing alarms and metrics need to be identified.\r\n{{Service2}} is the reference package name, which follows best practices for service health monitoring.\r\n{{ALARM_TYPE}} is the AWS resource type. E.g. File Descriptor, Garbage collection.\r\nThe code for the reference and target packages need to be converted to a structured format and appended to the prompt.\r\n\r\nUtility to convert code packages to a structured format: packages/GenAICDKAnalyzer/blobs/mainline/--/codebase_to_text.py\r\nSample usage of the utility: packages/GenAICDKAnalyzer/blobs/6aec4cd1b96c975dff5f1a8950b1b0ab70be7399/--/main.py#L184"},"slug":{"S":"identifying-metrics-alarms-related-to-service-health-0fdb45f1"},"createdAt":{"S":"2025-03-13T06:08:02.655Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Identifying metrics/alarms related to service health"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-03-17T11:05:17.241Z"},"owner":{"S":"23546802-8051-7065-df4e-cf55f4fd7dc4"},"description":{"S":"This prompt aims to identify missing metrics/alarms related to service health in a target package. A reference package is used to limit the response to required metrics/alarms, assuming it follows best practices for service health monitoring."},"id":{"S":"0fdb45f1-11ab-4e02-b4fe-d40bf416d497"},"sourceURL":{"S":""},"tags":{"L":[]}}
{"content":{"S":"You are acting as a react NodeJS developer with expertise in mocha, KnexJS and DatabaseClient libraries of Nodejs.\r\n1. Read the fetch-external-submission-status folder to understand how this service interact with these PostgresDB tables: ExternalSubmissionContainer, ExternalSubmissionStatusContainer & ExternalSubmissionStatusContacts including fetching, mapping and storage methods.\r\n2. Read the flkitover folder and README.md file to understand how this project being tested with information on test library, test methods.\r\n3. Use below data from real PostgresDB to create mock Data for the tests.\r\n\r\nYour task is to:\r\n- Create a test folder with unit test files and test cases for all methods, services and controller that used to interact with the provided PostgresDB tables in the fetch-external-submission-status Workspace.\r\n- Create the mock Data for the test based on the provided PostgresDB data\r\n- Imported required libraries and test configuration in the fetch-external-submission-status Workspace\r\n\r\nThe goals are:\r\n- Make sure all required methods, services, controllers will be cover by unit tests and passed the code coverage check. \r\n- Just create Unit test, not other tests. \r\n- The Unit test should using same test library and test mechanism with flkitover workspace.\r\n- All Unit test cases should follow best testing practices for Node JS project.\r\n- All Unit test cases should passed\r\n- Project build and run successfully after update."},"copyCount":{"N":"1"},"starCount":{"N":"0"},"instruction":{"S":"You are acting as a react NodeJS developer with expertise in mocha, KnexJS and DatabaseClient libraries of Nodejs.\r\n1. Read the fetch-external-submission-status folder to understand how this service interact with these PostgresDB tables: ExternalSubmissionContainer, ExternalSubmissionStatusContainer & ExternalSubmissionStatusContacts including fetching, mapping and storage methods.\r\n2. Read the flkitover folder and README.md file to understand how this project being tested with information on test library, test methods.\r\n3. Use below data from real PostgresDB to create mock Data for the tests.\r\n\r\nYour task is to:\r\n- Create a test folder with unit test files and test cases for all methods, services and controller that used to interact with the provided PostgresDB tables in the fetch-external-submission-status Workspace.\r\n- Create the mock Data for the test based on the provided PostgresDB data\r\n- Imported required libraries and test configuration in the fetch-external-submission-status Workspace\r\n\r\nThe goals are:\r\n- Make sure all required methods, services, controllers will be cover by unit tests and passed the code coverage check. \r\n- Just create Unit test, not other tests. \r\n- The Unit test should using same test library and test mechanism with flkitover workspace.\r\n- All Unit test cases should follow best testing practices for Node JS project.\r\n- All Unit test cases should passed\r\n- Project build and run successfully after update."},"howto":{"NULL":true},"slug":{"S":"create-unit-test-1609168c"},"createdAt":{"S":"2025-06-19T06:20:49.650Z"},"public":{"BOOL":false},"scope":{"S":"PRIVATE"},"name":{"S":"Create Unit Test"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-06-20T04:18:39.601Z"},"owner":{"S":"63c41822-4031-700e-1e18-c2871494a978"},"description":{"S":"Create Unit Test"},"id":{"S":"1609168c-fd2a-4287-bcbd-c0eaf990aad5"},"sourceURL":{"NULL":true},"tags":{"L":[]}}
{"content":{"S":"Genera una documentación del flujo funcional descrito en el archivo @Flujo-Pago-tarjetas.csv  tomando como contexto todos los archivos .md de la carpeta @servicios que documentan cada uno de los endpoints.\r\n\r\n- El diagrama de flujo debe tener todos los flujos condicionales.\r\n\r\n- Considera el archivo @flujo_tarjetas_condiciones.md para generar el diagrama de flujo de la documentación.\r\n\r\n- Utiliza el archivo FuntionalFlowTemplate.md como estructura base\r\n\r\n- Agrupa condiciones redundantes\r\n\r\n- En la tabla de servicio agrega el link corespondiente al archivo .md que define el servicio de la carpeta @servicios"},"copyCount":{"N":"0"},"howto":{"S":""},"slug":{"S":"flujo-de-negocio-ext-dbcc81cc"},"createdAt":{"S":"2025-08-27T20:01:02.661Z"},"scope":{"S":"PRIVATE"},"name":{"S":"Flujo de negocio EXT"},"downloadCount":{"N":"0"},"updatedAt":{"S":"2025-08-27T20:01:02.661Z"},"owner":{"S":"43f4a882-d0d1-70bf-b154-24dc52a0abd4"},"description":{"S":"Documentación extendida de flujo de negocios"},"id":{"S":"dbcc81cc-ce32-4f09-81f8-a80f9b9f8bde"},"tags":{"L":[]},"sourceURL":{"S":""}}
{"id":{"S":"2e34b074-1acc-47f6-acfe-f85e23e45bae"},"copyCount":{"N":"3"}}
{"__typename":{"S":"prompt"},"content":{"S":"Analyze the selected Java 17 code for potential improvements.\r\nIdentify and remove code smells, such as duplicate code, long methods, and complex conditional statements.\r\nApply SOLID principles to enhance the overall design and maintainability of the code.\r\nUtilize Java 17 features and best practices to modernize the codebase.\r\nOptimize performance where applicable, considering time and space complexity.\r\nImprove code readability by following consistent naming conventions and formatting guidelines.\r\nEnhance error handling and exception management.\r\nImplement proper logging and debugging mechanisms.\r\nRefactor to improve testability and facilitate unit testing.\r\nProvide explanations for each refactoring decision and its benefits.\r\n\r\nKey Areas to Focus:\r\n\r\nCode Structure:\r\nBreak down large methods into smaller, more focused ones\r\nExtract reusable code into separate methods or classes\r\nImplement design patterns where appropriate\r\n\r\nJava 17 Features:\r\nUse record classes for immutable data holders\r\nImplement sealed classes and interfaces for better type hierarchies\r\nUtilize pattern matching for instanceof and switch expressions\r\nApply text blocks for multiline string literals\r\n\r\nPerformance Optimization:\r\nUse streams and lambdas for efficient data processing\r\nImplement lazy initialization where applicable\r\nOptimize loops and recursive functions\r\nConsider using concurrent programming techniques for parallelizable tasks\r\n\r\nCode Quality:\r\nRemove redundant code and unnecessary comments\r\nReplace magic numbers with named constants\r\nUse meaningful and consistent variable and method names\r\nApply the DRY (Don't Repeat Yourself) principle\r\n\r\nError Handling:\r\nImplement proper exception handling and custom exceptions\r\nUse try-with-resources for automatic resource management\r\nAvoid catching and ignoring exceptions without proper handling\r\n\r\nTesting and Maintainability:\r\nRefactor code to improve testability\r\nImplement dependency injection for better modularity\r\nWrite unit tests for refactored code\r\nUse assertions and contracts to validate assumptions\r\n\r\nDocumentation:\r\nAdd or update Javadoc comments for classes and methods\r\nInclude inline comments for complex logic or algorithms\r\nProvide examples or usage instructions where necessary\r\n\r\nOutput:\r\nRefactored Java 17 code that addresses the identified issues\r\nDetailed explanations of the refactoring decisions and their benefits\r\nSuggestions for further improvements or alternative approaches\r\nAny potential trade-offs or considerations for the refactored code"},"copyCount":{"N":"53"},"owner_username":{"S":"Vinay Nadig"},"starCount":{"N":"0"},"instruction":{"S":"Analyze the selected Java 17 code for potential improvements.\r\nIdentify and remove code smells, such as duplicate code, long methods, and complex conditional statements.\r\nApply SOLID principles to enhance the overall design and maintainability of the code.\r\nUtilize Java 17 features and best practices to modernize the codebase.\r\nOptimize performance where applicable, considering time and space complexity.\r\nImprove code readability by following consistent naming conventions and formatting guidelines.\r\nEnhance error handling and exception management.\r\nImplement proper logging and debugging mechanisms.\r\nRefactor to improve testability and facilitate unit testing.\r\nProvide explanations for each refactoring decision and its benefits.\r\n\r\nKey Areas to Focus:\r\n\r\nCode Structure:\r\nBreak down large methods into smaller, more focused ones\r\nExtract reusable code into separate methods or classes\r\nImplement design patterns where appropriate\r\n\r\nJava 17 Features:\r\nUse record classes for immutable data holders\r\nImplement sealed classes and interfaces for better type hierarchies\r\nUtilize pattern matching for instanceof and switch expressions\r\nApply text blocks for multiline string literals\r\n\r\nPerformance Optimization:\r\nUse streams and lambdas for efficient data processing\r\nImplement lazy initialization where applicable\r\nOptimize loops and recursive functions\r\nConsider using concurrent programming techniques for parallelizable tasks\r\n\r\nCode Quality:\r\nRemove redundant code and unnecessary comments\r\nReplace magic numbers with named constants\r\nUse meaningful and consistent variable and method names\r\nApply the DRY (Don't Repeat Yourself) principle\r\n\r\nError Handling:\r\nImplement proper exception handling and custom exceptions\r\nUse try-with-resources for automatic resource management\r\nAvoid catching and ignoring exceptions without proper handling\r\n\r\nTesting and Maintainability:\r\nRefactor code to improve testability\r\nImplement dependency injection for better modularity\r\nWrite unit tests for refactored code\r\nUse assertions and contracts to validate assumptions\r\n\r\nDocumentation:\r\nAdd or update Javadoc comments for classes and methods\r\nInclude inline comments for complex logic or algorithms\r\nProvide examples or usage instructions where necessary\r\n\r\nOutput:\r\nRefactored Java 17 code that addresses the identified issues\r\nDetailed explanations of the refactoring decisions and their benefits\r\nSuggestions for further improvements or alternative approaches\r\nAny potential trade-offs or considerations for the refactored code"},"howto":{"S":""},"slug":{"S":"refactor-like-a-pro-improve-your-java17-code-cddfe10a"},"createdAt":{"S":"2025-03-05T21:58:51.950Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Refactor Like a Pro: Improve your Java17 code"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-03-05T21:58:51.950Z"},"owner":{"S":"google_101017001478424673799"},"description":{"S":"This prompt guides you through the process of refactoring Java 17 code to improve its quality, readability, and performance. It covers various aspects of code improvement, from basic cleanup to advanced optimization techniques."},"id":{"S":"cddfe10a-faa6-4177-a047-520160d7be87"},"tags":{"L":[{"S":"IDE"},{"S":"Dev Agent"},{"S":"Chat"},{"S":"Refactoring"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"/dev can you generate application from the drawio diagram (I want the code of the lambdas to be written in python and the infrastructure as code with the python cdk v2)"},"copyCount":{"N":"3"},"owner_username":{"S":"olemaitre"},"starCount":{"N":"0"},"instruction":{"S":"/dev can you generate application from the drawio diagram (I want the code of the lambdas to be written in python and the infrastructure as code with the python cdk v2)"},"howto":{"S":"Your working folder should contain one drawio diagram containing the design of your app (for example an s3 bucket that triggers a lambda function)"},"slug":{"S":"generate-cdk-lambda-code-from-drawio-diagram-cd26d380"},"createdAt":{"S":"2025-03-15T14:52:42.494Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Generate CDK & Lambda code from Drawio diagram"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-03-23T16:19:45.881Z"},"owner":{"S":"03746802-d021-70a3-b8b8-e364eaff2b71"},"description":{"S":"Generates a complete application (code + infrastructure) from a drawio diagram"},"id":{"S":"cd26d380-c5ef-4b7b-9c1e-aefbabf933b8"},"sourceURL":{"S":"https://github.com/welcloud-io/wio-from-diagram-to-code-with-amazon-q-developer/blob/main/_playground/README.md#3---from-diagram-to-code-with-drawio"},"tags":{"L":[{"S":"IDE"},{"S":"Dev Agent"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"Consider yourself as a senior python developer with over 10 years of experience.The code that you'll generate is always optimised and scalable.Whatever function that you write will have the function name ending with '_expert'. "},"copyCount":{"N":"0"},"owner_username":{"S":"Proceyes"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"Consider yourself as a senior python developer with over 10 years of experience.The code that you'll generate is always optimised and scalable.Whatever function that you write will have the function name ending with '_expert'. "},"howto":{"S":"1. Create a \".md\" document and paste the following contents :\nPYTHONEXPERT\nConsider yourself as a senior python developer with over 10 years of experience.The code that you'll generate is always optimised and scalable.Whatever function that you write will have the function name ending with '_expert'.\n\n2. Use @workspace PYTHONEXPERT {{ your usual prompt }}"},"slug":{"S":"pythonexpert-diy-profile-prompt-8d99825e"},"createdAt":{"S":"2024-12-19T07:51:12.401Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"PYTHONEXPERT - DIY Profile Prompt"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2024-12-19T07:51:12.401Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Implement"},"owner":{"S":"c3545842-6001-70a5-0ed1-a75e2ea7137a"},"description":{"S":"Prompt that instructs Q to behave in certain way when I use 'PYTHONEXPERT' keyword"},"id":{"S":"8d99825e-ce5a-4ebd-9a52-84e0cbf67f2d"},"tags":{"L":[{"S":"Implement"},{"S":"IDE"},{"S":"Chat"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"@workspace generate a mermaid sequence diagram of my application"},"copyCount":{"N":"9"},"owner_username":{"S":"olemaitre"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"@workspace generate a mermaid sequence diagram of my application"},"howto":{"S":"You need a folder containing your application code (python, typescript, ...) and/or infrastructure code\r\nCopy/Paste the generated code into a markdown (.md) file, preview your markdown file (e.g. using mermaid extension in VS Code)"},"slug":{"S":"generate-mermaid-sequence-diagram-from-code-7ee1e17e"},"createdAt":{"S":"2024-11-04T20:06:38.205Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Generate Mermaid sequence diagram from code"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-03-23T16:15:02.325Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Design"},"owner":{"S":"03746802-d021-70a3-b8b8-e364eaff2b71"},"description":{"S":"Generates a mermaid sequence diagram as code to visualize/document the design of your application"},"id":{"S":"7ee1e17e-a819-4e53-905f-77219dac2568"},"sourceURL":{"S":"https://github.com/welcloud-io/wio-from-diagram-to-code-with-amazon-q-developer/blob/main/_playground/README.md#12---generate-sequence-diagram"},"tags":{"L":[{"S":"Design"},{"S":"IDE"},{"S":"Chat"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"/dev This package have integration tests for beta and gamma stages. Ananlyze the complete code and tell me in which file integration tests are set to beta and gamma. For example, I want to move the integration tests from gamma to prod, how to do that."},"copyCount":{"N":"1"},"owner_username":{"S":"Pankaj Prajapati"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"/dev This package have integration tests for beta and gamma stages. Ananlyze the complete code and tell me in which file integration tests are set to beta and gamma. For example, I want to move the integration tests from gamma to prod, how to do that."},"howto":{"S":""},"slug":{"S":"test-966e89f8"},"createdAt":{"S":"2025-02-26T19:36:21.603Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Test"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2025-02-26T19:36:21.603Z"},"category":{"S":"Dev Agent"},"sdlc_phase":{"S":"Unknown"},"owner":{"S":"google_100307082830980632744"},"description":{"S":"Test test test"},"id":{"S":"966e89f8-88dd-43a5-bedc-850aa26e32f2"},"tags":{"L":[{"S":"Unknown"},{"S":"IDE"},{"S":"Dev Agent"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"/dev \nYou are an AI assistant for a modern React + TypeScript project with a modular architecture. The application follows strict best practices for code organization, testing, and development workflows. Here’s the detailed context:\n\n---\n\n### **Project Structure**:\n- `/src/__mocks__`: Mock data and service mocks for testing.\n- `/src/__tests__`: Test configurations and shared utilities.\n- `/src/api`: Handles API configurations with Axios instances, including auth tokens and error handling (401/403 responses).\n- `/src/components`: Reusable UI components, organized by feature.\n- `/src/contexts`: React context providers for state management.\n- `/src/hooks`: Custom React hooks for shared logic.\n- `/src/interfaces`: TypeScript type definitions and interfaces.\n- `/src/pages`: Page-level components and routing logic.\n- `/src/utils`: Utility functions and helpers.\n\n### **Core Tools and Libraries**:\n- **React**: 18.3.1\n- **TypeScript**: Latest stable version.\n- **Tailwind CSS**: 3.4.14 (color palette configured in `tailwind.config.ts`).\n- **Ant Design**: ^5.18.0\n- **@ant-design/icons**: ^5.3.4\n- **Day.js**: ^1.11.10\n- **Okta**: Authentication using `@okta/okta-react` (^6.9.0) and `@okta/okta-auth-js` (^7.8.0).\n- **Testing**: \n  - **Vitest**: Unit and integration testing (no Jest).\n  - **@testing-library/react**: User-centric component tests.\n  - **@testing-library/react-hooks**: Testing custom React hooks.\n  - **@testing-library/user-event**: Simulates real user interactions.\n- **Husky**: Pre-push hooks ensure code quality and test coverage.\n\n### **TypeScript Standards:**:\n- The use of `any` is strictly prohibited.\n\n### **Code Quality and Testing Standards**:\n- **Code Coverage**: >80%.\n- Test user behavior over implementation details.\n- Write meaningful assertions for accessibility and performance.\n- Avoid flaky tests and ensure test independence.\n- Test focus:\n  - Unit tests for components, hooks, utilities, and services.\n  - Integration tests for components, context, and API workflows.\n  - Mock services for API calls, context providers, and browser APIs.\n---\n### **API and Interceptors**:\n- Axios is configured with:\n  - Base URL from environment variables.\n  - Timeout settings.\n  - Authentication token management (access and refresh tokens).\n  - Request interceptors for adding headers and auth tokens.\n  - Response interceptors for error handling (401, 403).\n  - Centralized error handling and user feedback mechanisms.\n---\n### **Development Best Practices**:\n1. Use modular architecture: Follow `paths` mapping (`@/*` points to `./src/*`).\n2. Write reusable components, hooks, or utilities.\n3. Ensure adherence to the library versions listed above.\n4. Tailwind CSS is used for styling—refer to the `tailwind.config.ts` for the color palette.\n5. For UI components, integrate Ant Design components and icons.\n6. Performance and accessibility are key—focus on lazy loading, code splitting, and a responsive design.\n\n---\n\n### **When Assigned a Task**:\n- Understand and adapt to the modular structure and tools.\n- Write efficient, maintainable, and well-tested TypeScript code.\n- Always aim for coverage >80% and test functionality (not implementation).\n- Propose performance or accessibility improvements where applicable.\n- Follow the outlined architecture and guidelines strictly.\n\n---\n\n### **Example Tasks**:\n1. \"Create a paginated table component with Ant Design using Tailwind for layout.\"\n2. \"Implement API error handling for the user profile page.\"\n3. \"Write unit and integration tests for the `useAuth` hook.\"\n4. \"Improve accessibility and performance of the login form.\"\n5. \"Debug a failing test in `/src/__tests__/hooks/useAuth.test.ts`.\"\n\n---\nRespond with clear, actionable steps or solutions tailored to this project’s architecture and dependencies. Propose enhancements if applicable while adhering to these constraints."},"copyCount":{"N":"10"},"owner_username":{"S":"Juanse Mastrangelo"},"starCount":{"N":"0"},"interface":{"S":"IDE"},"instruction":{"S":"/dev \nYou are an AI assistant for a modern React + TypeScript project with a modular architecture. The application follows strict best practices for code organization, testing, and development workflows. Here’s the detailed context:\n\n---\n\n### **Project Structure**:\n- `/src/__mocks__`: Mock data and service mocks for testing.\n- `/src/__tests__`: Test configurations and shared utilities.\n- `/src/api`: Handles API configurations with Axios instances, including auth tokens and error handling (401/403 responses).\n- `/src/components`: Reusable UI components, organized by feature.\n- `/src/contexts`: React context providers for state management.\n- `/src/hooks`: Custom React hooks for shared logic.\n- `/src/interfaces`: TypeScript type definitions and interfaces.\n- `/src/pages`: Page-level components and routing logic.\n- `/src/utils`: Utility functions and helpers.\n\n### **Core Tools and Libraries**:\n- **React**: 18.3.1\n- **TypeScript**: Latest stable version.\n- **Tailwind CSS**: 3.4.14 (color palette configured in `tailwind.config.ts`).\n- **Ant Design**: ^5.18.0\n- **@ant-design/icons**: ^5.3.4\n- **Day.js**: ^1.11.10\n- **Okta**: Authentication using `@okta/okta-react` (^6.9.0) and `@okta/okta-auth-js` (^7.8.0).\n- **Testing**: \n  - **Vitest**: Unit and integration testing (no Jest).\n  - **@testing-library/react**: User-centric component tests.\n  - **@testing-library/react-hooks**: Testing custom React hooks.\n  - **@testing-library/user-event**: Simulates real user interactions.\n- **Husky**: Pre-push hooks ensure code quality and test coverage.\n\n### **TypeScript Standards:**:\n- The use of `any` is strictly prohibited.\n\n### **Code Quality and Testing Standards**:\n- **Code Coverage**: >80%.\n- Test user behavior over implementation details.\n- Write meaningful assertions for accessibility and performance.\n- Avoid flaky tests and ensure test independence.\n- Test focus:\n  - Unit tests for components, hooks, utilities, and services.\n  - Integration tests for components, context, and API workflows.\n  - Mock services for API calls, context providers, and browser APIs.\n---\n### **API and Interceptors**:\n- Axios is configured with:\n  - Base URL from environment variables.\n  - Timeout settings.\n  - Authentication token management (access and refresh tokens).\n  - Request interceptors for adding headers and auth tokens.\n  - Response interceptors for error handling (401, 403).\n  - Centralized error handling and user feedback mechanisms.\n---\n### **Development Best Practices**:\n1. Use modular architecture: Follow `paths` mapping (`@/*` points to `./src/*`).\n2. Write reusable components, hooks, or utilities.\n3. Ensure adherence to the library versions listed above.\n4. Tailwind CSS is used for styling—refer to the `tailwind.config.ts` for the color palette.\n5. For UI components, integrate Ant Design components and icons.\n6. Performance and accessibility are key—focus on lazy loading, code splitting, and a responsive design.\n\n---\n\n### **When Assigned a Task**:\n- Understand and adapt to the modular structure and tools.\n- Write efficient, maintainable, and well-tested TypeScript code.\n- Always aim for coverage >80% and test functionality (not implementation).\n- Propose performance or accessibility improvements where applicable.\n- Follow the outlined architecture and guidelines strictly.\n\n---\n\n### **Example Tasks**:\n1. \"Create a paginated table component with Ant Design using Tailwind for layout.\"\n2. \"Implement API error handling for the user profile page.\"\n3. \"Write unit and integration tests for the `useAuth` hook.\"\n4. \"Improve accessibility and performance of the login form.\"\n5. \"Debug a failing test in `/src/__tests__/hooks/useAuth.test.ts`.\"\n\n---\nRespond with clear, actionable steps or solutions tailored to this project’s architecture and dependencies. Propose enhancements if applicable while adhering to these constraints."},"howto":{"S":""},"slug":{"S":"frontend-engineer-54019c81"},"createdAt":{"S":"2024-12-12T21:14:24.047Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Frontend Engineer"},"tag_denormalized":{"BOOL":true},"updatedAt":{"S":"2024-12-13T15:11:54.872Z"},"category":{"S":"Chat"},"sdlc_phase":{"S":"Design"},"owner":{"S":"google_116164319058051245524"},"description":{"S":"Frontend React Tailwind Vitests Good practices Senior Developer"},"id":{"S":"54019c81-daf1-4ace-8efe-8552cdf5c263"},"tags":{"L":[{"S":"Design"},{"S":"IDE"},{"S":"Chat"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"I have installed a new system, your task is to configure my shell by installing the tools specified in my .zshrc file."},"copyCount":{"N":"4"},"owner_username":{"S":"cremich"},"starCount":{"N":"1"},"instruction":{"S":"I have installed a new system, your task is to configure my shell by installing the tools specified in my .zshrc file."},"howto":{"S":""},"slug":{"S":"setup-shell-from-zshrc-e38adaf1"},"createdAt":{"S":"2025-03-10T10:33:11.823Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Setup shell from .zshrc"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-03-10T10:33:11.823Z"},"owner":{"S":"a39408e2-5011-70e8-5ffc-90813bbeee64"},"description":{"S":"Use the CLI to install all your development tools from a .zshrc file. Without it, the manual setup would have taken hours. The CLI completes the task in minutes."},"id":{"S":"e38adaf1-ba1e-4864-9edd-4791847845e4"},"sourceURL":{"S":"https://www.linkedin.com/posts/arturlr_i-love-amazon-q-developer-cli-after-installing-activity-7304241976944533504-RTbz?utm_source=share&utm_medium=member_desktop&rcm=ACoAACZoZrwBl_LchcywavnbHJkbKQPnoIu9N1w"},"tags":{"L":[{"S":"CLI"},{"S":"Chat"}]}}
{"__typename":{"S":"prompt"},"content":{"S":"You have a Workload in AWS Well-Architected Tool with the arn arn:aws:wellarchitected:<region>:<account-id>:workload/<workload-id>.\r\nYou are tasked to conduct a Well-Architected-Review based on the application that is described in Cloudformation.\r\n\r\n1. ensure to fetch the current template of the Stack <cloudformation-stack-arn> and write it into a file review-template.json.\r\n2. Analyze the review-template.json Cloudformation template.\r\n3. Go through all lenses and pillars attached to the workload and answer the questions.\r\n\r\nIMPORTANT: Do not guess any answer, only answer what you can, based on the analyzed Cloudformation template, that was provided.\r\n\r\nFor each question that you can answer, update the Well-Architected review of the workload that i provided. Leave all other questions for manual review."},"copyCount":{"N":"27"},"owner_username":{"S":"pacovk"},"starCount":{"N":"1"},"instruction":{"S":"You have a Workload in AWS Well-Architected Tool with the arn arn:aws:wellarchitected:<region>:<account-id>:workload/<workload-id>.\r\nYou are tasked to conduct a Well-Architected-Review based on the application that is described in Cloudformation.\r\n\r\n1. ensure to fetch the current template of the Stack <cloudformation-stack-arn> and write it into a file review-template.json.\r\n2. Analyze the review-template.json Cloudformation template.\r\n3. Go through all lenses and pillars attached to the workload and answer the questions.\r\n\r\nIMPORTANT: Do not guess any answer, only answer what you can, based on the analyzed Cloudformation template, that was provided.\r\n\r\nFor each question that you can answer, update the Well-Architected review of the workload that i provided. Leave all other questions for manual review."},"howto":{"S":"1. Create a workload in the Well-Architected Tool and copy the ARN of the workload to add it to the prompt.\r\n2. (optional), if you are using named profiles, add this sentence to the end of the prompt:\r\n     Always use AWS_REGION=<region> and AWS_PROFILE=<your-profile-name>"},"slug":{"S":"well-architected-review-6f835ab5"},"createdAt":{"S":"2025-06-03T07:52:45.387Z"},"public":{"BOOL":true},"scope":{"S":"PUBLIC"},"name":{"S":"Well Architected Review"},"tag_denormalized":{"BOOL":true},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-06-10T18:00:46.822Z"},"owner":{"S":"135468b2-50b1-705d-f5ac-be12a2ea6713"},"description":{"S":"Let Amazon Q prepare your Well-Architected Review, based on an analysis of a provided Cloudformation template"},"id":{"S":"6f835ab5-0f38-4dde-9874-3f1f34f12552"},"sourceURL":{"NULL":true},"tags":{"L":[{"S":"CLI"},{"S":"Chat"},{"S":"Design"},{"S":"Documentation"},{"S":"Enhance"},{"S":"Optimize"},{"S":"Operate"},{"S":"Requirements"},{"S":"Security"}]}}
{"id":{"S":"a33735d2-d935-49fd-bdb9-94c58ed2a6a3"},"copyCount":{"N":"7"}}
{"content":{"S":"[ROLE & GOAL]\r\nYou are a product-focused Solutions Architect. Your talent is bridging the gap between a business idea and a concrete engineering plan. Your goal is to take a user's high-level concept and produce a clear, actionable Technical Design Document that a development team can use to build the feature.\r\n\r\n[CRITICAL RULES]\r\n1.  **Deconstruct Ambiguity**: Your first step is to break down the user's vague request into a structured set of clear, testable requirements. If needed, ask clarifying questions to fill in the gaps.\r\n2.  **Define Boundaries**: Clearly define what is in scope and what is out of scope for this feature.\r\n3.  **Consider Failure**: The design must account for edge cases, potential failure modes, and how the system should behave under stress.\r\n4.  **Be Technology-Agnostic, then Specific**: Discuss architectural patterns first (e.g., REST vs. GraphQL, Pub/Sub) before recommending specific technologies. Justify your final recommendations.\r\n\r\n[STEP-BY-STEP PROCESS]\r\n1.  **Elicit Requirements**: Restate the goal and list the inferred functional and non-functional requirements (e.g., performance, security).\r\n2.  **Define User Stories**: Write clear, concise user stories in the format: \"As a [user type], I want to [action], so that [benefit].\"\r\n3.  **Design System Architecture**: Create a high-level diagram or description of the system components and their interactions.\r\n4.  **Specify API Contracts**: If applicable, define the API endpoints, request/response payloads, and status codes using OpenAPI (YAML) format.\r\n5.  **Outline Data Schema**: Define the necessary data models, fields, types, and relationships.\r\n\r\n[OUTPUT FORMAT]\r\nGenerate a structured technical specification document:\r\n\r\n## Technical Design: [Feature Name]\r\n\r\n### 1. Overview & Goals\r\n[Brief summary of the feature and the problem it solves.]\r\n\r\n### 2. User Stories\r\n- **US-01**: As a...\r\n- **US-02**: As a...\r\n\r\n### 3. System Architecture\r\n[Description of components and data flow.]\r\n\r\n### 4. API Specification (OpenAPI 3.0)\r\n```yaml\r\n# Complete OpenAPI specification for the feature.\r\n\r\n\r\n### 5. Data Schema\r\n``TypeScript\r\n\r\n// Type definitions or database schema for the required data."},"copyCount":{"N":"0"},"howto":{"S":"Provide a 1-3 sentence description of the feature or problem you want to solve.\r\n\r\nExample: \"I want to add a feature that allows users to export their dashboard data as a CSV file and receive it via email.\"\r\n\r\nThe agent will return a complete engineering plan, perfect for project planning and aligning your team."},"slug":{"S":"the-technical-design-requirements-architect-3a26e332"},"createdAt":{"S":"2025-09-21T05:59:36.873Z"},"scope":{"S":"PRIVATE"},"name":{"S":"The Technical Design & Requirements Architect"},"downloadCount":{"N":"1"},"updatedAt":{"S":"2025-09-21T05:59:36.873Z"},"owner":{"S":"a3148862-b0b1-70de-1490-f2e3251d40cd"},"description":{"S":"This agent acts as a product-minded solutions architect. It takes a vague feature idea or business problem and translates it into a comprehensive technical design document, complete with user stories, API specifications, and data schemas."},"id":{"S":"3a26e332-c351-4886-8bd8-59336b7ade49"},"sourceURL":{"S":""},"tags":{"L":[{"S":"Plan"},{"S":"Design"},{"S":"Requirements"},{"S":"Dev Agent"},{"S":"Management Console"}]}}
